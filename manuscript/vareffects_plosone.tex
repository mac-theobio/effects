% Template for PLoS
% Version 3.5 March 2018
%
% % % % % % % % % % % % % % % % % % % % % %
%
% -- IMPORTANT NOTE
%
% This template contains comments intended 
% to minimize problems and delays during our production 
% process. Please follow the template instructions
% whenever possible.
%
% % % % % % % % % % % % % % % % % % % % % % % 
%
% Once your paper is accepted for publication, 
% PLEASE REMOVE ALL TRACKED CHANGES in this file 
% and leave only the final text of your manuscript. 
% PLOS recommends the use of latexdiff to track changes during review, as this will help to maintain a clean tex file.
% Visit https://www.ctan.org/pkg/latexdiff?lang=en for info or contact us at latex@plos.org.
%
%
% There are no restrictions on package use within the LaTeX files except that 
% no packages listed in the template may be deleted.
%
% Please do not include colors or graphics in the text.
%
% The manuscript LaTeX source should be contained within a single file (do not use \input, \externaldocument, or similar commands).
%
% % % % % % % % % % % % % % % % % % % % % % %
%
% -- FIGURES AND TABLES
%
% Please include tables/figure captions directly after the paragraph where they are first cited in the text.
%
% DO NOT INCLUDE GRAPHICS IN YOUR MANUSCRIPT
% - Figures should be uploaded separately from your manuscript file. 
% - Figures generated using LaTeX should be extracted and removed from the PDF before submission. 
% - Figures containing multiple panels/subfigures must be combined into one image file before submission.
% For figure citations, please use "Fig" instead of "Figure".
% See http://journals.plos.org/plosone/s/figures for PLOS figure guidelines.
%
% Tables should be cell-based and may not contain:
% - spacing/line breaks within cells to alter layout or alignment
% - do not nest tabular environments (no tabular environments within tabular environments)
% - no graphics or colored text (cell background color/shading OK)
% See http://journals.plos.org/plosone/s/tables for table guidelines.
%
% For tables that exceed the width of the text column, use the adjustwidth environment as illustrated in the example table in text below.
%
% % % % % % % % % % % % % % % % % % % % % % % %
%
% -- EQUATIONS, MATH SYMBOLS, SUBSCRIPTS, AND SUPERSCRIPTS
%
% IMPORTANT
% Below are a few tips to help format your equations and other special characters according to our specifications. For more tips to help reduce the possibility of formatting errors during conversion, please see our LaTeX guidelines at http://journals.plos.org/plosone/s/latex
%
% For inline equations, please be sure to include all portions of an equation in the math environment.  For example, x$^2$ is incorrect; this should be formatted as $x^2$ (or $\mathrm{x}^2$ if the romanized font is desired).
%
% Do not include text that is not math in the math environment. For example, CO2 should be written as CO\textsubscript{2} instead of CO$_2$.
%
% Please add line breaks to long display equations when possible in order to fit size of the column. 
%
% For inline equations, please do not include punctuation (commas, etc) within the math environment unless this is part of the equation.
%
% When adding superscript or subscripts outside of brackets/braces, please group using {}.  For example, change "[U(D,E,\gamma)]^2" to "{[U(D,E,\gamma)]}^2". 
%
% Do not use \cal for caligraphic font.  Instead, use \mathcal{}
%
% % % % % % % % % % % % % % % % % % % % % % % % 
%
% Please contact latex@plos.org with any questions.
%
% % % % % % % % % % % % % % % % % % % % % % % %

\documentclass[10pt,letterpaper]{article}
\usepackage[top=0.85in,left=2.75in,footskip=0.75in]{geometry}

% amsmath and amssymb packages, useful for mathematical formulas and symbols
\usepackage{amsmath,amssymb}

% Use adjustwidth environment to exceed column width (see example table in text)
\usepackage{changepage}

% Use Unicode characters when possible
\usepackage[utf8x]{inputenc}

% textcomp package and marvosym package for additional characters
\usepackage{textcomp,marvosym}

% cite package, to clean up citations in the main text. Do not remove.
\usepackage{cite}

% Use nameref to cite supporting information files (see Supporting Information section for more info)
\usepackage{nameref,hyperref}

% line numbers
\usepackage[right]{lineno}

% ligatures disabled
\usepackage{microtype}
\DisableLigatures[f]{encoding = *, family = * }

% color can be used to apply background shading to table cells only
\usepackage[table]{xcolor}

% array package and thick rules for tables
\usepackage{array}

% create "+" rule type for thick vertical lines
\newcolumntype{+}{!{\vrule width 2pt}}

% create \thickcline for thick horizontal lines of variable length
\newlength\savedwidth
\newcommand\thickcline[1]{%
  \noalign{\global\savedwidth\arrayrulewidth\global\arrayrulewidth 2pt}%
  \cline{#1}%
  \noalign{\vskip\arrayrulewidth}%
  \noalign{\global\arrayrulewidth\savedwidth}%
}

% \thickhline command for thick horizontal lines that span the table
\newcommand\thickhline{\noalign{\global\savedwidth\arrayrulewidth\global\arrayrulewidth 2pt}%
\hline
\noalign{\global\arrayrulewidth\savedwidth}}


% Remove comment for double spacing
%\usepackage{setspace} 
%\doublespacing

% Text layout
\raggedright
\setlength{\parindent}{0.5cm}
\textwidth 5.25in 
\textheight 8.75in

% Bold the 'Figure #' in the caption and separate it from the title/caption with a period
% Captions will be left justified
\usepackage[aboveskip=1pt,labelfont=bf,labelsep=period,justification=raggedright,singlelinecheck=off]{caption}
\renewcommand{\figurename}{Fig}

% Use the PLoS provided BiBTeX style
\bibliographystyle{plos2015}

% Remove brackets from numbering in List of References
\makeatletter
\renewcommand{\@biblabel}[1]{\quad#1.}
\makeatother



% Header and Footer with logo
\usepackage{lastpage,fancyhdr,graphicx}
\usepackage{epstopdf}
%\pagestyle{myheadings}
\pagestyle{fancy}
\fancyhf{}
%\setlength{\headheight}{27.023pt}
%\lhead{\includegraphics[width=2.0in]{PLOS-submission.eps}}
\rfoot{\thepage/\pageref{LastPage}}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrule}{\hrule height 2pt \vspace{2mm}}
\fancyheadoffset[L]{2.25in}
\fancyfootoffset[L]{2.25in}
\lfoot{\today}

%% Include all macros below

\newcommand{\fix}{{\bf \textcolor{red}{FIXME}}}
\newcommand{\JD}[1]{{\color{blue} \emph{#1}}}
\newcommand{\bmb}[1]{{\color{RubineRed!70!} \emph{#1}}}
\newcommand{\pkg}[1]{\textbf{#1}}

\def\code#1{\texttt{#1}}
\let\proglang=\textsf

\newcommand{\bX}{{\mathbf X}}
\newcommand{\bZ}{{\mathbf Z}}
\newcommand{\bbeta}{{\boldsymbol \beta}}
\newcommand{\boldeta}{{\boldsymbol \eta}}
\newcommand{\boldmu}{{\boldsymbol \mu}}

\newcommand{\nset}[1]{#1_{\{n\}}}
\newcommand{\yref}{y_{\textrm{ref}}}
\newcommand{\cdist}{{D(\nset{x}|x_f)}}
\newcommand{\cdistprime}{{D(\nset{x}|x_{f'})}}
\newcommand{\xfprime}{x_{f'}}

\newcommand{\yE}{{\mathrm E}}
\let\over=\overline


%% END MACROS SECTION


\begin{document}
\vspace*{0.2in}

% Title must be 250 characters or less.
\begin{flushleft}
{\Large
\textbf\newline{Describing the curves: uncertainty propagation and bias correction for predictor effects in simple and generalized linear (mixed) models} % Please use "sentence case" for title and headings (capitalize only the first word in a title (or heading), the first word in a subtitle (or subheading), and any proper nouns).
}
\newline
% Insert author names, affiliations and corresponding author email (do not include titles, positions, or degrees).
\\
Steve Cygu\textsuperscript{1},
Benjamin M. Bolker\textsuperscript{1,2},
Jonathan Dushoff\textsuperscript{1,2}
\\
\bigskip
\textbf{1} School of Computational Science and Engineering, McMaster University, Hamilton, Ontario, Canada
\\
\textbf{2} Department of Biology, McMaster University, Hamilton, Ontario, Canada
\\
\bigskip


% Use the asterisk to denote corresponding authorship and provide email address in note below.
* cygu@aims.ac.za

\end{flushleft}
% Please keep the abstract below 300 words
\section*{Abstract}

In many applications using genralized linear (mixed) models, outcome predictions or predicted probabilities are often of interest. For models that involve complex multiplicative interactions, additional non-focal predictors or nonlinear link functions, the estimated coefficient are not readily interpretable. A general way to summarize these kind of models is through predictor effects, which are also sensitive to which values of non-focal predictors are chosen. The most common approach is generating predictor effects at a ``typical value'', usually the mean, of non-focal predictor, i.e., mean-anchored which is the effect of an ``average case'' in the population. In the presence of sources of bias such as additional non-focal predictors, nonlinear link functions, random effect terms, etc., mean-anchored approach generate predictor effects that are biased and not consistent with the observed quantities. An alternative is the population-based approach which estimates the average effect in the population. Moreover, isolated confidence intervals provide an alternative and a more clear way to describe uncertainty associated with the focal predictor of interest. In addition to theoretical and methodical comparison, using simulation, we illustrate the two approaches and show that they can produce substantially different results and that population-based approach can not only produce estimates consistent with the observed values, but also appropriate for bias correction.


% Please keep the Author Summary between 150 and 200 words
% Use first person. PLOS ONE authors please skip this step. 
% Author Summary not valid for PLOS ONE submissions.   
\section*{Author summary}

\fix

\linenumbers

% Use "Eq" instead of "Equation" for equation citations.
\section*{Introduction}

In many applications using simple or generalized linear (mixed) models, outcome predictions or probabilities, are often of interest. Predictions provide a great way to summarize what the regression model is telling us and very useful for interpreting and visualizing model estimates. For example, in logistic regression models, the coefficient estimates are usually not easy to interpret and less informative. Since logistic models are nonlinear (due to the nonlinear link function), in multivariate models with interactions, the magnitude of the effect of change in the outcome depends on the values of the predictor of interest and other predictors. Hence, the conclusions one can make about the estimated effects greatly depends on how well we choose the values of the other predictors, i.e., \emph{non-focal} predictors.  

Both simple and generalized linear (mixed) models (GL(M)Ms) can examine very complex relationships, including nonlinear relationships between response and predictors, interactions between predictors (and via splines for example), and nonlinear transformations via link functions due to their flexibility. This flexibility comes at a cost, for example, complex multivariate models may risk misinterpretation, and miscalculation of quantities of interest. Also, coefficient estimates of models involving nonlinear link functions or interactions lose their direct interpretation \cite{leeper2017interpreting}, meaning that interpretation of derived quantities from these estimates requires some understanding of the specified model. An alternative is to explore the \emph{effects} of predictors on the predictions or probabilities of the outcome at various level of the predictor of interest -- \emph{predictor effects} \cite{fox2009effect, leeper2017package, lenth2018package}. For example, as a way to plan, public health officials may want to know the effects of household income, wealth index, etc, on the predicted probability of having improved water services among slum dwellers.


When visually presented, predictor effects provide a unified and intuitive way of describing relationships from a fitted model, especially complex models involving interaction terms or some kind of transformations on the predictors whose estimates are usually, but not always, a subject to less clarity of interpretation. Further, generating predictor effects together with the associated confidence intervals for regression models has a number of challenges. In particular:
\begin{enumerate}
\item choice of representative values of \emph{focal} predictor(s) and appropriate \emph{anchor} for non-focal predictors especially in multivariate models
\item  propagation of uncertainty -- can we incorporate uncertainty in nonlinear components of GL(M)Ms? Should we exclude variation in non-focal parameters?
\item bias in the expected mean prediction induced by the nonlinear transformation of the response variable (especially in GL(M)Ms)
\end{enumerate}

The most common way of dealing with the first challenge is taking unique levels of the focal (predictor of interest) predictor if discrete or taking appropriately sized quantiles (or bins) if continuous, and then calculating the predictions while holding non-focal (other predictors other than the focal predictor) predictors at their typical values (e.g., averages) \cite{hanmer2013behind}. This generates -- \emph{predictor effects}\cite{fox2009effect}, \emph{marginal predictions} \cite{leeper2017package} and \emph{estimated marginal means} \cite{lenth2018package}. In this article, we refer to this quantity as predictor effects since it should, for example, tell us what we would expect the presponse to be at a particular value or level of the predictor, for an ``average case''. Formerly, predictor effects computes the expected outcome by meaningfully holding the non-focal predictors constant (or averaged in some meaningful way) while varying the focal predictor, with the goal that the outcome expected prediction represents how the model responds to the changes in the focal predictor.

The commonly used \proglang{R} software packages (\pkg{emmeans} and \pkg{effects}) for generating predictor effects, by default, averages the non-focal predictors. However, there are a number of choices one can make when considering this approach -- for example, in the presence of interaction, averaging the interactions (averaging product of interacting predictors) versus product of the averages of the interacting predictors (default for \pkg{emmeans} and \pkg{effects}). We claim that neither of these two approaches is the most appropriate but we show that averaging the interaction closely matches the observed values. To illustrate this, consider models~\ref{eq:simple_inter_higher_no_interaction} and \ref{eq:simple_inter_higher} below, with $x_1$ as the focal predictor:

%
\begin{align}
y &= \beta_0 + \beta_1x_1 + \beta_2x_2 + \beta_3x_3 + \epsilon \label{eq:simple_inter_higher_no_interaction}\\
y &= \beta_0 + \beta_1x_1 + \beta_2x_2 + \beta_3x_3 + \beta_{23}x_2x_3 + \epsilon \label{eq:simple_inter_higher}
\end{align}
%

We first simulate data with the two models, such that $x_{1,2,3} \sim \mathrm{Normal}(0, 1)$, $\beta_0 = 5$, $\beta_1 = -3$, $\beta_2 = 1$, $\beta_3 = 2$ and $\beta_{23} = 5$, and then compare the predictions from the \pkg{emmeans}, \pkg{effects} and our proposed alternative (\pkg{varpred}) to the observed average i.e., $\bar{y}$, as shown in Fig~\ref{fig:justify_plots}.

\begin{figure}[!h]
\centering
\includegraphics[width=0.8\textwidth]{justify_plots-figure1.pdf}
\caption{{\bf A comparison of \pkg{emmeans}, \pkg{effects} and \pkg{varpred} predictor effects for $x_1$ on $y$ for models with and without interactions.}
The horizontal blue, green and black lines are the mean predictions, i.e., $\bar{\hat{y}}$, the red ones are the mean observed $y$, i.e., $\bar{y}$, while the vertical dotted grey lines are the means of the corresponding focal predictors. The grey points are the binned simulated $y$. The trend lines represents the corresponding $\hat{y}$ at various levels of $x_1$, while holding the other predictors at their average. A: In the absence of interaction, the predicted mean, $\bar{\hat{y}}$, closely matches the observed in all the three approaches, i.e., $\bar{y} \approx \bar{\hat{y}}$. B: Even with the simple interaction between the non-focal predictors, we start seeing deviation of the predicted mean, $\bar{\hat{y}}$, from the observed, $\bar{y}$, in two commonly used packages (\pkg{emmeans} and \pkg{effects}), but not, the proposed \pkg{varpred}.}
\label{fig:justify_plots}
\end{figure}

In the absence of interaction (model~\ref{eq:simple_inter_higher_no_interaction}), the three approaches produce similar estimates, which match the observed values, Fig~\ref{fig:justify_plots}A. However, in the presence of interaction, even as simple as the one in model~\ref{eq:simple_inter_higher}, the estimates starts to differ. In particular, \pkg{emmeans} and \pkg{effects} give similar estimates ($\bar{\hat{y}}$) but different from the \pkg{varpred}'s which, however, is similar to the observed average ($\bar{y}$), Fig~\ref{fig:justify_plots}B. To generate Fig~\ref{fig:justify_plots}A, all the three packages averages the non-focal predictors $x_2$ and $x_3$. On other hand, to generate Fig~\ref{fig:justify_plots}B, the difference in the estimates lies on how each of the packages average the interaction term ($x_2x_3$). In particular \pkg{emmeans} and \pkg{effects} computes $\bar{x_2}\bar{x_3}$ while \pkg{varpred} computes $\over{x_2x_3}$.

In some applications, we may only be interested in the uncertainties associated with a particular focal predictor -- \emph{isolated} confidence intervals. However, currently, the two packages do not provide straightforward way do achieve this. To illustrate this, we generate predictor effect of $x_2$ from model~\ref{eq:simple_inter_higher_no_interaction} together with the associated $95\%$ confidence bands, as shown in Fig~\ref{fig:justify_ci_plots}. 

\begin{figure}[!h]
\centering
\includegraphics[width=0.8\textwidth]{justify_ci_plots-figure2.pdf}
\caption{{\bf A comparison of traditional and isolated $95\%$ confidence bands.} The description of horizontal, vertical and trend lines remain the same as above. The wider dotted blue curves overlaying the green curves are the traditional confidence bands from \pkg{emmeans} and \pkg{effects}, while the narrower black curves crossing at the mean of the focal predictor, i.e., the model center, are the isolated confidence bands from \pkg{varpred}. For simple models, the isolated confidence bands crosses at the model center.}
\label{fig:justify_ci_plots}
\end{figure}

For \pkg{emmeans} and \pkg{effects}, the confidence bands are much wider because they include uncertainties associated with the non-focal predictors, but narrower and crosses at the mean of the focal predictor, i.e., model center, in \pkg{varpred}. In other words, with \pkg{varpred}, we are able to generate isolated confidence bands indicating zero uncertainty at the value of the focal predictor we are more certain about, i.e., mean of the focal predictor. For simple models, the point where the confidence bands crosses is the model center and it corresponds to typical value we choose, in this case, the mean of the focal predictor.


When dealing with nonlinear link functions or models with multiple non-focal predictors, the correct predictions, for example, are even much harder to estimate. One approach is to make predictions on the transformed scale (linear predictor scale), and then back-transform to the original scale. However, the back-transformation may either result in biased predictions or requires some approximation. In particular, bias in expected mean prediction induced by nonlinear transformation of the response variable can lead inaccurate predictions. An alternative to averaging the non-focal predictors, is the \emph{population-based} approach, discussed in detail later, which involves computing the prediction over the population of the non-focal predictors and then averaging across the values of the focal predictor \cite{hanmer2013behind}. 


The main purpose of this article is to discuss and implement various approaches for computing predictor effects and provide an alternative method for computing the associated confidence intervals. We further explore and demonstrate, using simulated data, approaches for correcting bias in predictions for GL(M)Ms involving nonlinear link functions.


\section*{Quantities of interest}

Several quantities of interest may be derived from regression models. The first one is the coefficient estimates. Others are \emph{input variables},  \emph{predictors}, \emph{model matrix}, \emph{predicted values} and \emph{marginal effects}. Input variables are the variables that were measured (may be transformed), while predictors are the terms that are entered in the model. Hence, predictors encompass the main effects, but also polynomials of input variables and interaction terms (for example in polynomials and splines) \cite{schielzeth2010simple}. Model matrix refers to the design matrix whose rows include all combination of variables appearing in the interaction terms, along with the typical values of the focal and non-focal predictors.

In simple linear models with no interaction terms, the default output for the coefficient estimates are simple and directly interpretable as the expected change in outcome for a unit change in focal predictor. This is the \emph{unconditional marginal effect} \cite{leeper2017interpreting} and it is constant across all the observations and levels of all other predictors. Consider models ~\ref{eq:simple_inter_higher_no_interaction} and \ref{eq:simple_inter_higher}. The marginal effect of $x_2$ in model~\ref{eq:simple_inter_higher_no_interaction} is $\frac{\partial y}{\partial x_2} = \beta_2$. On the other hand, the marginal effect of $x_2$ in model~\ref{eq:simple_inter_higher} is given by $\frac{\partial y}{\partial x_2} = \beta_2 + \beta_{23}x_3$. In other words, if there are no interactions, the marginal effect of $x_2$ on $y$ is constant, while, if there are interactions in the model, the marginal effect of a change in $x_2$ on $y$ depends on the value of the other \emph{conditioning} predictor $x_3$. In general, for a continuous variable, $x_k$, the marginal effect is $\frac{\partial y}{\partial x_k} = g(x\beta)\beta_k$, where $g()$ is the probability density function. This implies that, in addition to coefficient estimates, the marginal effect depends on the nature of $g()$ and the values of the other non-focal predictors. For nonlinear link functions, $g()$, the effect is not constant and instead depends on the function and the values over which the curve is evaluated.

To distinguish between predictor effects and marginal effects, consider result from a hypothetical  simulated example -- regression of household size as function of household wealth index and age of household head, as shown in Fig~\ref{fig:qoi_age_pred_plot}. Since the model has no interactions, the relationship between the predicted household size and age is linear, hence the marginal effect of age is the slope ($\frac{\Delta \mathrm{hh size}}{\Delta \mathrm{age}}$) of the predictor effect line and can be calculated irrespective of the values of wealth index.

\begin{figure}[!h]
\centering
\includegraphics[width=0.8\textwidth]{qoi_age_pred_plot-figure3.pdf}
\caption{{\bf A comparison of predictor effect and unconditional marginal effect of age on household size.} The black line is the predictor effect trend line, while the dotted lines indicate the changes along the \code{age} and \code{household size} axis. For a linear model with no interaction, the marginal effect is the slope of the predictor effect line.}
\label{fig:qoi_age_pred_plot}
\end{figure}

Predictor effect, on the other hand, is the expected household size for a particular age, holding wealth index at its mean. In particular, the purpose and goal of a predictor effect seems fairly straightforward; for specified values of a focal predictor, we want to give a point estimate and confidence intervals for the prediction of the model for a typical individual with those values of the predictors.

\section*{Statistical background}

To get an intuition of how conditioning on the mean values of the non-focal predictors work, suppose we are interested in predictor effects of a particular predictor, i.e., focal, $x_f$, from the set of predictors. To keep it simple, assume that the model has no interaction terms. The idea is to \emph{anchor} the values of non-focal predictors to some particular values. For example, fixing the values of non-focal predictor(s) at some typical values -- typically determined by averaging (for now) in some meaningful way, for example, arithmetic mean  for continuous and average over the levels of the factors for categorical non-focal predictors. We refer to this as \emph{mean-anchored} approach. The most convenient way to achieve this is by constructing $\bX^\star$ by averaging the columns of non-focal predictors in model matrix $\bX$, and together with appropriately chosen values of focal predictor.


Consider a simple linear model with linear predictor $\eta = \bX\bbeta$ and let $g(\boldmu) = \boldeta$ be an identity link function (in the case of simple linear model), where $\boldmu$ is the expected value of response variable $y$. Let $\hat{\bbeta}$ be the estimate of $\bbeta$, together with the estimated covariance matrix $\Sigma = V(\hat{\bbeta})$ of $\hat{\bbeta}$. Let $\mathbf{X^*}$ be the model matrix, inheriting most of its key properties, for example transformations on predictors and interactions from the model matrix, $\mathbf{X}$. Then the prediction $\hat{\boldeta}^\star = \bX^\star\hat{\bbeta}$ is the predictor effect for the focal predictor in question \cite{fox2009effect}.

An alternative, save for later, formulation of predictor effect involves, expressing the linear predictor as the sum of the focal and non-focal predictor linear predictor. In particular, 

\begin{align}\label{eq:eta_mean}
\eta^\star(x_f, \nset{{\bar{x}}}) &= \beta_f x_f + \sum \nset{\beta} \nset{{\bar{x}^\star}} \\
\hat{y}_f  &= g^{-1} \left(\eta^\star(x_f, \nset{{\bar{x}}})\right)
\end{align}
where $\nset{{\bar{x}^\star}}$ are the appropriately averaged entries of non-focal predictors and $x_f$ is a vector of values of the focal predictors for a particular observation.


\subsection*{Dealing with higher order interactions}

Higher order terms such as interactions, splines, polynomials, etc., can be between the non-focal predictors or focal and non-focal predictor(s). In the former case, we treat the interactions as just another column in the variable space (of the model matrix). In the later case, the non-focal variables in the model matrix are averaged as before. However, for the interacting focal predictors, a combination of each unique levels (or quantiles) are first generated and then the interaction terms are generated by multiplying these combinations. For example, consider model~\ref{eq:simple_inter_higher} above. In the first case, if we consider $x_1$ as the focal predictor, the interaction ($x_2x_3$) is between the non-focal predictors, $x_2$ and $x_3$, the linear predictor is

\begin{align*}
\eta^\star(x_{1i}, \nset{{\bar{x}^\star}}) = \beta_0\mathbf{1} + \beta_1 x_{1i} + \beta_2\bar{x}_2 + \beta_3\bar{x}_3 + \beta_{23}\over{x_2x_3}
\end{align*}
where $x_{1i}$ are the carefully chosen levels of the focal predictor. On the other hand, for the second case, if we consider $x_2$ as the focal predictor, then the interaction ($x_2x_3$) is between focal and non-focal predictor. In this case, the linear predictor is given by

\begin{align*}
\eta^\star(x_{2ij}, \nset{{\bar{x}^\star}}) = \beta_0\mathbf{1} + \beta_1 \bar{x}_1 + \beta_2x_{2ij} + \beta_3x_{3j} + \beta_{23}x_{2ij}x_{3j}
\end{align*}

In general, our formulation, even for more complicated interactions, follow these two basic principles -- interaction between non-focal predictors and interaction between focal and non-focal predictors.


\section*{Uncertainty propagation}

What about the confidence intervals (CI)? The limits of the confidence intervals are points, not mean values. In principle, every value of focal predictor has a different CI. The traditional way to compute variances for predictions is $\sigma^2 = \textrm{Diag}(\bX^\star \Sigma \bX^{\star\top})$ \cite{lenth2018package, fox2009effect}, so that the confidence intervals are $\eta \pm q\sigma$, where $q$ is an appropriate quantile of Normal or t distribution. This approach incorporates all the uncertainties -- including the uncertainty due to non-focal predictors.  But what if we are only interested in the uncertainty as a result of the focal predictor, so that the confidence intervals are $\eta \pm q \sigma_f$? We call this isolated confidence intervals.

Currently, commonly used \proglang{R} packages for constructing predictions do not exclude the uncertainties resulting from the non-focal predictors when computing the CIs. A non-trivial way to exclude uncertainties associated with non-focal predictors in some of these packages is to provide a user defined variance-covariance matrix with the covariances of non-focal terms set to $0$ -- \emph{zeroing-out} variance-covariance matrix. This only works when the input predictors are \emph{centered} prior to model fitting, in case of numerical predictors, and even much complicated when the predictors are categorical. We first describe the variance-covariance based approach and then discuss our proposed method which is based on \emph{centering model matrix} and does not require input predictors to be scaled prior to model fitting.


\subsection*{Variance-covariance}

The computation of $\hat{\eta}^\star$ remains the same as described above. However, to compute $\sigma$, $\Sigma$ is modified by \emph{zeroing-out} (the variance-covariance of all non-focal predictors are set to zero) variances of non-focal terms. Although this is the simplest approach, it requires centering of continuous, i.e., $x_c = x - \bar{x}$, predictors prior to model fitting and proper way to average categorical predictors.

\subsection*{Centered model matrix}

Consider centered model matrix $\bX^{\star}_{c} = \{\bX_f^\star, \nset{{\bX}^\star} - \nset{{\bar{\bX}}^\star}\}$. It follows that the non-focal terms in $\bX^{\star}_{c}$ are all zero in simple models without interactions but are isolated (narrower) around the model center in models involving complex interactions. Consequently the uncertainty due to non-focal predictors are isolated in the computation of $\sigma^2 = \textrm{Diag}(\bX^\star_c \Sigma \bX^{\star\top}_c)$. In addition, the computation of $\bX^{\star}_c$ impacts only on the intercepts and the non-focal terms, i.e., the slopes and variance of the focal predictors are not affected. This means that we can still generate isolated CIs without necessarily centering the predictors prior to model fitting.


\section*{Bias correction}

In many applications, it usually important to report the estimates that reflect the expected values of the untransformed response. However, when dealing with nonlinear link functions, it is even harder to generate correct predictions that reflect the untransformed response due to the bias in the expected mean induced by the nonlinear transformation of the response variable. In such cases, bias correction is needed when back-transforming the predictions to the original scales. Most common approach for bias-adjustment is second-order Taylor approximation \cite{lenth2018package, duursma2003bias}. Another potential source of bias comes from additional non-focal predictors, especially in models with nonlinear link functions. Here, we describe and implement a different approach, population-based approach for bias correction.


\subsection*{Population-based approach for bias correction}

The most precise (although not necessarily accurate!) way to predict is to condition on values of the focal predictor and make predictions for all observations (members of the population) \cite{hanmer2013behind}. A key point is that the nonlinear transformation involved in these computations is always \emph{one-dimensional}; all of the multivariate computations required are at the stage of collapsing the multidimensional set of predictors for some subset of the population to a one-dimensional distribution of $\eta^\star(x_f, \nset{x})$, which is a function of focal predictor and the observed values of the non-focal predictors, as oposed to the definition in Equation~\ref{eq:eta_mean}. More specifically:

\begin{itemize}
\item compute linear predictor associated with the non-focal predictors, $\nset{\eta} = \sum \nset{\beta} \nset{x}$
\item compute linear predictor associated with the focal predictors, $\eta_{jf} = \sum{\beta_f x_{jf}}$
\item for every value of the focal predictor, $\eta_{jf}$:

\begin{align}\label{eq:pop_eta} 
\eta_j^\star(\eta_{jf}, \nset{\eta})  &= \eta_{jf} + \nset{\eta} \nonumber \\
&= \eta_j^\star(x_f, \nset{x})
\end{align}
\end{itemize}

Once Equation~\ref{eq:pop_eta} is computed, one can back-transform the estimates to the original scale and the average over the levels of the focal predictors, $j$:

\begin{align}\label{eq:pop_response} 
\hat{y}_f  &= \textrm{mean} ~ g^{-1} \left(\eta_j^\star(x_f, \nset{x})\right)
\end{align}

We make similar adjustments to compute the variances of the predictions at every level of the focal predictor:

\begin{align}
\sigma_{jf}^2 = \textrm{Diag}(\bX^\star_{jc} \Sigma \bX^{\star\top}_{jc})
\end{align}
where $\bX^{\star}_{jc} = \{\bX_{jf}^\star, \nset{{\bX}^\star} - \nset{{\bar{\bX}}^\star}\}$ and 

\begin{align}
\mathrm{CI}_f = \mathrm{mean} ~ g^{-1} \left(\eta_j^\star(x_f, \nset{x}) \pm q\sigma_{jf}\right)
\end{align}

For models with random effects components, we make further adjustment to correct for bias induced by the random effects terms. In the population approach, we treat the random effects terms as additional non-focal predictors and simply make adjustment to Equation~\ref{eq:pop_eta}. In particular

\begin{align}\label{eq:pop_eta_re} 
\tau &= \bZ b \nonumber \\
\eta_j^\star(x_f, \nset{x}, \tau)  &= \eta_j^\star(x_f, \nset{x}) + \tau
\end{align}
where $\bZ$ and $b$ are the design matrix and a vector of random effects, respectively.

\section*{Mean-anchored vs population-based}

As mentioned above, the two common choices to generate predictor effects are: 1) setting the non-focal predictors to their mean -- mean-anchored; and 2) using the entire population of the non-focal predictors -- population-based. If the link function is nonlinear and/or the model has complex higher order interactions, the average of the predictions evaluated at the mean of the non-focal predictors and the average of predictions evaluated at the population level (and then averaged) of the non-focal predictor are not equivalent, i.e.,

\begin{align}\label{eq:compare_anchored_pop_based}
g^{-1} \left(\eta_j^\star(\bar{x}_f, \nset{\bar{x}})\right) \neq \frac{1}{n} \sum_{i=1}^n{ g^{-1} \left(\eta_j^\star(\bar{x}_f, \nset{x})\right)}.
\end{align}

If $g()$ is strictly concave or strictly convex, one can use Jensen's inequality to determine which side of Equation~\ref{eq:compare_anchored_pop_based} is smaller or larger. However, for non-fully convex or concave link function, one can use Taylor series expansion to approximate the range over which the two are smaller or smaller than the other \cite{hanmer2013behind}. 


As stated above, in simple linear models without interactions, the effect is constant, so both approaches yield similar results. However, picking a single value, e.g., mean of the predictor, on which to draw conclusions about the effect can be problematic, unrealistic or not contained in or representative of the population. In addition, the mean-anchored approach fails to use the every values of the non-focal predictors hence not utilizing the full potential of the information contained in the data. This may limit the inferences we can make about the entire population. In general, the mean-anchored approach provides the predictor effect of an average case, whereas, the population-based approach, summarizes the predictor effect over the entire population -- and in some applications, the effect of an average case might not be generalizable to the entire population, especially, if the average does not represent the population. The population-based focuses on specific observations since the prediction is first obtained for each observation and then averaged across the levels of the focal predictor.

Another potential concern with the mean-anchored approach arises in situations where direct naive use leads to rare or meaningless basis for generalization. For example, setting categorical dummy categorical variables in the model matrix to their means, which, by default, sets them to their sample means or observed proportions. For example, a dummy variable for christian household heads may be set to $0.2$, translating to prediction for an household head who is $20\%$ christian. This problem may extend to models with other complex interaction terms \cite{hanmer2013behind}.

Population-based approach is not entirely foolproof. For instance, similar to the mean-anchored approach, in the case of continuous focal predictors, choosing the representative values of the focal predictors can be very challenging especially if the cases are not evenly distributed around the minimum and the maximum values or within some subgroups defined in the population. In addition, population-based approach can be very computationally intensive for large datasets.

\section*{Simulation examples}

We now illustrate the construction of predictor effects with isolated confidence intervals and also demonstrate that the mean-anchored and population approaches produce different results in models with nonlinear link functions and/or additional source of potential bias. In addition, we demonstrate that population-based approach can be used to correct bias in the predictions.

\subsection*{Isolated confidence intervals}

As mentioned above, in some applications, one may be interested in uncertainties associated with the focal predictor only. In that case, it is important to exclude all the uncertainties as a result of the non-focal predictors and only show confidence intervals describing the predictor of interest. To illustrate this, we consider the simulation model described in \nameref{S1_Appendix}. 

We start by fitting two models from the simulated data, i.e., consider a cubic polynomial predictor, age, as a focal predictor and also, consider the non-polynomial predictor, wealth index as the focal predictor. After fitting the model, we constructed predictor effects and then compared isolated vs non-isolated confidence intervals associated with these predictions (see Fig~\ref{fig:pred_cubic_plots}).

\begin{figure}[!h]
\centering
\includegraphics[width=0.8\textwidth]{pred_cubic_plots-figure4.pdf}
\caption{{\bf Isolated and non-isolated predictor effects $95\%$ confidence bands.} These figures compare the predictor effects together with their corresponding $95\%$ confidence bands. A: The focal predictor is a cubic polynomial. B: The focal predictor is not a polynomial function, implying that the complex interaction is in the non-focal predictor. In both cases, the confidence bands are narrower in the isolated case, and crosses at the mean of the focal predictor (model center) in the case of simple (non-polynomial) focal predictor -- B. In the case of cubic polynomial focal predictor, the model center is not a point in the predictor space, i.e., mean of the focal predictor, but a combination of all the terms in the cubic polynomial, consequently, the isolated bands do not cross at a point -- A. The horizontal black and red dotted lines are the observed and predicted average household size, i.e., $\over{hh~size}$ and $\over{\widehat{hh~size}}$, respectively; the inner red dotted curves and crossing line are the isolated confidence bands for A and B, respectively, while the outer blue curves are the non-isolated confidence bands in both cases. The central curve and trend line, in A and B, respectively, are the predictor effect of age and wealth index on the predicted household size, respectively.}
\label{fig:pred_cubic_plots}
\end{figure}

In the absence of complex higher order interaction terms or transformations on the focal predictor in simple linear models, we would expect, at the model center, the observed average, $\over{hh~size}$, and the average of the predictions, $\over{\widehat{hh~size}}$, to be identical and cross, in the case of isolated confidence bands, at the model center (see Fig~\ref{fig:pred_cubic_plots}B). On the other hand, if the focal predictor is characterized by interactions or any other form of transformation, the model center is not necessarily a point in the predictor space. In this case, the isolated confidence bands will be narrower than the non-isolated but not necessarily crossing at the model center (see Fig~\ref{fig:pred_cubic_plots}A).

\subsection*{Bias correction}

Mean-anchored and population-based approaches can produce very different results in models with nonlinear link functions with additional sources of potential bias such as additional non-focal predictor(s), random effect terms or complex interactions. To demonstrate this, we considered a two predictor binary outcome simulation described in \nameref{S2_Appendix}, such that the age effect is way smaller than that of the wealth index, and compared their predictor effect on the predicted probability of improved water quality as shown in Fig~\ref{fig:pred_bin_plots}. 

\begin{figure}[!h]
\centering
\includegraphics[width=0.8\textwidth]{pred_bin_plots-figure5.pdf}
\caption{{\bf Mean-anchored and population-based predictor effects.} The two approaches produce relatively different predictor effects for each of the predictors but the difference is more pronounced when the effect of the particular focal predictor has no strong effect -- \emph{on the left}. In both cases, age and wealth index effect, the average predicted probability of improved water based on population-based approach is very close to the observed proportion in the simulated data. The horizontal blue, black and the red dotted lines are the average mean-anchored, population-based predicted probability and observed proportion of improved water quality, respectively. The vertical dotted black line represents the mean of the focal predictor, and the point at which it crosses the red dotted line represents the expected ``perfect'' prediction at the model center. The grey points are binned observations -- observed proportions of improved water quality in each bin. We would expect all the curves, horizontal, and vertical lines to cross at the model center but due the nonlinear averaging (at least in the bias corrected population-based approach) of the predictions on the response scale, this may not always be the case.} 
\label{fig:pred_bin_plots}
\end{figure}

If there was no effect of nonlinear averaging, then we would expect the observed proportion and the average of the predicted probabilities to cross at the model center as we see in Fig~\ref{fig:pred_cubic_plots}B. However, the differences we see in Fig~\ref{fig:pred_bin_plots} are due to nonlinear averaging since both observed status and predicted probabilities are averaged on the response scale as opposed to link scale. In particular, if the range of values are bigger than $0.5$ (seemingly the case here), then we would expected the averages to be slightly higher than what we would expect at the model center, and vice versa.

\subsection*{Mediated effect}

Consider the simple indirect mediation simulation described in \nameref{S3_Appendix}. We then fitted two models -- \emph{non-mediated} which models \emph{z} as a function of \emph{x} and the \emph{mediated} which models \emph{z} as a function of both \emph{x} and \emph{y}. In both cases, we compared mean-anchored and the population-based predictions, as shown in Fig~\ref{fig:pred_mediated_plots}.

\begin{figure}[!h]
\centering
\includegraphics[width=0.8\textwidth]{pred_mediated_plots-figure6.pdf}
\caption{{\bf Mean-anchored and population-based predictor effects for mediated effect.} These figures compare the mean-anchored and population-based predictor effect of $x$ from a mediated, $z \sim x + y$, and non-mediated, $z \sim x$, models. A: In the absence of mediator variable, both mean-anchored and population-based approaches predictors are identical since there is no any other additional (non-focal predictors) sources of bias. Consequently, in both approaches, the average predicted probability is very close to the observed proportion. B: When the mediator variable is included, there is no direct effect of $x$ on $z$ and as a result the predictor effect curve does not align with the observations. However, the population-based approach still closely approximates the average proportion in the simulated data. The horizontal blue, black and the red dotted lines are the average mean-anchored, population-based predicted probability and observed proportion, respectively. The vertical dotted black line represents the mean of the focal predictor, and the point at which it crosses the red dotted line represents the expected ``perfect'' prediction at the model center. The grey points are the binned observations.}
\label{fig:pred_mediated_plots}
\end{figure}

From Fig~\ref{fig:pred_mediated_plots}A, we see what we would expect in the absence of additional sources of bias, even though in the simulation, the effect of $x$ on $z$ is mediated through $y$. By ignoring $y$ in the model, we are still able to capture the effect of $x$ and closely match the observed values using both approaches. However, if there were additional non-focal predictors, we would expect to see the differences similar to those in Fig~\ref{fig:pred_bin_plots}. Including both $y$ and $x$ ``dilutes'' the direct effect of $x$ on $y$ and as a result, our prediction do not necessarily match the observed binned observations (see Fig~\ref{fig:pred_mediated_plots}B).

\section*{Discussion}

Our simulations examples majorly focused on simple linear and logistic models due their wide range of usage and application. In addition, these models act as a starting point for building other complex models, including mixed effect models and models with categorical predictors. However, the logic for extension of approaches to more complex models, including other forms of nonlinear link functions is very straightforward. In addition, our \proglang{R} package implementation already extends to and supports most of the nonlinear link functions and mixed model framework, including multivariate binary outcome models.

Although commonly used \proglang{R} software packages, by default, implements mean-anchored approach, our simulation results demonstrated that the population-based approach has a potential of yielding results which are more consistent with the observed data. We would, therefore, argue that the use of mean-anchored approach should have some theoretical justification, especially in complex models. 

\section*{Conclusion}

Generating outcome predictions or predicted probabilities from simple and generalized linear (mixed) models is not only important but also, generating quantities which are consistent with the observed values should be of interest. However, many studies still report coefficient estimates from generalized models like probit, logistic, etc.,\cite{hanmer2013behind}, which are subject of less clarity due to lack of direct link to the outcome of interest.

The argument and results we present in this paper supports a greater need for a shift on focus on what and how to present predictions from generalized models. For example, we believe that isolated confidence intervals could provide more clarity concerning the uncertainty due to the predictor of interests as opposed to the traditional way of incorporating everything. 

From our theoretical, methodological and simulation results, researchers using these kind of models should, in the absence of theoretical justification, report predictions based on population-based approach or at least attempt to do a comparison of the two approaches before settling on the most appropriate in answering their research question. Moreover, we provide \proglang{R} package, \pkg{vareffects}, which implements these methods and is available on github (\href{https://github.com/mac-theobio/effects}{https://github.com/mac-theobio/effects}).

\section*{Supporting information}

% Include only the SI item label in the paragraph heading. Use the \nameref{label} command to cite SI items in the text.
\paragraph*{S1 Appendix.}
\label{S1_Appendix}
{\bf Cubic polynomial interaction simulation.} Consider an hypothetical simulation which simulates household size as a function of household wealth index and cubic function of the age of the household head, specified as follows:

\begin{align}\label{sim:lm_cubic}
\mathrm{hh~size}_i &= \beta_0 + \beta_{\mathrm{A_1}}\mathrm{Age}_i + \beta_{\mathrm{A_2}}\mathrm{Age}^2_i + \beta_{\mathrm{A_3}}\mathrm{Age}^3_i + \beta_{\mathrm{W}}\mathrm{Wealthindex}_i + \epsilon_i \nonumber\\
\mathrm{Age}_i &\sim \mathrm{Normal}(0, 1) \nonumber\\
\mathrm{Wealthindex}_i &\sim \mathrm{Normal}(0, 1) \nonumber\\
\epsilon_i &\sim \mathrm{Normal}(0, 10) \nonumber\\
\beta_0 &= 20 \nonumber\\
\beta_{\mathrm{A}_1} &= 0.1 \nonumber\\
\beta_{\mathrm{A}_2} &= 0.8 \nonumber\\
\beta_{\mathrm{A}_3} &= 0.3 \nonumber\\
\beta_{\mathrm{W}} &= -0.5 \nonumber\\
i &= 1,\cdots, 100
\end{align}


\paragraph*{S2 Appendix.}
\label{S2_Appendix}
{\bf Binary outcome simulation.} Consider a simple simulation for improved water quality in Nairobi slums, such that the status is $1$ for improved and $0$ for unimproved water quality. In additional to the focal predictor, age of the household head, we add wealth index. In particular:

\begin{align}\label{sim:glm_two_pred}
\mathrm{status}_i &\sim \mathrm{Binomial}(1, \mathrm{P(status}_i = 1)) \nonumber\\
\mathrm{logit(P(status}_i = 1)) &= \eta_i \nonumber\\
\mathrm{\eta}_i &= \beta_0 + \beta_{\mathrm{A}}\mathrm{Age}_i + \beta_{\mathrm{W}}\mathrm{Wealthindex}_i \nonumber\\
\mathrm{Age}_i &\sim \mathrm{Normal}(0, 1) \nonumber\\
\mathrm{Wealthindex}_i &\sim \mathrm{Normal}(0, 1) \nonumber\\
\beta_0 &= 5 \nonumber\\
\beta_{\mathrm{A}} &= 0.5 \nonumber\\
\beta_{\mathrm{W}} &= 1.5 \nonumber\\
i &= 1,\cdots, 10000
\end{align}

\paragraph*{S3 Appendix.}
\label{S3_Appendix}
{\bf Mediated effect simulation.} Next, we consider a simple indirect mediation simulation such that $x$ has direct effect on $y$ which in turn has effect on $z$ but $x$ has no direct effect on $y$, i.e., $x \rightarrow y \rightarrow z$. In particular:

\begin{align}\label{sim:simple_mediate}
z_i &\sim \mathrm{Binomial(1, P(z_i = 1))} \nonumber\\
\mathrm{logit(P}(z_i = 1)) &= \eta_i \nonumber\\
\eta_i &= \beta_0 + \beta_{yz} y_i \nonumber\\
y_i &= \beta_{xy} x_i + \epsilon_y \nonumber\\
x_i &\sim \mathrm{Normal(0, 1)} \nonumber\\
\epsilon_y &\sim \mathrm{Normal(0, 1)} \nonumber\\
\beta_0 &= 5 \nonumber\\
\beta_{xy} &= 1 \nonumber\\
\beta_{yz} &= 1.5 \nonumber\\
i &= 1,\cdots, 10000
\end{align}


\section*{Acknowledgments}

This work was supported by a grant to Jonathan Dushoff from the Natural Sciences and Engineering Research Council of Canada (NSERC) Discovery.

\section*{Author Contributions}

\textbf{Conceptualization:} Jonathan Dushoff

\noindent\textbf{Software:} Steve Cygu, Benjamin M. Bolker

\noindent\textbf{Supervision:} Jonathan Dushoff, Benjamin M. Bolker

\noindent\textbf{Writing  original draft:} Steve Cygu




\nolinenumbers

% Either type in your references using
% \begin{thebibliography}{}
% \bibitem{}
% Text
% \end{thebibliography}
%
% or
%
% Compile your BiBTeX database using our plos2015.bst
% style file and paste the contents of your .bbl file
% here. See http://journals.plos.org/plosone/s/latex for 
% step-by-step instructions.
% 

\bibliography{vareffects_plosone}



\end{document}

