%% Main tex

\linenumbers

% Use "Eq" instead of "Equation" for equation citations. 
%% BC: use \EREF{} for equations and \FREF{} for figures
%% JD: Why do you capitalize these? It's scary.
% Best to use a command that combines the name and the reference
\section{Introduction}

Plots of predicted values of an outcome against predictors (often called effect plots or prediction plots) are often a useful way to summarize the results of a regression model. These can be used to illustrate model uncertainty or to give a more explicit quantitative sense of how the outcome is expected to change. In generalized models with a non-linear link function, or models with a spline or polynomial response to a predictor variable, they can also aid in understanding difficult-to-interpret coefficient estimates \citep{brambor_understanding_2006, berry_improving_2012, leeper2017interpreting}. 

To make an outcome plot, we use a \emph{focal} predictor on the x-axis and central estimate (predicted values) on the y-axis. The resulting plot will depend on choices we make about other (non-focal) predictor(s). In ordinary (Gaussian) linear regression, the non-focal choices may have a simple additive effect on the central estimate. However, when the focal predictor has interactions or a non-linear link function, non-focal choices can also affect the slope of the estimate. Additional challenges arise when dealing with “mixed” models, which incorporate random effects.

As noted, the outcome plots described above are often called prediction plots or effects plots. We endeavor here to make a conceptual distinction. 
The primary distinction between the two lies in how we describe the uncertainties around the central estimate. 
If our goal is to \emph{predict} what we learn about the outcome variable by measuring the focal predictor, then we may want to capture a variety of sources of uncertainty, including that due to the intercept, focal and non-focal predictors, and random effects.
Conversely, if we wish to focus on the \emph{effect} of a focal predictor only, we might want to isolate uncertainty due to coefficients associated with that predictor.
If we follow this convention, we expect effects plots to have narrower confidence intervals (CIs) than prediction plots.

The other distinction relates not to the method of calculating CIs, but to the model chosen for the plot. 
In general, if we want to predict based on a focal parameter, we are likely to want to fit a univariate model, that only contains terms related to that predictor.
If we want to know the effects of a predictor, we may want to control for covariates with a multivariate model, in order to estimate “direct” effects, or leave covariates out, in order to estimate “total” effects (direct plus indirect), or take an intermediate strategy.
Shi et al. \citep{shi_evidence_2017} used multivariate effects plots to visualize estimated direct effects of different predictors in a paper that compared the difference in sexual risk behaviors between circumcised and uncircumcised men.

Generating quantities, i.e., central estimate together with the corresponding confidence intervals has some challenges. In particular:
\begin{enumerate}
\item choosing the \emph{reference point} for non-focal predictors in multivariate models
\item uncertainty estimation -- appropriate choice of \emph{anchor} for computing confidence intervals in effects plots
\item \jd{When is this a challenge? Doesn't it just work like magic with the lm machinery? and how to incorporate the uncertainty due to non-focal predictors} \BC{Clarify with JD. Another challenge or a continuation  of the above?} 
\item biases induced by non-linear transformations of the response variable in generalized models (especially generalized mixed models).
\item choice of representative values of the focal predictor \jd{I still don't see this as much of a challenge.} \dya{We needed to mention somewhere that we also have to choose focal values. I think \P~ below is suffecient.}
\end{enumerate}

Representative values for a focal predictor are generally chosen using quantiles, or equally spaced values, for a continuous predictor; or an exhaustive set of levels for a categorical predictor.
The central estimates are then calculated by holding the non-focal predictors at a reference point (a value chosen for a non-focal predictor) while varying the focal predictor, with the goal that the estimates represent how the model responds to the changes in the focal predictor \citep{fox2009effect, hanmer2013behind}. These values have been called: \emph{predictor effects} \citep{fox2009effect}, \emph{marginal predictions} \citep{leeper2017package} or \emph{estimated marginal means} \citep{lenth2018package} \jd{Is this also the same as least-squares means?} \BC{Yes. But was later renamed to emmeans}. In this article, we refer to these quantities as the \emph{central estimates} of the outcome. 

<<<<<<< HEAD
In models with non-focal predictors such as multivariate models, reference point can be chosen as the average of the non-focal \emph{model variables} -- we call this approach \emph{mean-based} reference point and is currently not implemented in commonly used \proglang{R} software packages. The mean of the central estimates is the prediction at the \emph{model center}. We introduce an alternative choice for the reference point below.

For linear models, the averaging is done on the linear scale, i.e., linear averaging. As a result, the \emph{bias} in model center estimates can easily be corrected using mean-based approach and the estimates are usually consistent with the observed values. However, in models with non-linear link functions, this is not always the true. In particular, when dealing with generalized models with non-linear link functions, the averaging is done on the non-linear scale, i.e., non-linear averaging, making generating correct predictions much harder. This is the bias in the expected mean prediction induced by the non-linear transformation of the response variable. One way to address this is to make predictions on the linear predictor scale and back-transform to the original scale. However, the back-transformation may either result in biased predictions or requires some approximation, for example, second-order Taylor approximation implemented in \pkg{emmeans} \citep{lenth2018package}. An alternative to the mean-based reference point is the \emph{whole-sample-based} approach, discussed in detail later, which involves computing the prediction over the population of non-focal predictors and then averaging across the values of the focal predictor \citep{hanmer2013behind}. 

This article aims to discuss and implement various approaches for computing predictions and effects, together with the associated plots. We further explore and demonstrate, using simulated data, approaches for correcting bias in central estimates for generalized (mixed) models involving non-linear link functions. The proposed method and \proglang{R} software package will complement the existing ones by providing: 1) a straightforward way to generate effects, and 2) an alternative and a more robust way to correct for prediction bias in generalized (mixed) models.

\jd{We should revisit this list.}

\section{Definitions}

In order to discuss the statistical background and mathematical formulation of the proposed approaches, we need to understand and formally define a number of terms, some of which have been introduced in the previous section:

\jd{I guess this list should really be a desc, not an itemize.}\BC{Clarify}

\begin{itemize}
\item \textbf{Input variables:} Refers to the observed (or scientific) variables underlying an inference or exploration. For example, the regression models described by \EREF{simple_inter_higher_no_interaction} and \EREF{simple_inter_higher} both have $3$ input variables -- $x_1, x_2, x_3$.
\item \textbf{Focal predictors}: We call the input variable on the x-axis of an outcome plot the focal predictor.  Any other predictor variables are ``non-focal'' predictors. 

\item \textbf{Model matrix:} Refers to the design matrix whose rows include all combination of input variables. Consider an example for three hypothetical households -- the first household head is a Christian with an income of $\$ 50$, the second household head is Muslim with an income of $\$ 100$ while the third household head is a Jew with an income of $\$ 77$. Suppose we want to model the household size (\code{hhsize}) as function of these household characteristics, i.e., $$\mathrm{hhsize} = \beta_0 + \beta_1\times\mathrm{income} + \beta_{2[r]}\times\mathrm{religion} + \mathrm{error}.$$ The model matrix corresponding to this model is given by
$$\begin{bmatrix}{}
 Intercept & income & religionJew & religionMuslim \\
 1 & 50 & 0 & 0 \\
  1 & 100 & 0 & 1 \\
  1 & 77 & 1 & 0 \\
\end{bmatrix}.$$ The first column represents the constant term in our model, $\beta_0$. For continuous input variables, the representation in the model matrix is the same as the corresponding input variables (for example second column representing income). For categorical variables, however, by default, the model matrix  creates additional dummy variables using the reference cell parameterization. This means that, if an input variable has $L$ factor levels, then there will be $L-1$ dummy columns representing all but the first level created in the model matrix. In our example, the column \code{religion} is missing and instead we have \code{religionJew} and \code{religionMuslim}; the missing category \code{religionChristian} is treated as the reference category.

\item \textbf{Linear predictor variables}: Refer to the variables which are combined to make the linear predictor (corresponding to the columns in the model matrix). Each input variable may correspond to one or more model variable. Input variables with more than two categories (for instance religion in our previous example), or input variables with non-linear response functions (e.g., spline or polynomial) will correspond to more than one linear predictor variable -- we call such variables “multi-parameter variables”.

\item \textbf{Model center:} A point corresponding to a column-wise mean of the model matrix (the mean of one or more model variables). Also referred to as center point. The center point for a set of model variables corresponding to an input variable may not represent a possible value of the input variable -- the case in \FREF{justify_plots}B. In simple linear models with no interactions, the mean of the input variable can be used is a center point. If there are more than one model variables associated with the focal input variable, however, the model center does not correspond to a single value of the focal predictor, see \FREF{pred_cubic_plots}.


\item \textbf{Reference point:} The values (or sets of values) chosen for non-focal predictors, when estimating the predictions and effects. Typically the center point, but can also be chosen as a baseline value or as a mean across categories. We will also discuss using a set of quantiles or observations as a reference.

\item \textbf{Anchor:} The value chosen for the focal predictor when estimating effect-style confidence intervals. The anchor choice does not affect the central estimates, nor prediction-style. Often chosen as the center point of the linear predictor variables corresponding to the focal predictor. 

\item \textbf{Prediction-style and effect-style plots:} A prediction-style plot is about predicting observations for a given value of the focal predictor. For this, we want to use the classic curved confidence intervals. An effect-style plot attempts to visualize the effect of a focal predictor and are characterized with narrower confidence intervals. Unlike a prediction-style plot, where the confidence intervals capture the uncertainty associated all predictors in the model, the effect-style plot focuses on uncertainty associated with the focal predictor only and depend on the anchor.

\end{itemize}

\section{Statistical background}

\jd{This should be more general. The natural way to do the comparison is to first write out the two ways of averaging, and then point out that they're the same when $g$ is the identity. In other words, do the general derivation before making the assumption. It doesn't ever seem good to write $g$ and then \emph{define} it as the identity.}

\BC{Trying to adopt new notation style, is this better?}

To estimate the central estimate of an outcome plot on the response scale, we need a link function $g$ and appropriate values of the focal predictor $\bX^{f}$ and reference point for the non-focal predictors $\uset{{\bX}}$. As previously mentioned, we can either use mean-based or whole-sample-based reference point. 

Using mean-based reference point, the central estimate is
%
\begin{align}\label{eq:eta_linear_mean}
\hat{\boldeta}^\star &= \bbetah \bX^{f}_c \nonumber\\
\hat{y}_f &= g^{-1}(\hat{\boldeta}^\star)
\end{align}
%
where $\bX^{f}_c = \{\bX^{f}, \uset{{\bX}}_c\}$ is a centered model matrix and $\uset{{\bX}}_c$ is a matrix constructed by averaging the linear predictor variables. 

On the other hand, using whole-sample-based reference point, \EREF{eta_linear_mean}
becomes
%
\begin{align}\label{eq:eta_linear_sample}
\hat{\boldeta}^\star_j &= \bbetah \bX^{f}_j \nonumber\\
\hat{y}_f  &= \underset{f}{\textrm{mean}} ~ g^{-1} (\hat{\boldeta}^\star_j)
\end{align}
%
where $\bX^{f}_j = \{\bX^{f}_j, \uset{{\bX}}\}$ is the model matrix of the $j$th
observation and $\uset{{\bX}}$ is the entire population of the non-focal linear
predictors. Here, we generate $J \times N$ values and then average over the value of the focal predictor; $J$ and $N$ represents the number of focal values and population of non-focal predictors, respectively.

For identity link function, e.g., in a simple linear model, \EREF{eta_linear_mean} and \EREF{eta_linear_sample} are equivalent. We start by discussing mean-based approach. An alternative formulation of \EREF{eta_linear_mean} involves expressing the linear predictor as the sum of the focal and non-focal predictors' linear predictors. In particular, 
%
\begin{align}\label{eq:eta_mean}
\eta^\star(x^f, \uset{{\bar{x}}}) &= \hat{\beta}^f x^f + \sum \uset{\hat{\beta}} \uset{{\bar{x}}} \\
\hat{y}_f  &= g^{-1} \left(\eta^\star(x^f, \uset{{\bar{x}}})\right)
\end{align}
where $x^f$ and $\uset{{\bar{x}}}$ are columns of $\bX^{f}_c$ focal predictor and non-focal predictors, respectively.

%%$\Sigma = V(\bbetah)$

\subsection{Dealing with multi-parameter variables}

\jd{I feel the first s.~is perfectly clear, and I don't know why it needs any explanation at all.}
Multi-parameter variables (MPVs) such as splines, polynomials, etc., can be within the focal predictor, or within non-focal predictor(s). To distinguish the two, suppose the model which describes the hypothetical simulation of household size based on a number of socio-demographic factors such as age and wealth index is
%
\begin{align}\label{eq:lm_cubic}
\mathrm{hh~size}_i &= \beta_0 + \beta_{\mathrm{A_1}}\mathrm{Age}_i + \beta_{\mathrm{A_2}}\mathrm{Age}^2_i + \beta_{\mathrm{A_3}}\mathrm{Age}^3_i\nonumber \\
&+ \beta_{\mathrm{W}}\mathrm{Wealthindex}_i + \epsilon_i.
\end{align}
%
In the first case, with \code{Age} as the focal predictor, is a cubic polynomial with three linear predictor variables ($\mathrm{Age}_i, \mathrm{Age}^2_i$ and $\mathrm{Age}^3_i$). In this case, each linear predictor variable is evaluated separately across the chosen levels of the focal predictor, $Age_i$. Specifically, the linear predictor variables are treated as additional columns of the model matrix evaluated with the same values chosen for the focal predictor, while non-focal predictors are fixed at their reference point as discussed in the previous section. The central estimates associated with \code{Age} on the linear predictor scale become
%
\begin{align}
\eta^\star(\mathrm{Age}_i, \nset{{\over{\mathrm{Wealthindex}}}}) &= \beta_0 + \beta_{\mathrm{A_1}}\mathrm{Age}_i + \beta_{\mathrm{A_2}}\mathrm{Age}^2_i + \beta_{\mathrm{A_3}}\mathrm{Age}^3_i \nonumber\\
	& + \beta_{\mathrm{W}}\over{\mathrm{Wealthindex}}.
\end{align}
%
In the second case, with \code{Wealthindex} as the focal predictor, the non-focal predictor, \code{Age}, is a cubic polynomial. In this case, the non-focal linear predictor variables ($\mathrm{Age}_i, \mathrm{Age}^2_i$ and $\mathrm{Age}^3_i$) are all treated as separate non-focal linear predictor variables and an appropriate choice of reference point applies just like in the models without MPVs. For instance, in mean-based approach, we average all non-focal MPVs. Thus
%
\begin{align}
\eta^\star(\mathrm{Wealthindex}_i, \nset{{\{\over{\mathrm{Age\mathop{\vphantom{^2}}}}, \over{\mathrm{Age}^2}, \over{\mathrm{Age}^2}\}}}) &= \beta_0 + \beta_{\mathrm{A_1}}\over{\mathrm{Age\mathop{\vphantom{^2}}}} + \beta_{\mathrm{A_2}}\over{\mathrm{Age}^2} + \beta_{\mathrm{A_3}}\over{\mathrm{Age}^3}\nonumber\\
	& + \beta_{\mathrm{W}}\mathrm{Wealthindex}_i.
\end{align}
%

\jd{Why is this under MPV as a subhead? Why “also”? Do we discuss non-focal interaction?} We could also have interactions between focal and non-focal predictors. To illustrate, we consider simple input variables but the logic extends to more complex ones like MPVs. Consider model described by \EREF{simple_inter_higher}, \jd{This is referring back to the definition list, which is a strange place to put examples} used to demonstrate how to handle interactions in non-focal predictors. Here, we use it to demonstrate how to handle interactions between the focal, $x_2$, and non-focal, $x_3$, predictors. In this case, the non-interacting predictors are treated as non-focal linear predictor variables, with appropriate choice of reference points \jd{What is the point of saying this again? AFAICT this s.~says if we have a non-interacting predictor we treat it as a non-interacting predictor as already described Can we delete?}. However, for the interacting linear predictor variables, we first choose representative values for the focal predictor and then some particular values of the interacting non-focal predictors in a similar way we choose the values of the focal predictor or use predetermined values. In our example, suppose we pick $i$ and $j$ unique values of the focal predictor, $x_2$ and interacting non-focal predictor, $x_3$, respectively. The central estimate on linear predictor scale is given by
%
\begin{align*}
\eta^\star(x_{2i}, x_{3j}, {\bar{x}^\star_1}) = \beta_0 + \beta_1 \bar{x}^\star_1 + \beta_2x_{2i} + \beta_3x_{3j} + \beta_{23}x_{2i}x_{3j}.
\end{align*}
%
\jd{I don't understand how this part fits in at all. Obviously in theory we could pick values of any non-focal predictor, but what's actually going on here? What's the actual difference between how we pick reference values for interacting vs.~non-interacting non-focal predictors?}

\section{Uncertainty estimation}

We describe the uncertainty around the estimates using confidence intervals (CIs). In principle, every prediction has a different CI. The conventional way to compute variances for predictions is 
%
\begin{align}\label{eq:conventional_variance}
\boldsymbol\sigma^2 = \mathrm{Diag}(\bX^\star \boldsymbol{\Sigma} \bX^{\star\top}), 
\end{align}
\jd{I don't understand how a scalar ($\sigma^2$) is equal to a vector (the $\mathrm{Diag}$). Is there a citation for this formula?}
so that the confidence intervals are $\boldeta \pm q\boldsymbol\sigma$, where $q$ is an appropriate quantile of Normal or t distribution \citep{lenth2018package, fox2009effect}. This generates conventional CIs which incorporate all the uncertainties -- including the uncertainties due to the intercept and non-focal predictor.  But what if we are interested in the uncertainty as a result of the focal predictor only, so that the CIs are $\boldeta \pm q \boldsymbol \sigma_f$, i.e., effects? 

\jd{Haven't we already discussed this idea? The new sentence reads like we didn't. We should start by saying what we want, then continue by explaining that there is an equivalent calculation (is it always equivalent?) that can be done in the packages.}
\NEW{We may be interested in the uncertainties associated with the focal predictor only, excluding other uncertainties due to other non-focal predictors -- effects. However, commonly used \proglang{R} packages for constructing predictions do not exclude the uncertainties resulting from non focal predictors when computing the CIs.} Currently obscure way to exclude uncertainties associated with non-focal predictors in some of these packages is to provide a user defined variance-covariance matrix with the covariances of non-focal predictors set to $0$. We refer to this procedure as \emph{zeroing-out} variance-covariance matrix; and only works when the input variables are \emph{centered} prior to model fitting, in case of numerical variables, and more complicated when the input variables are categorical. An alternative is our proposed approach which uses the model center and does not require the input variables to be centered prior to model fitting.

\jd{You explain it like the 0 variance at the center is the point. The point is to look at the effect of changing the focal parameter from the anchor value; the 0 variance at the anchor value is a corollary. You should start by explaining why something like \EREF{centered_variance} is what you want, and then explain the zero variance.}
\jd{The explanation of \bxo is not clear. I guess you mean that the values for everything except for the focal columns are centered? What is the point of defining \bxo\ and then defining \bafc\ so that it exactly cancels? Is it better to just define a matrix with zeroes in all the right places?}
Let $\bxo$ be a centered model matrix previously defined, and let $\ba$ be an anchor matrix, with the same dimensions and entries in all non-focal predictors as $\bxo$. Let $\baf$ be the column of $\ba$ corresponding to focal predictor(s) defined in $\bxo$. Any appropriate values can be chosen for $\baf$ but for model center (center-anchored), we use $\bafc$ which is the mean of the focal predictor(s). Thus 
%
\begin{align}\label{eq:centered_variance}
\boldsymbol\sigma_f^2 = \textrm{Diag}((\bxo - \bafc) \boldsymbol{\Sigma} (\bxo - \bafc)^\top).
\end{align}
%
We can see that $\forall ~\bxof=\baf$, $\bxo - \baf = \boldsymbol 0$, hence $\boldsymbol\sigma_f^2 = \boldsymbol{0}$. Similarly, for all values of $\bxof$ close to anchor point $\bafc$, the term $(\bxo - \bafc)$ and $\boldsymbol\sigma_f^2$ goes to $\boldsymbol 0$ and $\boldsymbol\sigma_f^2 = \boldsymbol 0$ if $\bxof=\bafc$. This means that $\boldsymbol\sigma_f^2$ close to the anchor point are smaller than those away from the anchor point; and results to confidence intervals which are narrower around the anchor or crosses at the anchor point for simple models. This is the effect of the particular focal predictor. By setting $\baf = \boldsymbol 0$, we get the variances for the conventional CIs in \EREF{conventional_variance}.


The computation of $\bxo - \bafc$ impacts only on the intercepts and non-focal predictors, i.e., the slopes and variance corresponding to the focal predictors are not affected. This means that we can still generate effects without necessarily centering the predictors prior to model fitting. \jd{What is the point of this s.? What does it mean “impacts only on”?}

%% \subsection{Is center-anchored better?}
%% 
%% We want to compare the amount of uncertainty when there is/no anchor. Let $\bao = \boldsymbol{0}$ be the anchoring matrix with all entries in $0$s, and let $\bafc$ be the center-anchored matrix defined above. Then entries in $(\bxo - \bao) \geq (\bxo - \bafc)$.
%%

\section{Bias correction}

\jd{Why at the model center? Aren't we interested in comparisons at the reference point for any value of the focal variable?}
We can directly compare the outcome estimate at the model center (mean-based estimate) with the average of predictions evaluated across the population values of non-focal predictors (sample-based estimate):

\begin{align}\label{eq:compare_anchored_pop_based}
g^{-1} \left(\eta_j^\star(\bar{x}_f, \nset{\bar{x}})\right) : \frac{1}{n} \sum_{i=1}^n{ g^{-1} \left(\eta_j^\star(\bar{x}_f, \nset{x})\right)}.
\end{align}

In an ordinary linear model, the link function $g$ is the identity function, so the two means are the same. For non-trivial link functions, we expect them to be different in general -- \NEW{a consequent of Jensen inequality \citep{duursma_bias_2003, denny_performance_2019, ye_generalized_2021} \jd{Drop this claim; it's obvious we expect them to be different, Jensen is just about the sign}. In GL(M)Ms the assumed link function, predetermines the curvature of the response surface and also the sign of the Jensen effect. For example, logistic model has a positive curvature if the predicted probabilities are low and negative curvature if the predicted probabilities are high. In other words, logistic model may be concave or convex depending on the predicted probabilities, hence the sign of the Jensen effect is not readily available. However, in log link functions, the inverse of the link (exponential) function is strictly convex, i.e., an accelerating function. For accelerating functions, the Jensen’s inequality describes how the changes in input values elevate the predictions and otherwise describes how these changes depress the predictions. Further, our models may include input variables and/or random effects terms other than the focal one. In non-trivial link functions, the Jensen effect may depend on the additional input variables \citep{ye_generalized_2021}}.
\jd{I think I asked you to describe how Jensen is working in these cases. In each of the cases it would be both easier and clearer to say whether we expect the left side or the right side to be larger than to spin all of those words about “describes how the changes in input values elevate the predictions and otherwise describes how these changes depress the predictions”.}

\NEW{It is usually important to report the estimates that reflect the expected values of the untransformed response \jd{Hard to understand this s.}. This is not a major issue in simple linear models \jd{What do you mean by major issue? In what sense is it an issue? In what sense does it exist?}. However, when dealing with nonlinear link functions,  generated predictions may not reflect the observed response due to the bias in the expected mean induced by the nonlinear transformation of the response variable -- a consequent of Jensen effect mentioned above. In such cases, bias correction is needed to back-transform the predictions to the original scales. The common approach for bias-adjustment is second-order Taylor approximation \citep{duursma2003bias, hanmer2013behind}; already implemented in \pkg{emmeans} \citep{lenth2018package}. Here, we describe and implement a different approach -- whole-sample-based approach for bias correction. Hanmer and Kalkan \citep{hanmer2013behind} introduced mean- and whole-sample- based approaches but limited their discussion to binary response models only.} 
\jd{We mostly talk about binary-response models as well. Also, they did not introduce (there are much older citations to it, and they use a different name, which we should mention (or maybe adopt).}

\subsection{Whole-sample-based approach for bias correction}

An alternative approach to choosing a reference point is to make predictions over all observations of the non-focal predictors (members of the population) \citep{hanmer2013behind}. The nonlinear transformation involved in these computations is always \emph{one-dimensional}; all of the multivariate computations required are at the stage of collapsing the multidimensional set of predictors for some subset of the population to a one-dimensional distribution of $\eta^\star(x_f, \nset{x})$, which is a function of the chosen values of the focal predictor and the whole sample of non-focal predictors, as opposed to the definition in \EREF{eta_mean}. More specifically:
\begin{itemize}
\item compute linear predictor associated with whole sample of the non-focal predictors, $\nset{\eta} = \sum \nset{\beta} \nset{x}$
\item compute linear predictor associated with the chosen values focal predictor, $\eta_{jf} = \sum{\beta_f x_{jf}}$
\item for every value of the focal linear predictor, $\eta_{jf}$, compute
%
\begin{align}\label{eq:pop_eta} 
\eta_j^\star(\eta_{jf}, \nset{\eta})  &= \eta_{jf} + \nset{\eta} \nonumber \\
&= \eta_j^\star(x_f, \nset{x}).
\end{align}
\end{itemize}
%

Once \EREF{pop_eta} is computed, we back-transform the estimates to the original scale and average over the levels of the focal predictors, $j$:
%
\begin{align}\label{eq:pop_response} 
\hat{y}_f  &= \textrm{mean} ~ g^{-1} \left(\eta_j^\star(x_f, \nset{x})\right).
\end{align}
%

We make similar adjustments to compute the variances of the predictions at every level of the focal predictor:
%
\begin{align}
\sigma_{jf}^2 = \textrm{Diag}(\bX^\star_{jc} \boldsymbol{\Sigma} \bX^{\star\top}_{jc})
\end{align}
where $\bX^{\star}_{jc} = \{\bX_{jf}^\star, \nset{{\bX}^\star} - \nset{{\bar{\bX}}^\star}\}$ and 
%
\begin{align}
\mathrm{CI}_f = \mathrm{mean} ~ g^{-1} \left(\eta_j^\star(x_f, \nset{x}) \pm q\sigma_{jf}\right).
\end{align}
%

For models with random effects components, we make further adjustment to correct for bias induced by the random effects terms. In whole-sample approach, we treat the random effects terms as additional non-focal predictors and simply make adjustment to \EREF{pop_eta}. In particular
%
\begin{align}\label{eq:pop_eta_re} 
\tau &= \bZ b \nonumber \\
\eta_j^\star(x_f, \nset{x}, \tau)  &= \eta_j^\star(x_f, \nset{x}) + \tau
\end{align}
where $\bZ$ and $b$ are the design matrix and a vector of random effects, respectively.

\section{Mean-based vs. whole-sample-based}

In the whole-sample-based approach, the ensemble of predictions and CIs are back-transformed before averaging, see \EREF{pop_response}, so we do not need to worry about the nonlinear averaging. In other words, the averaging is no longer on the link scale and is likely to be bounded by the original data scale. In simple linear models without interactions, averaging on the link scale is identical to averaging on the response, so both approaches yield similar results. However, picking a single value, e.g., the mean of the predictor, on which to draw conclusions about the effect can be problematic, unrealistic, or not contained in or representative of the population. In addition, the mean-based approach fails to use every value of non-focal predictors hence not utilizing the full potential of the information contained in the data. This may limit the inferences we can make about the entire population. In general, the mean-based approach provides the predictions of an average case, whereas the whole-sample-based approach summarizes the predictions over the entire population. In some applications, the effect of an average case might not be generalizable to the entire population, especially, if the average does not represent the population. This might not be a problem in the whole-sample-based approach since it focuses on specific observations -- the prediction is first obtained for each observation and then averaged across the levels of the focal predictor.

Another potential concern with the mean-based approach arises when direct naive use leads to a rare or meaningless basis for generalization. For example, if our sample has 20\% Jews, 30\% Muslims, and 50\% Christians. One approach (default in common packages) is assigning equal category weight, i.e., 1/3 Jews, 1/3 Muslims, and 1/3 Christians (the ``sum-to-zero'' approach). The second approach (our default) is setting dummy categorical variables in the model matrix to their means, which, by default, set them to their sample means or observed proportions. The first or second approach translates to prediction for a household head who is 1/3 or 50\% Christian, respectively \citep{hanmer2013behind}. The second approach seems more realistic and will converge to the population mean in many cases.

The whole-sample-based approach is not entirely foolproof. For instance, similar to the mean-based approach, in the case of continuous focal predictors, choosing the representative values of the focal predictors can be very challenging, especially if the cases are not evenly distributed around the minimum and the maximum values or within some subgroups defined in the population. In addition, the whole-sample-based approach can be computationally intensive for large datasets.



\section{Simulation examples}

We start by comparing our proposed approach with the existing implementations and then illustrate the construction of outcome plots and also demonstrate that the mean-based and whole-sample-based approaches produce different results in models with nonlinear link functions and/or additional source(s) of potential bias. In addition, we demonstrate that whole-sample-based approach can be used for bias correction.

\subsection{Comparison with other implementations}

The most commonly used \proglang{R} software packages for outcome plots (\pkg{emmeans} and \pkg{effects}), by default, use the average of input variables and ``sum-to-zero'' as the reference point approach for continuous and categorical input variables, respectively. However, there are a number of choices one can make when constructing outcome plots -- for example, in the presence of interactions, averaging the interactions (averaging the product of linear predictor variables) versus taking the product of the averages of the input variables (the default for \pkg{emmeans} and \pkg{effects}). For simple OLS models (with no interactions), the two approaches give the same estimates. However, for complex models, we demonstrate that the two approaches can produce substantially different results and show that averaging the interactions closely matches the observed values. To illustrate this, consider models~\ref{eq:simple_inter_higher_no_interaction} and \ref{eq:simple_inter_higher} below, with $x_1$ as the focal predictor:
%
\begin{align}
y &= \beta_0 + \beta_1x_1 + \beta_2x_2 + \beta_3x_3 + \epsilon \label{eq:simple_inter_higher_no_interaction}\\
y &= \beta_0 + \beta_1x_1 + \beta_2x_2 + \beta_3x_3 + \beta_{23}x_2x_3 + \epsilon \label{eq:simple_inter_higher}.
\end{align}
%
We first simulate data with the two models, such that $x_{1,2,3} \sim \mathrm{Normal}(0, 1)$, $\beta_0 = 5$, $\beta_1 = -3$, $\beta_2 = 1$, $\beta_3 = 2$, $\beta_{23} = 5$, $\epsilon \sim \mathrm{Normal}(0, \sigma^2)$ and $\sigma^2 = 1$, and then compare estimates from the \pkg{emmeans}, \pkg{effects} and our proposed alternative (\pkg{varpred}) to the ``true'' central estimates (based on the true simulation parameters) and observed average, i.e., $\bar{y}$, as shown in \FREF{justify_plots}.
%
\begin{figure}
\begin{center}
\includegraphics{justify_preds.inter.pdf}
\end{center}
\caption{{\bf A comparison of \pkg{emmeans}, \pkg{effects} and \pkg{varpred} central estimates for regression of $x_1$ on $y$ (outcome plots).} The horizontal dashed lines are the mean of the central estimates and simulated $y$, $\bar{\hat{y}}$ and $\bar{y}$, respectively. The grey points are the binned simulated $y$. The trend lines represent the corresponding $\hat{y}$ at various levels of $x_1$, while holding the other input variables at their mean and the true predictions based on the simulation parameters -- central estimate. A: In the absence of interaction, the predicted mean, $\bar{\hat{y}}$, closely matches the simulated one in all the three approaches, i.e., $\bar{y} \approx \bar{\hat{y}}$. Similarly, the central estimate based on the three approaches match the truth. B: Even with the simple interaction between non-focal predictors, we see differences between predicted mean, $\bar{\hat{y}}$ and simulated mean , $\bar{y}$. Similarly, there are differences between central estimates and the truth, in two commonly used packages (\pkg{emmeans} and \pkg{effects}), but not the proposed \pkg{varpred}.}
\label{fig:justify_plots}
\end{figure}
%
In the absence of interactions (\EREF{simple_inter_higher_no_interaction}), the three approaches produce the same estimates, which match the simulated values, \FREF{justify_plots}A. However, in the presence of interactions, even as simple as the one in \EREF{simple_inter_higher}, the estimates start to differ. In particular, \pkg{emmeans} and \pkg{effects} have similar estimates ($\bar{\hat{y}}$) but different from the \pkg{varpred}'s which, however, is very close to the simulated average ($\bar{y}$), \FREF{justify_plots}B. To generate \FREF{justify_plots}A,  \pkg{emmeans} and \pkg{effects} average $x_2$ and $x_3$, i.e., the input variables while \pkg{varpred} averages the linear predictor variables corresponding to $x_2$ and $x_3$. On other hand, to generate \FREF{justify_plots}B, the difference in the estimates lies on how each of the packages average the interaction linear predictor variable ($x_2x_3$). In particular, \pkg{emmeans} and \pkg{effects} use input variables to compute $\bar{x_2}\bar{x_3}$ while \pkg{varpred} uses linear predictor variables to compute $\over{x_2x_3}$. In the case of \FREF{justify_plots}A, averaging the input variables is equivalent to averaging the linear predictor variables.

One may be interested in the uncertainties associated with the focal predictor only, excluding other uncertainties due to other non-focal predictors -- effect plots. However, as previously mentioned, the two packages do not provide a straightforward way do achieve this. To illustrate this, we consider \EREF{simple_inter_higher_no_interaction} and use $x_2$ as the focal predictor, and generate the outcome plot shown in \FREF{justify_ci_plots}. 
%
\begin{figure}
\begin{center}
\includegraphics{justify_anchors_all.ggp.pdf}
\end{center}
\caption{{\bf Prediction and effect plots.} The description of horizontal, vertical and trend lines remain the same as above. A: The wider dashed curves corresponds to the conventional prediction curves from \pkg{emmeans} and \pkg{effects} packages, while the narrower curves crossing at the mean of the focal predictor, also referred to as the center point, represent the effect from \pkg{varpred}. For simple OLS models, the effect-styled curves cross at the center point (which is the default anchor and also referred to as center-anchored). The prediction-styled curves incorporates not only the uncertainties due to intercept term but also other non-focal predictors. On the other hand, effect-styled curves only take into account the main effect uncertainty of the focal predictor. B: center- and zero- anchored effects. The center-anchored effects (as described above) while the zero-anchored means that the anchor is at zero value of the focal predictor. The choice of the anchor do not affect the central estimates, hence they are identical in both choices of the anchor.}
\label{fig:justify_ci_plots}
\end{figure}
%
For \pkg{emmeans} and \pkg{effects}, the confidence intervals are much wider because they include uncertainties associated with the intercept and non-focal predictors, but narrower and crosses at the mean of the focal predictor in \pkg{varpred}. In other words, with \pkg{varpred}, we are able to generate effects indicating zero uncertainty at the value of the focal predictor we are more certain about, i.e., the anchor. For simple OLS models, the point where the curves cross is the model center or simply center point; it corresponds to anchor we choose, in this case, the center point (which is generally an appropriate and stable choice). 

Lastly, we compare effect plots and the marginal effects \citep{leeper2017interpreting} plots implemented in package \pkg{margins} \citep{lenth2018package}. To illustrate this, we use the simulated data described in \nameref{S1_Appendix}. The results are shown in \FREF{qoi_age_pred_plot}.
%
\begin{figure}
\centering
\includegraphics{cubic_varpred_margins_pred.ggp.pdf}
\caption{{\bf Effect and marginal effect plots.} \NEW{A:  The effect plot. B: The marginal effect (ME) at representative values of the focal predictor \code{age} together with the $95\%$ confidence intervals. For simple linear models with no interactions, the ME should be constant across all the values of the focal predictor; and it would correspond to the slope of the central estimate of central estimate. However, in this example, the focal predictor is a cubic polynomial, and so, the effect is not constant but a function of the partial derivatives of the corresponding linear predictor variables.}}
\label{fig:qoi_age_pred_plot}
\end{figure}
%


\subsection{Prediction and effect styled plots for MPVs}

To illustrate the distinction between predictions and effects in MPVs, we simulated a multivariate model described in \nameref{S1_Appendix}. We also used the same model to illustrate how predictions and effects differ if MPVs are in the focal or non-focal predictor. In particular, we generated two sets of mean-based predictions and effects: 1) one with \code{age} as the focal predictor (a cubic polynomial focal input variable); and 2) one with \code{Wealthindex} as the focal predictor (linear focal input variable). In both cases the, we used center point as the anchor for the effects, as shown in \FREF{pred_cubic_plots}.

\begin{figure}
\begin{center}
\includegraphics{cubic_predictors_preds.ggp.pdf}
\end{center}
\caption{{\bf Prediction and effect plots for cubic polynomial and simple focal predictors.} A: The focal predictor is a MPV cubic polynomial. B: The focal input variable is linear, with MPV non-focal predictor. The central estimates (dashed central curves or lines) are the same for predictions and effects, in each case (A and B). However, the effects are narrower than the predictions. The default anchor for generating effects is the center point. For linear (or simple) focal input variables, the center point is a point within the range of focal values; and therefore the effect curves intersect at that that point -- B. In the case of MPVs such as cubic polynomials, the center point is not a point but a combination of all the linear predictor variables associated with the cubic polynomial, consequently, curves will not necessarily cross at a point -- A. The horizontal black and red dashed lines are the observed and predicted average household size, i.e., $\over{hh~size}$ and $\over{\widehat{hh~size}}$, respectively.}
\label{fig:pred_cubic_plots}
\end{figure}

In the absence of, complex interactions, MPVs, or transformations on the focal input variable, in simple OLS models we would expect the observed average, $\over{hh~size}$, and the average of the predictions, $\over{\widehat{hh~size}}$, to be identical and intersect with the trend lines at the center point, for the effect plot. On the other hand, if the focal input variable is characterized by complex interactions, MPVs, or any other form of transformations, the center point is not necessarily a point in the range of focal input values. In this case, the effects will be narrower than the predictions plots but will not necessarily intersect. 


\subsection{Bias correction}

Mean-based and whole-sample-based approaches can produce very different results in models with nonlinear link functions with additional sources of potential bias such as additional non-focal input variable(s), random effects or complex interactions. To demonstrate this, we considered a two predictor binary outcome simulation described in \nameref{S2_Appendix}, such that age has a very small effect size in comparison to wealth index, and compared their effects on the estimated probability of improved water quality as shown in \FREF{pred_bin_plots}. 

\begin{figure}
\begin{center}
\includegraphics{glm_two_predictor_preds.ggp.pdf}
\end{center}
\caption{{\bf Mean-based and whole-sample-based central estimates.} The \emph{truth} is based on the true simulation parameters. If the focal predictor has a small effect size, mean-based and whole-sample-based approaches produce different estimates -- A. In the case of strong effect size, however, the two approaches produce very close estimates -- B. In both cases, the whole-sample-based estimates are closer to the truth. The difference in mean-based and whole-sample-based is due to the bias induced by the non-focal predictor and the nonlinear link function in the logistic model. Mean-based approach suffers from nonlinear averaging; and if focal predictor has small effect size, the bias is even pronounced since the effect of nonlinear averaging is driven by the non-focal predictor(s) with the strong effect. However, this is not the case if the non-focal predictor(s) have small effect since the bias they induce is equally likely to be small. Since whole-sample-based approach averages over the whole population of the non-focal predictor variables, it is less likely to be affected by the nonlinear averaging for the reasons already mentioned. The horizontal dashed lines correspond to the respective averages. The vertical dashed lines represent the center point, and the point at which they intersect the horizontal lines represents the expected ``perfect'' estimate at the model center. The grey points are binned observations -- observed proportions of improved water quality in each bin.} 
\label{fig:pred_bin_plots}
\end{figure}

If there was no effect of nonlinear averaging, then we would expect the average observed proportion and the average predictions to intersect at the center point as we see in \FREF{pred_cubic_plots}B. One possible reason for the variations we see in \FREF{pred_bin_plots} is the nonlinear averaging; since both observed status and predicted probabilities are averaged on the response scale as opposed to link scale. For example, if the range of values are bigger than $0.5$ (seemingly the case here), then we would expected the averages to be slightly higher than what we would expect at the center point.

In \FREF{pred_bin_prediction_effects_plots} below, we use \FREF{pred_bin_plots}A and compare the prediction and effect plots associated with the central estimates. 

\begin{figure}
\begin{center}
\includegraphics{glm_two_predictor_preds_effects.ggp.pdf}
\end{center}
\caption{{\bf Bias correction for prediction and effect plots.} In each case (A and B), the central estimates for predictions and effects are the same. These patterns are  consistent with the ones in \FREF{pred_bin_plots}A compared to the truth. Further, the predictions and effects exhibit patterns and generalize in a similar way to the ones in simple linear models.
}
\label{fig:pred_bin_prediction_effects_plots}
\end{figure}


\subsection{Mediated effect}

A \emph{mediated} effect is a situation in which only some of the input variables have a \emph{causal} impact on the outcome, even though all the variables are (somehow) associated with the outcome. For example, the age at marriage may be strongly associated with divorce rate but only married people divorce. So does marriage \emph{cause} divorce?

For simplicity, we consider an hypothetical simulation for three variables: input variables $x$ and $y$; and outcome variable $z$; such that
%
\begin{center}
\begin{tikzpicture}
    \node (1) at (0,0) {x};
    \node (2) [right = of 1] {y};
    \node (3) [below = of 2] {z};
    \path (1) edge  (2);
    \path (1) edge (2);
    \path (2) edge (3);
    \path (1) edge (3);
\end{tikzpicture}
\end{center}
%
The arrows above show the direction of influence; and the implication of $x\rightarrow y$ and $y \rightarrow z$ is that $x$ affects $z$ in two ways. First, it has (some) direct effect; and second, it can have indirect effect by influencing $y$, regulated by parameter $\rho$ as shown in \nameref{S3_Appendix}.

To make inferences about this mediated effect, we need more than one model. First, the regression of $z$ on $x$, i.e., the \emph{non-mediated} (or univariate) model which tells on the \emph{total} effect of $x$ on $z$; and second, the regression of $z$ on $x$ and $y$, i.e., the \emph{mediated} (or multivariate or full) model. We simulated the data as shown in \nameref{S3_Appendix} and fitted the two models -- non-mediated and mediated. In both cases, we compared mean-based and the whole-sample-based predictions, as shown in \FREF{pred_mediated_plots}.

\begin{figure}
\begin{center}
\includegraphics{mediate_preds.ggp.pdf}
\end{center}
\caption{{\bf Mean-based and whole-sample-based estimates for mediated (multivariate) and non-mediated (univariate) models.} A: In the absence of mediator variable, both mean-based and whole-sample-based approaches predictions are identical since there is no any other additional (non-focal predictor) sources of bias. Consequently, in both approaches, the average estimated probability is very close to the observed proportion. B: When the mediator variable is included,  $x$ has no direct effect on $z$ and as a result the predictions do not align with the observations. However, the whole-sample-based approach still closely approximates the average proportion of the simulated data. The horizontal dashed lines are the respective average estimates and observed proportions. The vertical dashed black represents the center point, and the point at which it crosses the horizontal lines represents the expected ``perfect'' estimate at the model center. The grey points are the binned observations.}
\label{fig:pred_mediated_plots}
\end{figure}

From \FREF{pred_mediated_plots}A, we see what we would expect in the absence of additional sources of bias, even though in the simulation, the effect of $x$ on $z$ is mediated through $y$. This is the total effect of $x$, which only tells us the influence of $x$ on $z$. By ignoring $y$ in the model, we are still able to capture the effect of $x$ and closely match the observed values using both approaches. However, if there were additional non-focal predictors, we would expect to see the differences similar to those in \FREF{pred_bin_plots}A. Including both $y$ and $x$ ``dilutes'' the direct effect of $x$ on $z$ and as a result, our estimates do not necessarily match the observed binned observations (see \FREF{pred_mediated_plots}B).

\section{Discussion}

Our simulations examples focused on simple linear and logistic models due their wide range of usage and application. These models also act as a starting point for building other complex models, including mixed effect models and models with categorical predictors. The logic for extending to more complex models, including other forms of nonlinear link functions is very straightforward. In fact the components needed for extension are the correct linear predictor and the inverse link function; everything else generalizes. In addition, our \proglang{R} package implementation already extends to and supports most of the nonlinear link functions and mixed model framework, including multivariate binary outcome models.

Although commonly used \proglang{R} software packages, by default, implements mean-based approach, our simulation results demonstrated that the whole-sample-based approach has a potential of yielding results which are more consistent with the observed data. We would, therefore, argue that the use of mean-based approach should have some theoretical justification, especially in complex models. 

\section{Conclusion}

Generating outcome predictions or predicted probabilities from simple and generalized linear (mixed) models is not only important but also, generating quantities which are consistent with the observed values should be of interest. However, many studies still report coefficient estimates from generalized models like probit, logistic, etc., \citep{hanmer2013behind}, which are subject of less clarity and complexities in interpretation.

The argument and results we present in this paper support a greater need for a shift on focus on how to present predictions from generalized models. For example, effect plots could provide more clarity concerning the uncertainty due to the input variable of interests as opposed to the conventional way of incorporating everything. 

From our theoretical, methodological and simulation results, researchers using these kind of models should, in the absence of theoretical justification, report predictions based on whole-sample-based approach or at least attempt to do a comparison of the two approaches before settling on the most appropriate in answering their research question. Moreover, we provide \proglang{R} package, \pkg{vareffects}, which implements these methods and is available on github (\href{https://github.com/mac-theobio/effects}{https://github.com/mac-theobio/effects}).


\section{Supporting information}

% Include only the SI item label in the paragraph heading. Use the \nameref{label} command to cite SI items in the text.
\paragraph*{S1 Appendix.}
\label{S1_Appendix}
{\bf Cubic polynomial interaction simulation.} Consider an hypothetical simulation which simulates household size as a function of household wealth index and cubic function of the age of the household head, specified as follows:

\begin{align}\label{sim:lm_cubic}
\mathrm{hh~size}_i &= \beta_0 + \beta_{\mathrm{A_1}}\mathrm{Age}_i + \beta_{\mathrm{A_2}}\mathrm{Age}^2_i + \beta_{\mathrm{A_3}}\mathrm{Age}^3_i + \beta_{\mathrm{W}}\mathrm{Wealthindex}_i + \epsilon_i \nonumber\\
\mathrm{Age}_i &\sim \mathrm{Normal}(0, 1) \nonumber\\
\mathrm{Wealthindex}_i &\sim \mathrm{Normal}(0, 1) \nonumber\\
\epsilon_i &\sim \mathrm{Normal}(0, 10) \nonumber\\
\beta_0 &= 20 \nonumber\\
\beta_{\mathrm{A}_1} &= 0.1 \nonumber\\
\beta_{\mathrm{A}_2} &= 0.8 \nonumber\\
\beta_{\mathrm{A}_3} &= 0.3 \nonumber\\
\beta_{\mathrm{W}} &= -0.5 \nonumber\\
i &= 1,\cdots, 100
\end{align}


\paragraph*{S2 Appendix.}
\label{S2_Appendix}
{\bf Binary outcome simulation.} Consider a simple simulation for improved water quality in Nairobi slums, such that the status is $1$ for improved and $0$ for unimproved water quality. In additional to the focal predictor, age of the household head, we add wealth index. In particular:

\begin{align}\label{sim:glm_two_pred}
\mathrm{status}_i &\sim \mathrm{Bern}(\mathrm{P_i}) \nonumber\\
\mathrm{logit}(\mathrm{P_i}) &= \eta_i \nonumber\\
\mathrm{\eta}_i &= \beta_0 + \beta_{\mathrm{A}}\mathrm{Age}_i + \beta_{\mathrm{W}}\mathrm{Wealthindex}_i \nonumber\\
\mathrm{Age}_i &\sim \mathrm{Normal}(0, 1) \nonumber\\
\mathrm{Wealthindex}_i &\sim \mathrm{Normal}(0, 1) \nonumber\\
\beta_0 &= 5 \nonumber\\
\beta_{\mathrm{A}} &= 0.5 \nonumber\\
\beta_{\mathrm{W}} &= 1.5 \nonumber\\
i &= 1,\cdots, 10000
\end{align}

\paragraph*{S3 Appendix.}
\label{S3_Appendix}
{\bf Mediated effect simulation.} Next, we consider a simple indirect mediation previously described and simulate a binary outcome model such that:

\begin{align}\label{sim:simple_mediate}
z_i &\sim \mathrm{Bern}(\mathrm{P_i}) \nonumber\\
\mathrm{logit}(\mathrm{P_i}) &= \eta_i \nonumber\\
\eta_i &= \beta_0 + \beta_{xz} x_i + \beta_{yz} y_i \nonumber\\
y_i &= \rho x_i + \sqrt{1-\rho^2} y_y \nonumber\\
x_i &\sim \mathrm{Normal(0, 1)} \nonumber\\
y_y &\sim \mathrm{Normal(0, 1)} \nonumber\\
\rho &= 0.8 \nonumber\\
\beta_0 &= 5 \nonumber\\
\beta_{xz} &= 0.2 \nonumber\\
\beta_{yz} &= 1.5 \nonumber\\
i &= 1,\cdots, 10000
\end{align}


\section*{Acknowledgments}

This work was supported by a grant to Jonathan Dushoff from the Natural Sciences and Engineering Research Council of Canada (NSERC) Discovery.

\section*{Author Contributions}

\textbf{Conceptualization:} Jonathan Dushoff

\noindent\textbf{Software:} Steve Cygu, Benjamin M. Bolker

\noindent\textbf{Writing – original draft:} Steve Cygu


\nolinenumbers
