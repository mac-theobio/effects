%% Main tex

\linenumbers

\jd{How did all the figures wind up in back?}

% Use "Eq" instead of "Equation" for equation citations.
\section*{Introduction}

\jd{Can we stake out early what we mean by predictions vs.~effects? It still seems muddled together. I guess it's complicated because in many cases the estimate is the same (only CIs differ). But I think we should do it anyway.}


In applications that use regression models, outcome predictions are often of interest. Predictions provide a great way to summarize what the regression model is telling us and very useful for interpreting and visualizing model estimates. For example, in logistic regression models, the coefficient estimates, when reported as log odds, are not easy to interpret and less informative. Since logistic models are nonlinear (due to the nonlinear link function), in multivariate models with\bmb{?only}\BC{clarify with BMB} interactions, the magnitude of the effect of change in the outcome depends on the values of the predictor of interest and other predictors. Hence, the conclusions one can make about the estimated effects greatly depends on how well we choose the values of the other predictors, i.e., \emph{non-focal} predictors.  

Ordinary least squares (OLS) regression provides an easy way to express multivariate relationships as an additive linear combination of many predictors with the outcome. The coefficient estimates from OLS regression models are generally easy to interpret as the expected change in the outcome with a unit change in the continuous predictor or as the expected outcome difference between the levels of the categorical predictor with the baseline category. However, with additional complexities such interaction between predictors, the resulting coefficients risk misinterpretation or interpretation complexity \citep{brambor_understanding_2006, berry_improving_2012}. 

Simple OLS regression models are flexible and can easily be generalized, as generalized linear (mixed) models (GL(M)Ms), to examine more complex relationships, including \bmb{nonlinear relationships -- need to clarify}\BC{clarity with BMB} between response and predictors e.g., log transformed response or predictors, interactions between predictors (and via splines for example), and nonlinear transformations via link functions \bmb{due to their flexibility}\BC{clarify why BMB circled it}. This flexibility comes with additional complications, for example, complex multivariate models may risk misinterpretation, and miscalculation of quantities of interest \citep{berry_improving_2012, leeper2017interpreting}. Further, coefficient estimates of GLM models involving nonlinear link functions lack direct interpretation\citep{leeper2017interpreting}, meaning that interpretation of derived quantities from these estimates requires some understanding of the specified model. An alternative is to explore the \emph{effects} of predictors on the predictions of the outcome at various levels of the predictor of interest \jd{Are we still saying these (prediction and effects) are the same? Or are we now saying they're different, with the same citations?} \citep{fox2009effect, leeper2017package, lenth2018package}. For example, as a way to plan, public health officials may want to know the effects of household \code{income}, \code{wealthindex}, etc, on the predicted probability that slum dwellers will have improved water services.


When visually presented, predictions provide a unified and intuitive way of describing relationships from a fitted model, especially complex models involving interaction terms or some kind of transformations on the predictors whose estimates are usually, but not always, harder to interpret. Generating predictions together with the associated confidence intervals for regression models has a number of challenges. In particular:
\begin{enumerate}
\item choice of representative values of \emph{focal} predictor and the \emph{reference point} for non-focal predictors, especially in multivariate models
\item  propagation of uncertainty -- appropriate choice of \emph{anchor} for computing confidence intervals; and how to incorporate the uncertainty due to non-focal predictors 
\item bias in the expected mean prediction induced by the nonlinear transformation of the response variable (especially in GL(M)Ms)
\end{enumerate}

The most common way of choosing the representative values is taking unique levels of the focal predictor if discrete or taking appropriately sized quantiles \jd{Don't understand what the bins are doing here (when we are holding the reference point constant); it's not what we do, is it?} if continuous, and then calculating the predictions while holding non-focal (other predictors other than the focal predictor) predictors at their reference point (e.g., means) \citep{hanmer2013behind}. This procedure generates \jd{Are predictions and predictor effects really used for the same thing?} -- \emph{predictions}, \emph{predictor effects} \citep{fox2009effect}, \emph{marginal predictions} \citep{leeper2017package} or \emph{estimated marginal means} \citep{lenth2018package}. In this article, we refer to these quantities as predictions since they should, for example, tell us what we would expect the response to be at a particular value or level of the predictor, for an ``average case''. \bmb{More specifically, we compute the expected outcome by holding non-focal predictors constant (or averaged in some meaningful way) while varying the focal predictor, with the goal that the predictions represents how the model responds to the changes in the focal predictor. On the other hand, effects differ with predictions in the sense that the former is about how we describe the uncertainty around the latter and depends on the anchor. -- see next/unclear}\BC{clarify with BMB} 


The most \bmb{commonly used \proglang{R} software packages (\pkg{emmeans} and \pkg{effects})}\BC{not sure the underline} for generating predictions, by default, use the average of non-focal predictors as the reference point. 
\jd{This is ambiguous; we need to be talking about input variables and model variables by now. Also: what do the packages do about categorical non-focal predictors? Do we know?}
However, there are a number of choices one can make when considering this approach -- for example, in the presence of interaction, averaging the interactions (averaging the product of interacting model variables) versus taking the product of the averages of the interacting model variables (the default for \pkg{emmeans} and \pkg{effects}). For simple models (with no interactions), the two approaches give the same predictions. However, for complex models, we claim that neither of these two approaches is the most appropriate but we show that averaging the interaction closely matches the observed values. To illustrate this, consider models~\ref{eq:simple_inter_higher_no_interaction} and \ref{eq:simple_inter_higher} below, with $x_1$ as the focal predictor:
\bmb{This whole example .... example of nonlinear averaging}\BC{Yes and handling interaction terms?}
%
\begin{align}
y &= \beta_0 + \beta_1x_1 + \beta_2x_2 + \beta_3x_3 + \epsilon \label{eq:simple_inter_higher_no_interaction}\\
y &= \beta_0 + \beta_1x_1 + \beta_2x_2 + \beta_3x_3 + \beta_{23}x_2x_3 + \epsilon \label{eq:simple_inter_higher}
\end{align}
%

We first simulate data with the two models, such that $x_{1,2,3} \sim \mathrm{Normal}(0, 1)$, $\beta_0 = 5$, $\beta_1 = -3$, $\beta_2 = 1$, $\beta_3 = 2$ $\beta_{23} = 5$, $\epsilon \sim \mathrm{Normal}(0, \sigma^2)$ and $\sigma^2 = 1$, and then compare the predictions from the \pkg{emmeans}, \pkg{effects} and our proposed alternative (\pkg{varpred}) to the ``true'' predictions and observed average i.e., $\bar{y}$, as shown in Fig~\ref{fig:justify_plots}.
\jd{What are true predictions? Why does it look like effects matches varpred, but it sounds like we're saying it matches emmeans?}

\begin{figure}[h]
\begin{center}
\includegraphics{justify_preds.inter.pdf}
\end{center}
\caption{{\bf A comparison of \pkg{emmeans}, \pkg{effects} and \pkg{varpred} predictions for $x_1$ on $y$ for models with and without interactions.}
The horizontal blue, green and black lines are the mean predictions, i.e., $\bar{\hat{y}}$, the red ones are the means of the simulated $y$, i.e., $\bar{y}$, while the vertical dotted grey lines are the means of the corresponding focal predictors. The grey points are the binned simulated $y$. The trend lines represent the corresponding $\hat{y}$ at various levels of $x_1$, while holding the other predictors at their average for the three methods and the true predictions based on the simulation parameters. A: In the absence of interaction, the predicted mean, $\bar{\hat{y}}$, closely matches the simulated value in all the three approaches, i.e., $\bar{y} \approx \bar{\hat{y}}$. Similarly, the predictions based on the three approaches closely match the true predictions. B: Even with the simple interaction between non-focal predictors, we start seeing deviation in both predicted mean, $\bar{\hat{y}}$, and overall predictions from the simulated, $\bar{y}$, and true predictions, respectively; in two commonly used packages (\pkg{emmeans} and \pkg{effects}), but not the proposed \pkg{varpred}.}
\label{fig:justify_plots}
\end{figure}

\jd{Why do we say ``similar"? Are they not the same?}
In the absence of interaction (model~\ref{eq:simple_inter_higher_no_interaction}), the three approaches produce similar estimates, which match the simulated values, Fig~\ref{fig:justify_plots}A. However, in the presence of interaction, even as simple as the one in model~\ref{eq:simple_inter_higher}, the estimates starts to differ. In particular, \pkg{emmeans} and \pkg{effects} give similar estimates ($\bar{\hat{y}}$) but different from the \pkg{varpred}'s which, however, is very close to the simulated average ($\bar{y}$), Fig~\ref{fig:justify_plots}B. To generate Fig~\ref{fig:justify_plots}A, all the three packages averages non-focal predictors $x_2$ and $x_3$. On other hand, to generate Fig~\ref{fig:justify_plots}B, the difference in the estimates lies on how each of the packages average the interaction term ($x_2x_3$). In particular \pkg{emmeans} and \pkg{effects} uses \emph{input variables} to compute $\bar{x_2}\bar{x_3}$ while \pkg{varpred} uses \emph{model variables} to compute $\over{x_2x_3}$.

One may be interested in the uncertainties associated with the focal predictor of interest only, excluding other uncertainties due to other non-focal predictors -- effects. However, currently, the two packages do not provide straightforward way do achieve this. To illustrate this, we generate predictions of $x_2$ from model~\ref{eq:simple_inter_higher_no_interaction} together with the associated $95\%$ confidence bands, as shown in Fig~\ref{fig:justify_ci_plots}. 

\begin{figure}[h]
\begin{center}
\includegraphics{justify_preds.isolate.pdf}
\end{center}
\caption{{\bf A comparison of conventional $95\%$ confidence bands and effects.} The description of horizontal, vertical and trend lines remain the same as above. The wider dotted blue curves overlaying the green curves corresponds to the conventional confidence bands around the predcitions from \pkg{emmeans} and \pkg{effects}, while the narrower black curves crossing at the mean of the focal predictor, i.e., the model center, corresponds to the effects of the focal predictor from \pkg{varpred}. For simple models, the isolated confidence bands crosses at the model center. The wider curves incorporates not only the uncertainties due to intercept term but also other non-focal predictors. On the other hand, effects (narrower crossing lines) only take into account the main effect uncertainty of the focal predictor.}
\label{fig:justify_ci_plots}
\end{figure}

For \pkg{emmeans} and \pkg{effects}, the confidence bands are much wider because they include uncertainties associated with the intercept and non-focal predictors, but narrower and crosses at the mean of the focal predictor, i.e., \emph{center point or mean-based}, in \pkg{varpred}. In other words, with \pkg{varpred}, we are able to generate effects indicating zero uncertainty at the value of the focal predictor we are more certain about, i.e., mean of the model variable corresponding to the focal predictor (center point or mean-based). For simple models, the point where the confidence bands crosses is the model center; it corresponds to anchor we choose, in this case, the mean of the focal predictor.

\jd{Hard to parse. Why ``for example''? The key here is that the lm case works out well because it's all about linear averaging (the mean prediction is the prediction from the mean point), whereas the glm case is non-linear averaging. There should be a link also to why we use the ``model center'' (we're using the correct center point for the linear averaging to work out.}

When dealing with nonlinear link functions or models with multiple non-focal predictors, the correct predictions are much harder to estimate. One approach is to make predictions on the transformed scale (linear predictor scale), and then back-transform to the original scale. However, the back-transformation may either result in biased predictions or requires some approximation. In particular, bias in expected mean prediction induced by nonlinear transformation of the response variable can lead inaccurate predictions. An alternative to mean-based reference point, i.e., averaging non-focal predictors, is the \emph{whole-sample-based} approach, discussed in detail later, which involves computing the prediction over the population of non-focal predictors and then averaging across the values of the focal predictor \citep{hanmer2013behind}. 

The main purpose of this article is to discuss and implement various approaches for computing predictions and provide an alternative method for computing the associated confidence intervals, i.e., effects. We further explore and demonstrate, using simulated data, approaches for correcting bias in predictions for GL(M)Ms involving nonlinear link functions.

\section*{Quantities of interest}

\jd{Is this borrowed from me? I'm not really following the structure of the MS right now. Maybe I'll be clearer in the morning.}

Several quantities of interest may be derived from regression models. The first one is the coefficient estimates. Others are \emph{input and model variables}, \emph{model matrix}, \emph{model center}, \emph{reference point} and \emph{anchor}.

\subsection*{Input variables}

These are scientific variables underlying an inference or exploration. The focal and non-focal predictors we use for effects or predictions are an input variables.

\subsection*{Model matrix}

Model matrix refers to the design matrix whose rows include all combination of variables appearing in the interaction terms, along with the typical values of the focal and non-focal predictors. 

\subsection*{Model variables}

These are variables that represent columns in the model matrix. Each input variable may correspond to one or more model variables. In particular, variables with more than two categories, or variables modeled with a spline or polynomial response, will correspond to more than one model variables.

\subsection*{Model center} 

A point corresponding to a column-wise mean of the model matrix (the mean of one or more model variables). We also refer to this as mean-based approach. The center point for a set of model variables corresponding to an input variable may not represent a possible value of the input variable -- the case in Fig~\ref{fig:justify_plots}. In simple linear models (without) interaction, the input variable can be used as a proxy.

\subsection*{Reference point}

Corresponds to the value or values chosen for non-focal predictors, when estimating the predictions. Typically the center point (mean-based), but can instead be a whole-sample of quantiles or observations. Appropriately choosing the reference point is very crucial in generating ``correct'' predictions especially when dealing with non-linear link functions.


\subsection*{Anchor}

The value chosen for the focal predictor when estimating effect confidence intervals (anchor choice does not affect the main prediction estimates). Typically chosen as the center point of the model variables corresponding to the focal input variable but other sensible values can be chosen too.

If we are trying to focus on effects, the anchor from which we calculate CIs becomes important. This is not true for the more conventional prediction plots: we can choose any anchor, e.g., zero-anchored, but model center seems like a natural, stable choice, i.e., center-anchored. In Fig~\ref{fig:justify_anchors}, we compare effects plots anchored at the minimum and center (mean) of the focal predictor.

\begin{figure}[h]
\begin{center}
\includegraphics{justify_anchors.combined.pdf}
\end{center}
\caption{{\bf A comparison of min-based and center- (mean-) based anchors.} The center-based effects are based on the mean of the focal predictor while the min-anchored effects are based on the minimum of the focal predictor. As we mentioned earlier, the choice of the anchor do not affect the main estimates (central trend lines).} 
\label{fig:justify_anchors}
\end{figure}

If we have more than one model variables for our focal predictor, however, the model center does not correspond to any given value of the variable, and we don't get the nice crossing we get in simpler cases. See Fig~\ref{fig:pred_cubic_plots}.


\subsection*{Prediction- vs. effect- styled plots}

A prediction-style plot is about predicting observations (or the ensemble mean of observations) for a given value of the focal predictor. For this, we want to use the classic curved confidence intervals (or prediction intervals). A prediction-style plot will generally focus on \emph{total} effects, and so will often be suited for a univariate fit. An effect-style plot, however, is an attempt to visualize the effect of a focal predictor. In this case, we suggest the narrower confidence intervals. Here, it makes equal sense to think about the total effect of our focal predictor, from a univariate model, or the direct effects – after controlling for whatever – from a multivariate model. See Fig~\ref{fig:justify_ci_plots}.

\subsection*{Predictions vs. effects}

We would like to summarize by talking about predictions vs. effects. Predictions are the standard curves; they tell us what we expect to see if we know the value of the focal predictor. The lines inside (effects) are a little different: they are a good way to visualize the effect of the focal predictor. Unlike predictions, where the uncertainty captures the uncertainty in the whole model, the effects plot focuses on uncertainty in the effect of the focal predictor only and depend on the anchor.



\section*{Statistical background}

To get an intuition of how conditioning on the mean values of non-focal predictors work, suppose we are interested in predictions at the levels of a particular predictor, i.e., focal, $x_f$, from the set of predictors. As a starting point, assume that the model has no interaction terms. The idea is to choose a reference point for the values of non-focal predictors. For example, fixing the values of non-focal predictor(s) at some typical values -- typically determined by averaging (for now) in some meaningful way, for example, arithmetic mean  for continuous and average over the levels of the factors for categorical non-focal predictors. We refer to this as centered or mean-based approach. The most convenient way to achieve this is by constructing centered model matrix, $\bX^\star$, by averaging the columns of non-focal predictors in model matrix $\bX$, and together with appropriately chosen values of focal predictor.


Consider a simple linear model with linear predictor $\eta = \bX\bbeta$ and let $g(\boldmu) = \boldeta$ be an identity link function (in the case of simple linear model), where $\boldmuh$ is the expected value of response variable $\hat{y}$. Let $\bbetah$ be the estimate of $\bbeta$, together with the estimated covariance matrix $\Sigma = V(\bbetah)$ of $\bbetah$. Then the quantity $\hat{\boldeta}^\star = \bX^\star\bbetah$ is the prediction with respect to the focal predictor in question \citep{fox2009effect}.

An alternative formulation of $\boldetah^\star$ involves expressing the linear predictor as the sum of the focal and non-focal predictors' linear predictors. In particular, 

\begin{align}\label{eq:eta_mean}
\eta^\star(x_f, \nset{{\bar{x}^\star}}) &= \hat{\beta}_f x_f + \sum \nset{\hat{\beta}} \nset{{\bar{x}^\star}} \\
\hat{y}_f  &= g^{-1} \left(\eta^\star(x_f, \nset{{\bar{x}^\star}})\right)
\end{align}
where $\nset{{\bar{x}^\star}}$ and $x_f$ are columns of $\bX^\star$ corresponding to the non-focal predictors and the focal predictor, respectively.


\subsection*{Dealing with higher order interactions}

Higher order terms such as interactions, splines, polynomials, etc., can be within the focal predictor, within (between) non-focal predictor(s) or between the focal and non-focal predictor(s). To distinguish the three, suppose the model which describes the hypothetical simulated household size simulation based on a number of socio-demographic factors such as age and wealthindex is

\begin{align}\label{sim:lm_cubic}
\mathrm{hh~size}_i &= \beta_0 + \beta_{\mathrm{A_1}}\mathrm{Age}_i + \beta_{\mathrm{A_2}}\mathrm{Age}^2_i + \beta_{\mathrm{A_3}}\mathrm{Age}^3_i + \beta_{\mathrm{W}}\mathrm{Wealthindex}_i + \epsilon_i \nonumber\\
\end{align}

In the first case, with \code{Age} as the focal predictor, with cubic polynomial interaction terms (and 3 model variables associated with it). In this case, each of the polynomial terms (model variables) of the focal predictor are evaluated independently across the chosen levels of the focal predictor, $Age_i$. Specifically, the higher order terms are treated as additional columns of the model matrix evaluated with the same values of the focal predictor, while non-focal predictors are fixed at their reference point as discussed in the previous section. In this case, the predictions associated with \code{Age} on the linear predictor scale become

\begin{align*}
\eta^\star(\mathrm{Age}_i, \nset{{\over{\mathrm{Wealthindex}}}}) &= \beta_0 + \beta_{\mathrm{A_1}}\mathrm{Age}_i + \beta_{\mathrm{A_2}}\mathrm{Age}^2_i + \beta_{\mathrm{A_3}}\mathrm{Age}^3_i\\
	& + \beta_{\mathrm{W}}\over{\mathrm{Wealthindex}}
\end{align*}

In the second case, with $Wealthindex$ as the focal predictor, the higher order terms in non-focal predictor, \code{Age}, are treated simply as additional columns in the variable space (model variables) and an appropriate choice of reference point applies just like in the models without higher order interactions. For instance, in mean-based approach, we average all non-focal model variables. Thus

\begin{align*}
\eta^\star(\mathrm{Wealthindex}_i, \nset{{\{\over{\mathrm{Age\mathop{\vphantom{^2}}}}, \over{\mathrm{Age}^2}, \over{\mathrm{Age}^2}\}}}) &= \beta_0 + \beta_{\mathrm{A_1}}\over{\mathrm{Age\mathop{\vphantom{^2}}}} + \beta_{\mathrm{A_2}}\over{\mathrm{Age}^2} + \beta_{\mathrm{A_3}}\over{\mathrm{Age}^3}\\
	& + \beta_{\mathrm{W}}\mathrm{Wealthindex}_i
\end{align*}

Lastly, consider model shown in Equation~\ref{eq:simple_inter_higher}, previously used to demonstrate how to handle interactions in non-focal predictors. Here, we use the same model to demonstrate how to handle interactions between the focal predictor, $x_2$, and non-focal predictor, $x_3$. In this case, the non-interacting predictors are treated as non-focal predictors, with appropriate reference points. However, for the interacting predictors, we first choose representative values for the focal predictor and some particular values of the interacting predictor similar to the way we choose values for the focal predictor or predetermined. In our example, suppose we pick $i$ and $j$ unique values of the focal predictor, $x_2$ and interacting predictor $x_3$, respectively. The prediction on linear predictor scale is given by

\begin{align*}
\eta^\star(x_{2i}, x_{3j}, \nset{{\bar{x}^\star}}) = \beta_0 + \beta_1 \bar{x}_1 + \beta_2x_{2i} + \beta_3x_{3j} + \beta_{23}x_{2i}x_{3j}.
\end{align*}

In general, our formulation, even for more complicated interactions, follow these three basic principles -- interaction within focal predictor, interaction between non-focal predictors and interaction between focal and non-focal predictors.


\section*{Uncertainty estimation}

We describe the uncertainty around the estimates using confidence intervals (CI). In principle, every value of focal predictor has a different CI. The conventional way to compute variances for predictions is $\boldsymbol\sigma^2 = \textrm{Diag}(\bX^\star \boldsymbol{\Sigma} \bX^{\star\top})$ \citep{lenth2018package, fox2009effect}, so that the confidence intervals are $\boldeta \pm q\boldsymbol\sigma$, where $q$ is an appropriate quantile of Normal or t distribution. This generates prediction CIs and incorporates all the uncertainties -- including the uncertainty due to the intercept and non-focal predictors.  But what if we are only interested in the uncertainty as a result of the focal predictor, so that the confidence intervals are $\boldeta \pm q \boldsymbol \sigma_f$, i.e., effects? 

Commonly used \proglang{R} packages for constructing predictions do not exclude the uncertainties resulting from non focal predictors when computing the CIs. Currently a non-trivial way to exclude uncertainties associated with non-focal predictors in some of these packages is to provide a user defined variance-covariance matrix with the covariances of non-focal terms set to $0$. We refer to this procedure as \emph{zeroing-out} variance-covariance matrix; and only works when the input predictors are \emph{centered} prior to model fitting, in case of numerical predictors, and more complicated when the predictors are categorical. We describe our proposed method which is based on the model center and does not require input predictors to be centered prior to model fitting.


\subsection*{Model center based}

Let $\bxo$ be a model matrix containing appropriately chosen values of focal predictor and centered non-focal model variables, and let $\ba$ be the anchor matrix, with same dimension and entries in all non-focal model variables as $\bxo$. Let $\baf$ be the column of $\ba$ corresponding to focal predictor model variable(s) defined in $\bxo$. Any appropriate values can be chosen for $\baf$ but for model center (center-anchored), we use $\bafc$ which is the mean of the focal predictor model variable(s). Thus the variances for the predictions we defined in the previous section is 

%
\begin{align}\label{eq:centered_variance}
\boldsymbol\sigma_f^2 = \textrm{Diag}((\bxo - \bafc) \boldsymbol{\Sigma} (\bxo - \bafc)^\top)
\end{align}
%
We can see that $\forall ~\bxof=\baf$, $\bxo - \baf = \boldsymbol 0$, hence $\boldsymbol\sigma_f^2 = \boldsymbol{0}$. Similarly, for all values of $\bxof$ close to anchor point $\bafc$ the term $(\bxo - \bafc)$ and $\boldsymbol\sigma_f^2$ goes to $\boldsymbol 0$ and $\boldsymbol\sigma_f^2 = \boldsymbol 0$ if $\bxof=\bafc$. This means that $\boldsymbol\sigma_f^2$ close to the anchor point are smaller than those away from the anchor point; and results to confidence intervals which are narrower (isolated) around the anchor or crosses at the anchor point for simple models.


The computation of $\bxo - \bafc$ impacts only on the intercepts and non-focal model variables, i.e., the slopes and variance corresponding to the focal predictors are not affected. This means that we can still generate effects without necessarily centering the predictors prior to model fitting.

%% \subsection*{Is center-anchored better?}
%% 
%% We want to compare the amount of uncertainty when there is/no anchor. Let $\bao = \boldsymbol{0}$ be the anchoring matrix with all entries in $0$s, and let $\bafc$ be the center-anchored matrix defined above. Then entries in $(\bxo - \bao) \geq (\bxo - \bafc)$.
%%

\section*{Bias correction}

It is usually important to report the estimates that reflect the expected values of the untransformed response. This is not a major issue in simple linear models. However, when dealing with nonlinear link functions,  generated predictions may not reflect the observed response due to the bias in the expected mean induced by the nonlinear transformation of the response variable. In such cases, bias correction is needed when back-transforming the predictions to the original scales. The common approach for bias-adjustment is second-order Taylor approximation \citep{lenth2018package, duursma2003bias}. Another potential source of bias comes from additional non-focal predictors, especially in models with nonlinear link functions. Here, we describe and implement a different approach; whole-sample-based approach for bias correction.


\subsection*{Whole-sample-based approach for bias correction}

One way to predict is to condition on values of the focal predictor and make predictions for all observations (members of the population) \citep{hanmer2013behind}. The nonlinear transformation involved in these computations is always \emph{one-dimensional}; all of the multivariate computations required are at the stage of collapsing the multidimensional set of predictors for some subset of the population to a one-dimensional distribution of $\eta^\star(x_f, \nset{x})$, which is a function of focal predictor and the observed values of non-focal predictors, as opposed to the definition in Equation~\ref{eq:eta_mean}. More specifically:

\begin{itemize}
\item compute linear predictor associated with non-focal predictors, $\nset{\eta} = \sum \nset{\beta} \nset{x}$
\item compute linear predictor associated with the focal predictors, $\eta_{jf} = \sum{\beta_f x_{jf}}$
\item for every value of the focal predictor, $\eta_{jf}$:

\begin{align}\label{eq:pop_eta} 
\eta_j^\star(\eta_{jf}, \nset{\eta})  &= \eta_{jf} + \nset{\eta} \nonumber \\
&= \eta_j^\star(x_f, \nset{x})
\end{align}
\end{itemize}

Once Equation~\ref{eq:pop_eta} is computed, one can back-transform the estimates to the original scale and the average over the levels of the focal predictors, $j$:

\begin{align}\label{eq:pop_response} 
\hat{y}_f  &= \textrm{mean} ~ g^{-1} \left(\eta_j^\star(x_f, \nset{x})\right)
\end{align}

We make similar adjustments to compute the variances of the predictions at every level of the focal predictor:

\begin{align}
\sigma_{jf}^2 = \textrm{Diag}(\bX^\star_{jc} \boldsymbol{\Sigma} \bX^{\star\top}_{jc})
\end{align}
where $\bX^{\star}_{jc} = \{\bX_{jf}^\star, \nset{{\bX}^\star} - \nset{{\bar{\bX}}^\star}\}$ and 

\begin{align}
\mathrm{CI}_f = \mathrm{mean} ~ g^{-1} \left(\eta_j^\star(x_f, \nset{x}) \pm q\sigma_{jf}\right)
\end{align}

\bmb{does averaging the CI ...}\BC{Theoretical proof or just a statement?}

For models with random effects components, we make further adjustment to correct for bias induced by the random effects terms. In the population approach, we treat the random effects terms as additional non-focal predictors and simply make adjustment to Equation~\ref{eq:pop_eta}. In particular

\begin{align}\label{eq:pop_eta_re} 
\tau &= \bZ b \nonumber \\
\eta_j^\star(x_f, \nset{x}, \tau)  &= \eta_j^\star(x_f, \nset{x}) + \tau
\end{align}
where $\bZ$ and $b$ are the design matrix and a vector of random effects, respectively.

\section*{Mean-based vs. whole-sample-based}

As mentioned above, the two common choices to generate predictions are: 1) setting non-focal predictors to their mean -- mean-based; and 2) using the entire population of non-focal predictors -- whole-sample-based. If the link function is nonlinear and/or the model has complex higher order interactions, the average of the predictions evaluated at the mean of non-focal predictors and the average of predictions evaluated at the population level (and then averaged) of non-focal predictor are not equivalent, i.e.,

\begin{align}\label{eq:compare_anchored_pop_based}
g^{-1} \left(\eta_j^\star(\bar{x}_f, \nset{\bar{x}})\right) \neq \frac{1}{n} \sum_{i=1}^n{ g^{-1} \left(\eta_j^\star(\bar{x}_f, \nset{x})\right)}.
\end{align}

If $g()$ is strictly concave or strictly convex, one can use Jensen's inequality to determine which side of Equation~\ref{eq:compare_anchored_pop_based} is decelerating or accelerating. For accelerating functions, the Jensen’s inequality describes how the changes in input values elevate the predictions and otherwise describes how these changes depress the predictions. For a non-fully convex or concave link function, one can use Taylor series expansion to approximate the range over which the two are smaller or smaller than the other \citep{hanmer2013behind}. 
\bmb{Just knowing is not enough and discuss much earlier}\BC{Clarify with BMB the current version and appropriate section to move to}


As stated above, in simple linear models without interactions, the effect is constant, so both approaches yield similar results. However, picking a single value, e.g., mean of the predictor, on which to draw conclusions about the effect can be problematic, unrealistic or not contained in or representative of the population. In addition, the mean-based approach fails to use every values of non-focal predictors hence not utilizing the full potential of the information contained in the data. This may limit the inferences we can make about the entire population. In general, the mean-based approach provides the predictions of an average case, whereas the whole-sample-based approach, summarizes the predictions over the entire population -- and in some applications, the effect of an average case might not be generalizable to the entire population, especially, if the average does not represent the population. In particular the whole-sample-based approach focuses on specific observations since the prediction is first obtained for each observation and then averaged across the levels of the focal predictor.

Another potential concern with the mean-based approach arises in situations where direct naive use leads to rare or meaningless basis for generalization. For example, setting dummy categorical variables in the model matrix to their means, which, by default, sets them to their sample means or observed proportions. For example, a dummy variable for christian household heads may be set to $0.2$, translating to prediction for an household head who is $20\%$ christian. This may be problematic in models with complex interaction terms in which the values may not be converge to population mean\citep{hanmer2013behind}.

Whole-sample-based approach is not entirely foolproof. For instance, similar to the mean-based approach, in the case of continuous focal predictors, choosing the representative values of the focal predictors can be very challenging especially if the cases are not evenly distributed around the minimum and the maximum values or within some subgroups defined in the population. In addition, whole-sample-based approach can be computationally intensive for large datasets.

\section*{Simulation examples}

We now illustrate the construction of prediction-styled and effect-styled plots and also demonstrate that the mean-based and whole-sample-based approaches produce different results in models with nonlinear link functions and/or additional source(s) of potential bias. In addition, we demonstrate that whole-sample-based approach can be used for bias correction.

\subsection*{Predictions-styled and effects-styled plots}

As mentioned above, in some applications, one may be interested in uncertainties associated with the focal predictor only. In that case, it is important to exclude all the uncertainties as a result of non-focal predictors and only show confidence intervals describing the predictor of interest. To illustrate this, we consider the simulation model described in \nameref{S1_Appendix}. 

We start by generating two predictions from the fitted model \nameref{S1_Appendix}: 1) one with cubic polynomial of \code{age} as a focal predictor; and 2) one with a simple focal predictor (non-polynomial) of \code{Wealthindex}. Then we compared non-anchored and mean-anchored (effects) confidence intervals around the predicted values (see Fig~\ref{fig:pred_cubic_plots}).

\begin{figure}[h]
\begin{center}
\includegraphics{cubic_predictors_preds.ggp.pdf}
\end{center}
\caption{{\bf Prediction-styled and effect-styled plots for cubic polynomial and simple focal predictors.} A: The focal predictor is a cubic polynomial. B: The focal predictor is a linear function, with a cubic polynomial non-focal predictor. In both cases, the mean-anchored effects are narrower than the non-anchored (predictions), but intersects at the mean of the focal predictor (model center) only in the case of linear focal predictor -- B. In the case of cubic polynomial focal predictor, the model center is not a point in the predictor space, i.e., mean of the focal predictor, but a combination of all the model variables in the cubic polynomial, consequently, mean-anchored curves will not necessarily cross at a point -- A. The horizontal black and red dashed lines are the observed and predicted average household size, i.e., $\over{hh~size}$ and $\over{\widehat{hh~size}}$, respectively; the inner red dotted curves and crossing lines are the effects for A and B, respectively; while the outer blue curves are the \BC{predictions (place holder for now)} in both cases. The central curve and trend line, in A and B, respectively; are the predicted household size based on age and wealth index, respectively. \bmb{Use different line types ...}\BC{Confirm with BMB}}
\label{fig:pred_cubic_plots}
\end{figure}

In the absence of complex higher order interaction terms or transformations on the focal predictor in simple linear models, we would expect, at the model center, the observed average, $\over{hh~size}$, and the average of the predictions, $\over{\widehat{hh~size}}$, to be identical and all intersect at the mean-anchored confidence bands (effects), at the model center (Fig~\ref{fig:pred_cubic_plots}B). On the other hand, if the focal predictor is characterized by complex interactions or any other form of transformation, the model center is not necessarily a point in the predictor space. In this case, the mean-anchored confidence bands will be narrower than the non-anchored ones but will not necessarily cross at the model center (Fig~\ref{fig:pred_cubic_plots}A).

\subsection*{Bias correction}

Mean-based and whole-sample-based approaches can produce very different results in models with nonlinear link functions with additional sources of potential bias such as additional non-focal predictor(s), random effect terms or complex interactions. To demonstrate this, we considered a two predictor binary outcome simulation described in \nameref{S2_Appendix}, such that the age effect is way smaller than that of the wealth index, and compared their effects on the predicted probability of improved water quality as shown in Fig~\ref{fig:pred_bin_plots}. 

\begin{figure}[h]
\begin{center}
\includegraphics{glm_two_predictor_preds.ggp.pdf}
\end{center}
\caption{{\bf Mean-based and whole-sample-based predictions.} The two approaches produce relatively different estimates in each of the predictors but the difference is more pronounced when the effect of the particular focal predictor has no strong effect -- \emph{on the left}. In both cases, \emph{right} and \emph{left}, the average predicted probability of improved water based on whole-sample-based approach is very close to the observed proportion in the simulated data. The horizontal blue, black and the red dotted lines are the average mean-based, whole-sample-based predicted probability and observed proportion of improved water quality, respectively. The vertical dotted black line represents the mean of the focal predictor, and the point at which it crosses the red dotted line represents the expected ``perfect'' prediction at the model center. The grey points are binned observations -- observed proportions of improved water quality in each bin. We would expect all the curves, horizontal, and vertical lines to cross at the model center but due the nonlinear averaging (at least in the bias corrected whole-sample-based approach) of the predictions on the response scale, this may not always be the case.} 
\label{fig:pred_bin_plots}
\end{figure}

If there was no effect of nonlinear averaging, then we would expect the observed proportion and the average of the predicted probabilities to cross at the model center as we see in Fig~\ref{fig:pred_cubic_plots}B. However, the differences we see in Fig~\ref{fig:pred_bin_plots} are due to nonlinear averaging since both observed status and predicted probabilities are averaged on the response scale as opposed to link scale. In particular, if the range of values are bigger than $0.5$ (seemingly the case here), then we would expected the averages to be slightly higher than what we would expect at the model center, and vice versa.

\subsection*{Mediated effect}

Using simple indirect mediation simulation model described in \nameref{S3_Appendix}, fitted two models -- \emph{non-mediated} which models \emph{z} as a function of \emph{x} (univariate model) and the \emph{mediated} which models \emph{z} as a function of both \emph{x} and \emph{y} (multivariate model). In both cases, we compared mean-based and the whole-sample-based predictions, as shown in Fig~\ref{fig:pred_mediated_plots}.

\begin{figure}[h]
\begin{center}
\includegraphics{mediate_preds.ggp.pdf}
\end{center}
\caption{{\bf Mean-based and whole-sample-based predictions for mediated effects.} These figures compare the mean-based and whole-sample-based predictions for the mediated (multivariate) and non-mediated (univariate) models. A: In the absence of mediator variable, both mean-based and whole-sample-based approaches predictors are identical since there is no any other additional (non-focal predictors) sources of bias. Consequently, for both approaches, the average predicted probability is very close to the observed proportion. B: When the mediator variable is included, there is no direct effect of $x$ on $z$ and as a result the predictions do not necessarily align with the observations. However, the whole-sample-based approach still closely approximates the average proportion in the simulated data. The horizontal blue, black and the red dotted lines are the average mean-based, whole-sample-based predicted probability and observed proportion, respectively. The vertical dotted black line represents the mean of the focal predictor, and the point at which it crosses the red dotted line represents the expected ``perfect'' prediction at the model center. The grey points are the binned observations.}
\label{fig:pred_mediated_plots}
\end{figure}

From Fig~\ref{fig:pred_mediated_plots}A, we see what we would expect in the absence of additional sources of bias, even though in the simulation, the effect of $x$ on $z$ is mediated through $y$. By ignoring $y$ in the model, we are still able to capture the effect of $x$ and closely match the observed values using both approaches. However, if there were additional non-focal predictors, we would expect to see the differences similar to those in Fig~\ref{fig:pred_bin_plots}. Including both $y$ and $x$ ``dilutes'' the direct effect of $x$ on $y$ and as a result, our prediction do not necessarily match the observed binned observations (see Fig~\ref{fig:pred_mediated_plots}B).

\section*{Discussion}

Our simulations examples majorly focused on simple linear and logistic models due their wide range of usage and application. In addition, these models act as a starting point for building other complex models, including mixed effect models and models with categorical predictors. However, the logic for extension of approaches to more complex models, including other forms of nonlinear link functions is very straightforward. In addition, our \proglang{R} package implementation already extends to and supports most of the nonlinear link functions and mixed model framework, including multivariate binary outcome models.

Although commonly used \proglang{R} software packages, by default, implements mean-based approach, our simulation results demonstrated that the whole-sample-based approach has a potential of yielding results which are more consistent with the observed data. We would, therefore, argue that the use of mean-based approach should have some theoretical justification, especially in complex models. 

\section*{Conclusion}

Generating outcome predictions or predicted probabilities from simple and generalized linear (mixed) models is not only important but also, generating quantities which are consistent with the observed values should be of interest. However, many studies still report coefficient estimates from generalized models like probit, logistic, etc., \citep{hanmer2013behind}, which are subject of less clarity due to lack of direct link to the outcome of interest.

The argument and results we present in this paper supports a greater need for a shift on focus on what and how to present predictions from generalized models. For example, we believe that effect-styled confidence intervals could provide more clarity concerning the uncertainty due to the predictor of interests as opposed to the conventional way of incorporating everything. 

From our theoretical, methodological and simulation results, researchers using these kind of models should, in the absence of theoretical justification, report predictions based on whole-sample-based approach or at least attempt to do a comparison of the two approaches before settling on the most appropriate in answering their research question. Moreover, we provide \proglang{R} package, \pkg{vareffects}, which implements these methods and is available on github (\href{https://github.com/mac-theobio/effects}{https://github.com/mac-theobio/effects}).


\section*{Supporting information}

% Include only the SI item label in the paragraph heading. Use the \nameref{label} command to cite SI items in the text.
\paragraph*{S1 Appendix.}
\label{S1_Appendix}
{\bf Cubic polynomial interaction simulation.} Consider an hypothetical simulation which simulates household size as a function of household wealth index and cubic function of the age of the household head, specified as follows:

\begin{align}\label{sim:lm_cubic}
\mathrm{hh~size}_i &= \beta_0 + \beta_{\mathrm{A_1}}\mathrm{Age}_i + \beta_{\mathrm{A_2}}\mathrm{Age}^2_i + \beta_{\mathrm{A_3}}\mathrm{Age}^3_i + \beta_{\mathrm{W}}\mathrm{Wealthindex}_i + \epsilon_i \nonumber\\
\mathrm{Age}_i &\sim \mathrm{Normal}(0, 1) \nonumber\\
\mathrm{Wealthindex}_i &\sim \mathrm{Normal}(0, 1) \nonumber\\
\epsilon_i &\sim \mathrm{Normal}(0, 10) \nonumber\\
\beta_0 &= 20 \nonumber\\
\beta_{\mathrm{A}_1} &= 0.1 \nonumber\\
\beta_{\mathrm{A}_2} &= 0.8 \nonumber\\
\beta_{\mathrm{A}_3} &= 0.3 \nonumber\\
\beta_{\mathrm{W}} &= -0.5 \nonumber\\
i &= 1,\cdots, 100
\end{align}


\paragraph*{S2 Appendix.}
\label{S2_Appendix}
{\bf Binary outcome simulation.} Consider a simple simulation for improved water quality in Nairobi slums, such that the status is $1$ for improved and $0$ for unimproved water quality. In additional to the focal predictor, age of the household head, we add wealth index. In particular:

\begin{align}\label{sim:glm_two_pred}
\mathrm{status}_i &\sim \mathrm{Bern}(\mathrm{P_i}) \nonumber\\
\mathrm{logit}(\mathrm{P_i}) &= \eta_i \nonumber\\
\mathrm{\eta}_i &= \beta_0 + \beta_{\mathrm{A}}\mathrm{Age}_i + \beta_{\mathrm{W}}\mathrm{Wealthindex}_i \nonumber\\
\mathrm{Age}_i &\sim \mathrm{Normal}(0, 1) \nonumber\\
\mathrm{Wealthindex}_i &\sim \mathrm{Normal}(0, 1) \nonumber\\
\beta_0 &= 5 \nonumber\\
\beta_{\mathrm{A}} &= 0.5 \nonumber\\
\beta_{\mathrm{W}} &= 1.5 \nonumber\\
i &= 1,\cdots, 10000
\end{align}

\paragraph*{S3 Appendix.}
\label{S3_Appendix}
{\bf Mediated effect simulation.} Next, we consider a simple indirect mediation simulation such that $x$ has direct effect on $y$ which in turn has effect on $z$ but $x$ has no direct effect on $y$, i.e., $x \rightarrow y \rightarrow z$. In particular:

\begin{align}\label{sim:simple_mediate}
z_i &\sim \mathrm{Bern}(\mathrm{P_i}) \nonumber\\
\mathrm{logit}(\mathrm{P_i}) &= \eta_i \nonumber\\
\eta_i &= \beta_0 + \beta_{xz} x_i + \beta_{yz} y_i \nonumber\\
y_i &= \rho x_i + \sqrt{1-\rho^2} y_y \nonumber\\
x_i &\sim \mathrm{Normal(0, 1)} \nonumber\\
y_y &\sim \mathrm{Normal(0, 1)} \nonumber\\
\rho &= 0.8 \nonumber\\
\beta_0 &= 5 \nonumber\\
\beta_{xz} &= 0.2 \nonumber\\
\beta_{yz} &= 1.5 \nonumber\\
i &= 1,\cdots, 10000
\end{align}


\section*{Acknowledgments}

This work was supported by a grant to Jonathan Dushoff from the Natural Sciences and Engineering Research Council of Canada (NSERC) Discovery.

\section*{Author Contributions}

\textbf{Conceptualization:} Jonathan Dushoff

\noindent\textbf{Software:} Steve Cygu, Benjamin M. Bolker

\noindent\textbf{Supervision:} Jonathan Dushoff, Benjamin M. Bolker

\noindent\textbf{Writing – original draft:} Steve Cygu


\nolinenumbers
