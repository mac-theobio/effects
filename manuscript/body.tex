%% Main tex

\linenumbers

% Use "Eq" instead of "Equation" for equation citations.
% Best to use a command that combines the name and the reference
\section{Introduction}

Plots of predicted values of an outcome against predictors (often called effect plots or prediction plots) are often a useful way to summarize the results of a regression model. These can be used to illustrate model uncertainty or to give a more explicit quantitative sense of how the outcome is expected to change. In generalized models with a non-linear link function, or models with a spline or polynomial response to a predictor variable, they can also aid in understanding difficult-to-interpret coefficient estimates \citep{brambor_understanding_2006, berry_improving_2012, leeper2017interpreting}. 

To make an outcome plot, we use a \emph{focal} predictor on the x-axis. The resulting plot will depend on choices we make about other (non-focal) predictor(s). In ordinary (Gaussian) linear regression, the non-focal choices may have a simple additive effect on the outcome estimate. However, when the focal predictor has interactions or a non-linear link function, non-focal choices can also affect the slope of the response. Additional challenges arise when dealing with generalized linear (mixed) models (GL(M)Ms), which extend ordinary linear models to incorporate random effects. How we treat random effects can also have an effect. 

The outcome plots described above are often called prediction plots or effects plots. We endeavor here to make a conceptual distinction. If our goal is to \emph{predict} what we learn about the outcome variable by measuring the focal predictor, \NEW{then we would focus on the central estimate, which is the same for both prediction and effects plots. However, the distinction between the two lies in how we describe the uncertainties around the central estimate. In particular, we may want to capture the uncertainty in the whole model (these include uncertainty due to intercept, focal and non-focal predictors, and random effects), or we may be interested in showing the uncertainty associated with the focal predictor only. In the former case, we use the prediction plots, which generally focus on the \emph{total} effect and will often be suited for a univariate model. In the latter case, we use effect plots that focus on the direct effect of the focal predictor -- after controlling for other non-focal predictors -- from a multivariate model, which will be preferable for multivariate models. Since effects plots focus on focal-specific uncertainty, they are usually narrower than prediction plots. Shi et al. \citep{shi_evidence_2017} used effects plots to compare the difference in sexual risk behaviors between circumcised and uncircumcised men.}

Generating quantities, i.e., central estimate, together with the corresponding confidence intervals, i.e.,  prediction and effects plots, has some challenges. In particular:
\begin{enumerate}
\item choice of representative values of focal predictor and the \emph{reference point} for non-focal predictors, especially in multivariate models
\item uncertainty estimation -- appropriate choice of \emph{anchor} for computing confidence intervals; and how to incorporate the uncertainty due to non-focal predictors 
\item bias in the expected mean prediction induced by the non-linear transformation of the response variable (especially in GL(M)Ms).
\end{enumerate}

The most common way of choosing the representative values is taking unique levels or quantiles of the focal predictor if discrete or continuous, respectively. The central estimates are then calculated by holding the non-focal predictors at their reference point (values chosen for the non-focal predictors, e.g., means) while varying the focal predictor, with the goal that the estimates represent how the model responds to the changes in the focal predictor \citep{fox2009effect, hanmer2013behind}. This procedure generates -- \emph{predictor effects} \citep{fox2009effect}, \emph{marginal predictions} \citep{leeper2017package} or \emph{estimated marginal means} \citep{lenth2018package}. In this article, we refer to these quantities as the \emph{central estimates} for an ``average case'' in a population; the associated confidence intervals will either describe a prediction or effect plot. In the effect plots, we can also choose an anchor (value chosen for the focal predictor).

For linear models (including models with complex interactions), the averaging is done on the linear scale, i.e., linear averaging. As a result, the \emph{bias} in the expected (mean) predictions can easily be corrected using \emph{mean-based reference point}, i.e., averaging of the non-focal model variables -- currently not implemented in commonly used \proglang{R} software packages. The mean of the central estimates is the prediction at the \emph{model center}. In this case, the estimates are usually consistent with the observed values. However, in models with non-linear link functions, this is not always the case. In particular, when dealing with GL(M)Ms with non-linear link functions, the averaging is done on the non-linear scale, i.e., non-linear averaging, making generating correct predictions much harder. This is the bias in the expected mean prediction induced by the non-linear transformation of the response variable. One way to address this is to make predictions on the linear predictor scale and back-transform to the original scale. However, the back-transformation may either result in biased predictions or requires some approximation, for example, second-order Taylor approximation implemented in \pkg{emmeans} \citep{lenth2018package}. An alternative to the mean-based reference point is the \emph{whole-sample-based} approach, discussed in detail later, which involves computing the prediction over the population of non-focal predictors and then averaging across the values of the focal predictor \citep{hanmer2013behind}. 

This article aims to discuss and implement various approaches for computing predictions and effects, together with the associated plots. We further explore and demonstrate, using simulated data, approaches for correcting bias in central estimates for GL(M)Ms involving non-linear link functions. The proposed method and \proglang{R} software package will complement the existing ones by providing: 1) a straightforward way to generate effects, and 2) an alternative and a more robust way to correct for prediction bias in GL(M)Ms.

\section{Definitions}

In order to discuss the statistical background and mathematical formulation of the proposed approaches, we need to understand and formally define a number of terms, some of which have been introduced in the previous section:

\jd{I should edit if we can finally consense on nomenclature. I feel it's my fault.}
\begin{itemize}
\item \textbf{Input variables}: Refers to the observed (or scientific) variables underlying an inference or exploration. For example, the regression models described by Equation~\ref{eq:simple_inter_higher_no_interaction} and Equation~\ref{eq:simple_inter_higher} both have $3$ input variables -- $x_1, x_2, x_3$.
\item \textbf{Focal and non-focal predictors}: The focal predictor refers to the input variable we are interested in. For multivariate models, all other variables other than focal predictors are non-focal predictors. For example, consider model described by Equation~\ref{eq:simple_inter_higher_no_interaction}. Suppose we are interested in the effect of $x_1$ on the predicted $y$, then $x_1$ is the focal predictor while $x_2$ and $x_3$ are non-focal predictors.
\item \textbf{Model matrix}: Refers to the design matrix whose rows include all combination of input variables. Consider an example for three hypothetical households -- the first household head is a Christian with an income of $\$ 50$, the second household head is Muslim with an income of $\$ 100$ while the third household head is a Jew with an income of $\$ 77$. Suppose we want to model the household size (\code{hhsize}) as function of these household characteristics, i.e., $$\mathrm{hhsize} = \beta_0 + \beta_1\times\mathrm{income} + \beta_{2[r]}\times\mathrm{religion} + \mathrm{error}.$$ The model matrix corresponding to this model is given by
$$\begin{bmatrix}{}
 Intercept & income & religionJew & religionMuslim \\
 1 & 50 & 0 & 0 \\
  1 & 100 & 0 & 1 \\
  1 & 77 & 1 & 0 \\
\end{bmatrix}.$$ The first column represents the constant term in our model, $\beta_0$. For continuous input variables, the representation in the model matrix is the same as the corresponding input variables (for example second column representing income). For categorical variables, however, by default, the model matrix  creates additional dummy variables using the reference cell parameterization. This means that, if an input variable has $L$ factor levels, then there will be $L-1$ dummy columns representing all but the first level created in the model matrix. In our example, the column \code{religion} is missing and instead we have \code{religionJew} and \code{religionMuslim}; the missing category \code{religionChristian} is treated as the reference category.
\item \textbf{Model variables}: Refer to the X-variables which go into the regression model; and represent columns in the model matrix. Each input variable may correspond to one or more model variable. In particular, variables with more than two categories (for instance religion in our previous example), or input variables modeled with interactions, a spline or polynomial interactions, will correspond to more than one model variable. For example, the regression models described by Equation~\ref{eq:simple_inter_higher_no_interaction} and Equation~\ref{eq:simple_inter_higher} have $4$ model variables -- $x_1, x_2, x_3$ plus intercept term and $5$ model variables -- $x_1, x_2, x_3, x_2x_3$ plus the intercept term, respectively.
\item \textbf{Model center:} A point corresponding to a column-wise mean of the model matrix (the mean of one or more model variables). Also referred to as center point. We refer to the prediction approach that uses model center as mean-based. The center point for a set of model variables corresponding to an input variable may not represent a possible value of the input variable -- the case in Fig~\ref{fig:justify_plots}B. In simple linear models (without) interaction, the mean of the input variable can be used as a proxy for the center point. If there are more than one model variables associated with the focal input variable, however, the model center does not correspond to any given value of the focal predictor, and we do not necessarily get the ``nice'' crossing we get in simpler cases, see Fig~\ref{fig:pred_cubic_plots}.
\item \textbf{Reference point:} Corresponds to the value or values chosen for non-focal predictors, when estimating the predictions and effects. Typically the center point (mean-based), but can instead be a whole-sample of quantiles or observations. Appropriately choosing the reference point is very crucial in generating correct predictions (for bias correction) especially when dealing with non-linear link functions.
\item \textbf{Anchor:} The value chosen for the focal predictor when estimating effect confidence intervals. The anchor choice does not affect the central estimates. Typically chosen as the center point of the model variables corresponding to the focal predictor but other sensible values can be chosen too. If we are trying to focus on effects, the anchor from which we calculate confidence intervals becomes important. This is not true for the predictions. We can choose any anchor, but the center point is a natural and stable choice.
\item \textbf{Marginal effects:} In simple linear models with no interaction terms, the coefficient estimates are simple and directly interpretable as the expected change in outcome for a unit change in focal input variable. This is the \emph{unconditional marginal effect} and it is constant across all the observations and levels of all other input variables. Consider models described by Equation~\ref{eq:simple_inter_higher_no_interaction} and Equation~\ref{eq:simple_inter_higher}. The marginal effect of $x_2$ in model~\ref{eq:simple_inter_higher_no_interaction} is $\frac{\partial y}{\partial x_2} = \beta_2$. On the other hand, the marginal effect of $x_2$ in model~\ref{eq:simple_inter_higher} is given by $\frac{\partial y}{\partial x_2} = \beta_2 + \beta_{23}x_3$. In other words, if there are no interactions, the marginal effect of $x_2$ on $y$ is constant, while, if there are interactions in the model, the marginal effect of a change in $x_2$ on $y$ depends on the value of the other \emph{conditioning} predictor, $x_3$. In essence, computation of marginal effects requires the use of partial derivatives and can be considered as the slope multi-dimensional surface with response to the surface of interest \cite{leeper2017interpreting}. 
\end{itemize}

\section{Statistical background}

To illustrate mean-based approach, consider a simple linear model with linear predictor $\eta = \bX\bbeta$ and let $g(\boldmu) = \boldeta$ be an identity link function, where $\boldmuh$ is the expected value of response variable $\hat{y}$. Let $\bbetah$ be the estimate of $\bbeta$, together with the estimated covariance matrix $\Sigma = V(\bbetah)$ of $\bbetah$. Then the quantity $\hat{\boldeta}^\star = \bX^\star\bbetah$ is the central estimate with respect to the focal predictor in question \citep{fox2009effect}; where $\bX^\star$ is the centered model matrix constructed by averaging the columns of non-focal predictors in model matrix $\bX$, and together with appropriately chosen values of focal predictor.

An alternative formulation of $\boldetah^\star$ involves expressing the linear predictor as the sum of the focal and non-focal predictors' linear predictors. In particular, 

\begin{align}\label{eq:eta_mean}
\eta^\star(x^\star_f, \nset{{\bar{x}^\star}}) &= \hat{\beta}_f x^\star_f + \sum \nset{\hat{\beta}} \nset{{\bar{x}^\star}} \\
\hat{y}_f  &= g^{-1} \left(\eta^\star(x^\star_f, \nset{{\bar{x}^\star}})\right)
\end{align}
where $\nset{{\bar{x}^\star}}$ and $x^\star_f$ are columns of $\bX^\star$ corresponding to the non-focal predictors and the focal predictor, respectively.


\subsection{Dealing with higher-order terms}

\jd{I'm having trouble staking out higher-order terms as a thing. Yes, many times some or all of the terms in a multi-parameter predictor can be described as higher order, but not always (e.g., categorical predictors). Also, why are we interested in things that don't involve the focal predictor (and why only interactions?). I know that we have to average properly, but we should do that once. Does it make sense to talk separately about interactions, and multi-parameter focal predictors?}

\BC{Should we just be more specific and say "Dealing with polynomial input variables"?}
\BC{JD to explain second part ...}

Higher order input variables such as interactions, splines, polynomials, etc., can be within the focal input variable, within (between) non-focal input variable(s) or between the focal and non-focal input variable(s). To distinguish the three \jd{Right? Why are there three? There should be two or four.} \BC{Three: 1) on the focal, 2) on the non-focal, and 3) between focal and non-focal. Which one is redundant or missing?}, suppose the model which describes the hypothetical simulation of household size based on a number of socio-demographic factors such as age and wealth index is
%
\begin{align}\label{eq:lm_cubic}
\mathrm{hh~size}_i &= \beta_0 + \beta_{\mathrm{A_1}}\mathrm{Age}_i + \beta_{\mathrm{A_2}}\mathrm{Age}^2_i + \beta_{\mathrm{A_3}}\mathrm{Age}^3_i\nonumber \\
&+ \beta_{\mathrm{W}}\mathrm{Wealthindex}_i + \epsilon_i.
\end{align}
%
In the first case, with \code{Age} as the focal input variable, with cubic polynomial interaction ($3$ focal predictors associated with it). In this case, each of the focal predictors ($\mathrm{Age}_i, \mathrm{Age}^2_i$ and $\mathrm{Age}^3_i$) are evaluated independently across the chosen levels of the focal input variable, $Age_i$. Specifically, the higher order terms are treated as additional columns of the model matrix evaluated with the same values chosen for the focal input variable, while non-focal predictors are fixed at their reference point as discussed in the previous section. In this case, the predictions associated with \code{Age} on the linear predictor scale become
%
\begin{align}
\eta^\star(\mathrm{Age}_i, \nset{{\over{\mathrm{Wealthindex}}}}) &= \beta_0 + \beta_{\mathrm{A_1}}\mathrm{Age}_i + \beta_{\mathrm{A_2}}\mathrm{Age}^2_i + \beta_{\mathrm{A_3}}\mathrm{Age}^3_i \nonumber\\
	& + \beta_{\mathrm{W}}\over{\mathrm{Wealthindex}}.
\end{align}
%
In the second case, with \code{Wealthindex} as the focal input variable, the non-focal variable, \code{Age}, is a cubic polynomial. In this case, the non-focal predictors ($\mathrm{Age}_i, \mathrm{Age}^2_i$ and $\mathrm{Age}^3_i$) are simply treated as additional columns in the predictor space and an appropriate choice of reference point applies just like in the models without higher non-focal variable interactions. For instance, in mean-based approach, we average all non-focal predictors. Thus
%
\begin{align}
\eta^\star(\mathrm{Wealthindex}_i, \nset{{\{\over{\mathrm{Age\mathop{\vphantom{^2}}}}, \over{\mathrm{Age}^2}, \over{\mathrm{Age}^2}\}}}) &= \beta_0 + \beta_{\mathrm{A_1}}\over{\mathrm{Age\mathop{\vphantom{^2}}}} + \beta_{\mathrm{A_2}}\over{\mathrm{Age}^2} + \beta_{\mathrm{A_3}}\over{\mathrm{Age}^3}\nonumber\\
	& + \beta_{\mathrm{W}}\mathrm{Wealthindex}_i.
\end{align}
%
Lastly, consider model described by Equation~\ref{eq:simple_inter_higher}, previously used to demonstrate how to handle interactions in non-focal input variables. Here, we use the same model to demonstrate how to handle interactions between the focal input variable, $x_2$, and non-focal input variable, $x_3$. In this case, the non-interacting predictors are treated as non-focal predictors, with appropriate reference points. However, for the interacting predictors, we first choose representative values for the focal input variable and then some particular values of the interacting non-focal input variable in a similar way we chose the values for the focal input variable or use predetermined values. In our example, suppose we pick $i$ and $j$ unique values of the focal input variable, $x_2$ and interacting input variable $x_3$, respectively. The prediction on linear predictor scale is given by
%
\begin{align*}
\eta^\star(x_{2i}, x_{3j}, {\bar{x}^\star_1}) = \beta_0 + \beta_1 \bar{x}^\star_1 + \beta_2x_{2i} + \beta_3x_{3j} + \beta_{23}x_{2i}x_{3j}.
\end{align*}
%

In general, our formulation, even for more complicated interactions, follow these three basic principles -- interaction within focal input variables, interaction between non-focal input variables and interaction between focal and non-focal input variables.
\jd{We should talk about what this s. means. What are the principles?}
\BC{DISCUSS with JD}

\section{Uncertainty estimation}

We describe the uncertainty around the estimates using confidence intervals (CIs). In principle, every value of focal input variable has a different CI. The conventional way to compute variances for predictions is 
%
\begin{align}\label{eq:conventional_variance}
\boldsymbol\sigma^2 = \textrm{Diag}(\bX^\star \boldsymbol{\Sigma} \bX^{\star\top}), 
\end{align}
so that the confidence intervals are $\boldeta \pm q\boldsymbol\sigma$, where $q$ is an appropriate quantile of Normal or t distribution \citep{lenth2018package, fox2009effect}. This generates conventional CIs which incorporate all the uncertainties -- including the uncertainties due to the intercept and non-focal input variables.  But what if we are interested in the uncertainty as a result of the focal input variable only, so that the CIs are $\boldeta \pm q \boldsymbol \sigma_f$, i.e., effects? 

\NEW{We may be interested in the uncertainties associated with the focal input variable only, excluding other uncertainties due to other non-focal input variables -- effects. However, commonly used \proglang{R} packages for constructing predictions do not exclude the uncertainties resulting from non focal input variables when computing the CIs.} \jd{We should first explain what we want to do, and then do our comparisons with existing packages.} Currently obscure way to exclude uncertainties associated with non-focal input variables in some of these packages is to provide a user defined variance-covariance matrix with the covariances of non-focal predictors set to $0$. We refer to this procedure as \emph{zeroing-out} variance-covariance matrix; and only works when the input variables are \emph{centered} prior to model fitting, in case of numerical variables, and more complicated when the input variables are categorical. An alternative is our proposed approach which uses the model center and does not require the input variables to be centered prior to model fitting.

Let $\bxo$ be a centered model matrix previously defined, and let $\ba$ be an anchor matrix, with the same dimensions and entries in all non-focal predictors as $\bxo$. Let $\baf$ be the column of $\ba$ corresponding to focal predictor(s) defined in $\bxo$. Any appropriate values can be chosen for $\baf$ but for model center (center-anchored), we use $\bafc$ which is the mean of the focal predictor(s). Thus 
%
\begin{align}\label{eq:centered_variance}
\boldsymbol\sigma_f^2 = \textrm{Diag}((\bxo - \bafc) \boldsymbol{\Sigma} (\bxo - \bafc)^\top).
\end{align}
%
We can see that $\forall ~\bxof=\baf$, $\bxo - \baf = \boldsymbol 0$, hence $\boldsymbol\sigma_f^2 = \boldsymbol{0}$. Similarly, for all values of $\bxof$ close to anchor point $\bafc$, the term $(\bxo - \bafc)$ and $\boldsymbol\sigma_f^2$ goes to $\boldsymbol 0$ and $\boldsymbol\sigma_f^2 = \boldsymbol 0$ if $\bxof=\bafc$. This means that $\boldsymbol\sigma_f^2$ close to the anchor point are smaller than those away from the anchor point; and results to confidence intervals which are narrower around the anchor or crosses at the anchor point for simple models. This is the effect of the particular focal input variable. By setting $\baf = \boldsymbol 0$, we get the variances for the conventional CIs in Equation~\ref{eq:conventional_variance}.


The computation of $\bxo - \bafc$ impacts only on the intercepts and non-focal predictors, i.e., the slopes and variance corresponding to the focal predictors are not affected. This means that we can still generate effects without necessarily centering the predictors prior to model fitting.

%% \subsection{Is center-anchored better?}
%% 
%% We want to compare the amount of uncertainty when there is/no anchor. Let $\bao = \boldsymbol{0}$ be the anchoring matrix with all entries in $0$s, and let $\bafc$ be the center-anchored matrix defined above. Then entries in $(\bxo - \bao) \geq (\bxo - \bafc)$.
%%

\section{Bias correction}

We can directly compare the outcome estimate at the model center (mean-based estimate) with the average of predictions evaluated across the population values of non-focal predictors (sample-based estimate):

\begin{align}\label{eq:compare_anchored_pop_based}
g^{-1} \left(\eta_j^\star(\bar{x}_f, \nset{\bar{x}})\right) : \frac{1}{n} \sum_{i=1}^n{ g^{-1} \left(\eta_j^\star(\bar{x}_f, \nset{x})\right)}.
\end{align}

In an ordinary linear model, the link function $g$ is the identity function, so the two means are the same. For non-trivial link functions, we expect them to be different in general -- \NEW{a consequent of Jensen inequality \citep{duursma_bias_2003, denny_performance_2019, ye_generalized_2021}. In GL(M)Ms the assumed link function, predetermines the curvature of the response surface and also the sign of the Jensen effect. For example, logistic model has a positive curvature if the predicted probabilities are low and negative curvature if the predicted probabilities are high. In other words, logistic model may be concave or convex depending on the predicted probabilities, hence the sign of the Jensen effect is not readily available. However, in log link functions, the inverse of the link (exponential) function is strictly convex, i.e., an accelerating function. For accelerating functions, the Jensen’s inequality describes how the changes in input values elevate the predictions and otherwise describes how these changes depress the predictions. Further, our models may include input variables and/or random effects terms other than the focal one. In non-trivial link functions, the Jensen effect may depend on the additional input variables \citep{ye_generalized_2021}}.

\jd{We need to explain why we think this is a problem, not just state that it is “usually important".} \BC{See previous \P}

\NEW{It is usually important to report the estimates that reflect the expected values of the untransformed response. This is not a major issue in simple linear models. However, when dealing with nonlinear link functions,  generated predictions may not reflect the observed response due to the bias in the expected mean induced by the nonlinear transformation of the response variable -- a consequent of Jensen effect mentioned above. In such cases, bias correction is needed to back-transform the predictions to the original scales. The common approach for bias-adjustment is second-order Taylor approximation \citep{duursma2003bias, hanmer2013behind}; already implemented in \pkg{emmeans} \citep{lenth2018package}. Here, we describe and implement a different approach -- whole-sample-based approach for bias correction. Hammer and Kalkan \citep{hanmer2013behind} introduced mean- and whole-sample- based approaches but limited their discussion to binary response models only.} 

\subsection{Whole-sample-based approach for bias correction}

An alternative approach to choosing a reference point is to make predictions over all observations of the non-focal input variables (members of the population) \citep{hanmer2013behind}. The nonlinear transformation involved in these computations is always \emph{one-dimensional}; all of the multivariate computations required are at the stage of collapsing the multidimensional set of predictors for some subset of the population to a one-dimensional distribution of $\eta^\star(x_f, \nset{x})$, which is a function of the chosen values of the focal predictor and the whole sample of non-focal predictors, as opposed to the definition in Equation~\ref{eq:eta_mean}. More specifically:
\begin{itemize}
\item compute linear predictor associated with whole sample of the non-focal predictors, $\nset{\eta} = \sum \nset{\beta} \nset{x}$
\item compute linear predictor associated with the chosen values focal input variable, $\eta_{jf} = \sum{\beta_f x_{jf}}$
\item for every value of the focal linear predictor, $\eta_{jf}$, compute
%
\begin{align}\label{eq:pop_eta} 
\eta_j^\star(\eta_{jf}, \nset{\eta})  &= \eta_{jf} + \nset{\eta} \nonumber \\
&= \eta_j^\star(x_f, \nset{x}).
\end{align}
\end{itemize}
%

Once Equation~\ref{eq:pop_eta} is computed, we back-transform the estimates to the original scale and average over the levels of the focal predictors, $j$:
%
\begin{align}\label{eq:pop_response} 
\hat{y}_f  &= \textrm{mean} ~ g^{-1} \left(\eta_j^\star(x_f, \nset{x})\right).
\end{align}
%

We make similar adjustments to compute the variances of the predictions at every level of the focal input variable:
%
\begin{align}
\sigma_{jf}^2 = \textrm{Diag}(\bX^\star_{jc} \boldsymbol{\Sigma} \bX^{\star\top}_{jc})
\end{align}
where $\bX^{\star}_{jc} = \{\bX_{jf}^\star, \nset{{\bX}^\star} - \nset{{\bar{\bX}}^\star}\}$ and 
%
\begin{align}
\mathrm{CI}_f = \mathrm{mean} ~ g^{-1} \left(\eta_j^\star(x_f, \nset{x}) \pm q\sigma_{jf}\right).
\end{align}
%

For models with random effects components, we make further adjustment to correct for bias induced by the random effects terms. In whole-sample approach, we treat the random effects terms as additional non-focal predictors and simply make adjustment to Equation~\ref{eq:pop_eta}. In particular
%
\begin{align}\label{eq:pop_eta_re} 
\tau &= \bZ b \nonumber \\
\eta_j^\star(x_f, \nset{x}, \tau)  &= \eta_j^\star(x_f, \nset{x}) + \tau
\end{align}
where $\bZ$ and $b$ are the design matrix and a vector of random effects, respectively.

\section{Mean-based vs. whole-sample-based}

In the whole-sample-based approach, the ensemble of predictions and CIs are back-transformed before averaging, see Equation~\ref{eq:pop_response}, so we do not need to worry about the nonlinear averaging. In other words, the averaging is no longer on the link scale and is likely to be bounded by the original data scale. In simple linear models without interactions, averaging on the link scale is identical to averaging on the response, so both approaches yield similar results. However, picking a single value, e.g., the mean of the predictor, on which to draw conclusions about the effect can be problematic, unrealistic, or not contained in or representative of the population. In addition, the mean-based approach fails to use every value of non-focal predictors hence not utilizing the full potential of the information contained in the data. This may limit the inferences we can make about the entire population. In general, the mean-based approach provides the predictions of an average case, whereas the whole-sample-based approach summarizes the predictions over the entire population. In some applications, the effect of an average case might not be generalizable to the entire population, especially, if the average does not represent the population. This might not be a problem in the whole-sample-based approach since it focuses on specific observations -- the prediction is first obtained for each observation and then averaged across the levels of the focal input variable.

Another potential concern with the mean-based approach arises when direct naive use leads to a rare or meaningless basis for generalization. For example, if our sample has 20\% Jews, 30\% Muslims, and 50\% Christians. One approach (default in common packages) is assigning equal category weight, i.e., 1/3 Jews, 1/3 Muslims, and 1/3 Christians (the ``sum-to-zero'' approach). The second approach (our default) is setting dummy categorical variables in the model matrix to their means, which, by default, set them to their sample means or observed proportions. The first or second approach translates to prediction for a household head who is 1/3 or 50\% Christian, respectively \citep{hanmer2013behind}. The second approach seems more realistic and will converge to the population mean in many cases.

The whole-sample-based approach is not entirely foolproof. For instance, similar to the mean-based approach, in the case of continuous focal predictors, choosing the representative values of the focal predictors can be very challenging, especially if the cases are not evenly distributed around the minimum and the maximum values or within some subgroups defined in the population. In addition, the whole-sample-based approach can be computationally intensive for large datasets.



\section{Simulation examples}

We now illustrate the construction of prediction and effect plots and also demonstrate that the mean-based and whole-sample-based approaches produce different results in models with nonlinear link functions and/or additional source(s) of potential bias. In addition, we demonstrate that whole-sample-based approach can be used for bias correction.

\subsection{Comparison with other implementations}

The most commonly used \proglang{R} software packages for generating predictions (\pkg{emmeans} and \pkg{effects}), by default, use the average of \emph{input} and \emph{predictor variables} as the reference point for continuous and categorical input variables, respectively. However, there are a number of choices one can make when generating predictions -- for example, in the presence of interactions, averaging the interactions (averaging the product of interacting predictor variables) versus taking the product of the averages of the interacting predictor variables (the default for \pkg{emmeans} and \pkg{effects}). For simple OLS models (with no interactions), the two approaches give the same predictions. However, for complex models, we demonstrate that the two approaches can produce substantially different results and show that averaging the interactions closely matches the observed values. To illustrate this, consider models~\ref{eq:simple_inter_higher_no_interaction} and \ref{eq:simple_inter_higher} below, with $x_1$ as the focal input variable:
%
\begin{align}
y &= \beta_0 + \beta_1x_1 + \beta_2x_2 + \beta_3x_3 + \epsilon \label{eq:simple_inter_higher_no_interaction}\\
y &= \beta_0 + \beta_1x_1 + \beta_2x_2 + \beta_3x_3 + \beta_{23}x_2x_3 + \epsilon \label{eq:simple_inter_higher}.
\end{align}
%

We first simulate data with the two models, such that $x_{1,2,3} \sim \mathrm{Normal}(0, 1)$, $\beta_0 = 5$, $\beta_1 = -3$, $\beta_2 = 1$, $\beta_3 = 2$, $\beta_{23} = 5$, $\epsilon \sim \mathrm{Normal}(0, \sigma^2)$ and $\sigma^2 = 1$, and then compare the predictions from the \pkg{emmeans}, \pkg{effects} and our proposed alternative (\pkg{varpred}) to the ``true'' predictions (predictions based on the true simulation parameters) and observed average i.e., $\bar{y}$, as shown in Fig~\ref{fig:justify_plots}.
%
\begin{figure}
\begin{center}
\includegraphics{justify_preds.inter.pdf}
\end{center}
\caption{{\bf A comparison of \pkg{emmeans}, \pkg{effects} and \pkg{varpred} predictions for regression of $x_1$ on $y$.} The horizontal dashed lines are the mean of the predicted and simulated $y$, $\bar{\hat{y}}$ and $\bar{y}$, respectively. The grey points are the binned simulated $y$. The trend lines represent the corresponding $\hat{y}$ at various levels of $x_1$, while holding the other input variables at their mean and the true predictions based on the simulation parameters. A: In the absence of interaction, the predicted mean, $\bar{\hat{y}}$, closely matches the simulated value in all the three approaches, i.e., $\bar{y} \approx \bar{\hat{y}}$. Similarly, the predictions based on the three approaches match the true predictions. B: Even with the simple interaction between non-focal input variables, we start seeing deviation in both predicted mean, $\bar{\hat{y}}$, and overall predictions from the simulated, $\bar{y}$, and true predictions, respectively, in two commonly used packages (\pkg{emmeans} and \pkg{effects}), but not the proposed \pkg{varpred}.}
\label{fig:justify_plots}
\end{figure}
%
In the absence of interactions (\EREF{simple_inter_higher_no_interaction}), the three approaches produce the same estimates, which match the simulated values, Fig~\ref{fig:justify_plots}A. However, in the presence of interactions, even as simple as the one in Equation~\ref{eq:simple_inter_higher}, the estimates start to differ. In particular, \pkg{emmeans} and \pkg{effects} give similar estimates ($\bar{\hat{y}}$) but different from the \pkg{varpred}'s which, however, is very close to the simulated average ($\bar{y}$), Fig~\ref{fig:justify_plots}B. To generate Fig~\ref{fig:justify_plots}A,  \pkg{emmeans} and \pkg{effects} average $x_2$ and $x_3$, i.e., the input variables while \pkg{varpred} averages the predictor variables corresponds to $x_2$ and $x_3$. On other hand, to generate Fig~\ref{fig:justify_plots}B, the difference in the estimates lies on how each of the packages average the interaction term ($x_2x_3$). In particular, \pkg{emmeans} and \pkg{effects} use input variables to compute $\bar{x_2}\bar{x_3}$ while \pkg{varpred} uses predictor variables to compute $\over{x_2x_3}$. In the case of Fig~\ref{fig:justify_plots}A, averaging the input variables is equivalent to averaging the predictor variables.


One may be interested in the uncertainties associated with the focal input variable only, excluding other uncertainties due to other non-focal input variables -- effects. However, currently, the two packages do not provide a straightforward way do achieve this. To illustrate this, we generate predictions of $x_2$ from Equation~\ref{eq:simple_inter_higher_no_interaction} together with the associated $95\%$ confidence intervals, as shown in Fig~\ref{fig:justify_ci_plots}. 
%
\begin{figure}
\begin{center}
\includegraphics{justify_preds.isolate.pdf}
\end{center}
\caption{{\bf The prediction and effect styled plots at $95\%$ confidence intervals.} The description of horizontal, vertical and trend lines remain the same as above. The wider dashed curves corresponds to the conventional confidence intervals around the predictions from \pkg{emmeans} and \pkg{effects}, while the narrower curves crossing at the mean of the focal input variable, i.e., the center point, correspond to the effect of the focal input variable from \pkg{varpred}. For simple OLS models, the effect-styled confidence bands crosses at the center point (an anchor). The prediction-styled curves incorporates not only the uncertainties due to intercept term but also other non-focal input variables. On the other hand, effect-styled curves only take into account the main effect uncertainty of the focal input variable.}
\label{fig:justify_ci_plots}
\end{figure}
%
For \pkg{emmeans} and \pkg{effects}, the confidence intervals are much wider because they include uncertainties associated with the intercept and non-focal input variables, but narrower and crosses at the mean of the focal input variable in \pkg{varpred}. In other words, with \pkg{varpred}, we are able to generate effects indicating zero uncertainty at the value of the focal input variable we are more certain about, i.e., the center point. For simple OLS models, the point where the confidence intervals curves cross is the model center or simply center point; it corresponds to anchor we choose, in this case, the center point (which is generally an appropriate choice). Predictions are the standard curves; they tell us what we expect to see if we know the value of the focal predictor. The lines inside (effects) are a little different; they are a good way to visualize the effect of the focal predictor. Unlike predictions, where the uncertainty captures the uncertainty in the whole model, the effects plot focuses on uncertainty in the effect of the focal predictor only and depend on the anchor.

\jd{Why do we need this in the definitions section?:} In Fig~\ref{fig:justify_anchors}, we compare effects plots anchored at the center (mean) of the focal input variable with \ldots.
%
\begin{figure}
\begin{center}
\includegraphics{justify_anchors.combined.pdf}
\end{center}
\caption{{\bf A comparison of zero- and center-anchored effects.} \jd{This explanation is not currently correct, but do we really need to explain that the zero anchor means that the anchor is at zero? Also, the real difference between anchors is for multi-parameter predictors? Do we have an example of that?} The center-anchored effects are based on the mean of the focal predictor while the zero-anchored effects are based on the minimum of the focal predictor. As we mentioned earlier, the choice of the anchor do not affect the main estimates (central trend lines).} 
\label{fig:justify_anchors}
\end{figure}
%

The \proglang{R} software package \pkg{margins} \cite{lenth2018package} generates marginal effects. To illustrate the distinction between prediction and effects plots, and marginal effects, we use the simulated data described in \nameref{S1_Appendix}. 
%
\begin{figure}
\centering
\includegraphics{cubic_varpred_margins_pred.ggp.pdf}
\caption{{\bf A comparison of effects and marginal effect plots.} \NEW{A:  The black solid line is the central (outcome) estimate, while the dashed lines corresponds to the effects styled $95\%$ confidence interval. B: The marginal effect (ME) at representative values of the focal input variable \code{age} together with the $95\%$ confidence intervals. For simple linear models with no interactions, the ME should be constant across all the values of the focal input variable; and it would correspond to the slope of the central estimate of the prediction or effects. However, in this example, the focal input variable is a cubic polynomial, and so, the effect is not constant.} \jd{The definitions should be shorter and it's definitely weird to have a figure in the definitions. Maybe you should consider making a box? Also, if we're going to have this figure, we should try to illustrate a more difficult example for comparison.} \BC{What should we call the central and/or y-axis line of the effect/prediction plot?}}
\label{fig:qoi_age_pred_plot}
\end{figure}
%

\subsection{Prediction and effect styled plots}

To illustrate the distinction between the two approaches, we simulate a multivariate model described in \nameref{S1_Appendix}. We also use the same model to illustrate how predictions and effects differ in the presence of higher order interactions in focal or non-focal input variables. We then generated two sets of mean-based predictions and effects: 1) one with \code{age} as the focal input variable (a cubic polynomial focal input variable); and 2) one with \code{Wealthindex} as the focal in put variable (linear focal input variable). In both cases the, the center point was used as the anchor for the effects, as shown in Fig~\ref{fig:pred_cubic_plots}.

\begin{figure}
\begin{center}
\includegraphics{cubic_predictors_preds.ggp.pdf}
\end{center}
\caption{{\bf Prediction and effect plots for cubic polynomial and simple focal predictors.} A: The focal input variable is a cubic polynomial. B: The focal input variable is linear, with polynomial non-focal input variable. The central curve and trend lines are the same for predictions and effects plots in each case. However, the confidence intervals for the effects are narrower than those of the predictions in both cases. The default anchor for generating effects is the center point. For simple OLS models (or simple focal input variables), the center point is a point within the range of focal values; and therefore the confidence interval lines intersect at that that point -- B. In the case of higher order interactions such as cubic polynomials, the center point is not a point but a combination of all the predictor variables associated with the cubic polynomial, consequently, curves will not necessarily cross at a point -- A. The horizontal black and red dashed lines are the observed and predicted average household size, i.e., $\over{hh~size}$ and $\over{\widehat{hh~size}}$, respectively.}
\label{fig:pred_cubic_plots}
\end{figure}

Predictions are the standard curves (wider); they tell us what we expect to see if we know the value of the focal input variable. In multivariate models, at times, we may want to focus on the effect of the focal input variable only. Unlike prediction plot, which captures the uncertainty in the entire model, effect plot focuses on the uncertainty of the focal input variable only. In this case, effects styled plots which are usually narrower around the anchor are preferable over the conventional prediction plots which generally focus on the \emph{total} effects. 

In the absence of complex higher order interactions or transformations on the focal input variable, in simple OLS models we would expect the observed average, $\over{hh~size}$, and the average of the predictions, $\over{\widehat{hh~size}}$, to be identical and intersect with the trend lines at the center point, for the effects plot. On the other hand, if the focal input variable is characterized by complex interactions or any other form of transformations, the center point is not necessarily a point in the range of focal input values. In this case, the effects will be narrower than the predictions plots but will not necessarily intersect. 


\subsection{Bias correction}

Mean-based and whole-sample-based approaches can produce very different results in models with nonlinear link functions with additional sources of potential bias such as additional non-focal input variable(s), random effects or complex interactions. To demonstrate this, we considered a two predictor binary outcome simulation described in \nameref{S2_Appendix}, such that age has a very small effect size in comparison to wealth index, and compared their effects on the predicted probability of improved water quality as shown in Fig~\ref{fig:pred_bin_plots}. 

\begin{figure}
\begin{center}
\includegraphics{glm_two_predictor_preds.ggp.pdf}
\end{center}
\caption{{\bf Mean-based and whole-sample-based predictions.} The \emph{truth} is the prediction based on the true simulation parameters. If the focal input variable has small effect size, mean-based and whole-sample-based approaches produce different predictions -- A. In the case of strong effect size, however, the two approaches produce similar predictions -- B. In both cases, the whole-sample-based predictions are close to the truth. The difference in mean-based and whole-sample-based is due to the bias induced by the non-focal variables and the nonlinear link function in the logistic model. Mean-based approach suffers from nonlinear averaging; and if focal input variable has small effect size, the bias is even pronounced since the effect of nonlinear averaging is driven by the non-focal input variable with the strong effect. However, this is not the case if the non-focal input variables have small effect since the bias they induce is equally likely to be small. Since whole-sample-based approach averages over the whole population of the non-focal predictor variables, it is less likely to be affected by the nonlinear averaging for the reasons already mentioned. The horizontal dashed lines correspond to the respective averages. The vertical dashed lines represent the center point, and the point at which they intersect the horizontal lines represents the expected ``perfect'' prediction at the model center. The grey points are binned observations -- observed proportions of improved water quality in each bin.} 
\label{fig:pred_bin_plots}
\end{figure}

If there was no effect of nonlinear averaging, then we would expect the average observed proportion and the average predictions to intersect at the center point as we see in Fig~\ref{fig:pred_cubic_plots}B. One possible reason for the variations we see in Fig~\ref{fig:pred_bin_plots} is the nonlinear averaging; since both observed status and predicted probabilities are averaged on the response scale as opposed to link scale. For example, if the range of values are bigger than $0.5$ (seemingly the case here), then we would expected the averages to be slightly higher than what we would expect at the center point.

In Fig~\ref{fig:pred_bin_prediction_effects_plots} below, we zoom into Fig~\ref{fig:pred_bin_plots}{A} and compare the prediction and effect styled plots. 

\begin{figure}
\begin{center}
\includegraphics{glm_two_predictor_preds_effects.ggp.pdf}
\end{center}
\caption{{\bf Prediction and effect styled plots and bias correction.} The central curves for predictions and effects are the same in the respective case. These patterns are  consistent with the ones in Fig~\ref{fig:pred_bin_plots}A with respect to the \emph{truth}. Further, the prediction and effect CIs exhibit patterns similar to the ones we previously described and generalizes in a similar way to the ones in simple linear models.
}
\label{fig:pred_bin_prediction_effects_plots}
\end{figure}


\subsection{Mediated effect}

A \emph{mediated} effect is a situation in which only some of the input variables have a \emph{causal} impact on the outcome, even though all the variables are (somehow) associated with the outcome. For example, the age at marriage may be strongly associated with divorce rate but only married people divorce. So does marriage \emph{cause} divorce?

For simplicity, we consider an hypothetical simulation for three variables: input variables $x$ and $y$; and outcome variable $z$; such that
%
\begin{center}
\begin{tikzpicture}
    \node (1) at (0,0) {x};
    \node (2) [right = of 1] {y};
    \node (3) [below = of 2] {z};
    \path (1) edge  (2);
    \path (1) edge (2);
    \path (2) edge (3);
    \path (1) edge (3);
\end{tikzpicture}
\end{center}
%
The arrows above show the direction of influence; and the implication of $x\rightarrow y$ and $y \rightarrow z$ is that $x$ affects $z$ in two ways. First, it has (some) direct effect; and second, it can have indirect effect by influencing $y$, regulated by parameter $\rho$ as shown in \nameref{S3_Appendix}.

To make inferences about this mediated effect, we need more than one model. First, the regression of $z$ on $x$, i.e., the \emph{non-mediated} (or univariate) model which tells on the \emph{total} effect of $x$ on $z$; and second, the regression of $z$ on $x$ and $y$, i.e., the \emph{mediated} (or multivariate or full) model. We simulated the data as shown in \nameref{S3_Appendix} and fitted the two models -- non-mediated and mediated. In both cases, we compared mean-based and the whole-sample-based predictions, as shown in Fig~\ref{fig:pred_mediated_plots}.

\begin{figure}
\begin{center}
\includegraphics{mediate_preds.ggp.pdf}
\end{center}
\caption{{\bf Mean-based and whole-sample-based predictions for mediated effects for the mediated (multivariate) and non-mediated (univariate) models.} A: In the absence of mediator variable, both mean-based and whole-sample-based approaches predictions are identical since there is no any other additional (non-focal input variables) sources of bias. Consequently, for both approaches, the average predicted probability is very close to the observed proportion. B: When the mediator variable is included,  $x$ has no direct effect on $z$ and as a result the predictions do not align with the observations. However, the whole-sample-based approach still closely approximates the average proportion in the simulated data. The horizontal dashed lines are the respective average predictions and observed proportions. The vertical dashed black represents the center point, and the point at which it crosses the horizontal lines represents the expected ``perfect'' prediction at the model center. The grey points are the binned observations.}
\label{fig:pred_mediated_plots}
\end{figure}

From Fig~\ref{fig:pred_mediated_plots}A, we see what we would expect in the absence of additional sources of bias, even though in the simulation, the effect of $x$ on $z$ is mediated through $y$. This is the total effect of $x$, which only tells us the influence of $x$ on $z$. By ignoring $y$ in the model, we are still able to capture the effect of $x$ and closely match the observed values using both approaches. However, if there were additional non-focal predictors, we would expect to see the differences similar to those in Fig~\ref{fig:pred_bin_plots}A. Including both $y$ and $x$ ``dilutes'' the direct effect of $x$ on $z$ and as a result, our predictions do not necessarily match the observed binned observations (see Fig~\ref{fig:pred_mediated_plots}B).

\section{Discussion}

Our simulations examples focused on simple linear and logistic models due their wide range of usage and application. These models also act as a starting point for building other complex models, including mixed effect models and models with categorical predictors. The logic for extending to more complex models, including other forms of nonlinear link functions is very straightforward. In fact the components needed for extension are the correct linear predictor and the inverse link function; everything else generalizes. In addition, our \proglang{R} package implementation already extends to and supports most of the nonlinear link functions and mixed model framework, including multivariate binary outcome models.

Although commonly used \proglang{R} software packages, by default, implements mean-based approach, our simulation results demonstrated that the whole-sample-based approach has a potential of yielding results which are more consistent with the observed data. We would, therefore, argue that the use of mean-based approach should have some theoretical justification, especially in complex models. 

\section{Conclusion}

Generating outcome predictions or predicted probabilities from simple and generalized linear (mixed) models is not only important but also, generating quantities which are consistent with the observed values should be of interest. However, many studies still report coefficient estimates from generalized models like probit, logistic, etc., \citep{hanmer2013behind}, which are subject of less clarity and complexities in interpretation.

The argument and results we present in this paper support a greater need for a shift on focus on how to present predictions from generalized models. For example, the effect-styled confidence intervals could provide more clarity concerning the uncertainty due to the input variable of interests as opposed to the conventional way of incorporating everything. 

From our theoretical, methodological and simulation results, researchers using these kind of models should, in the absence of theoretical justification, report predictions based on whole-sample-based approach or at least attempt to do a comparison of the two approaches before settling on the most appropriate in answering their research question. Moreover, we provide \proglang{R} package, \pkg{vareffects}, which implements these methods and is available on github (\href{https://github.com/mac-theobio/effects}{https://github.com/mac-theobio/effects}).


\section{Supporting information}

% Include only the SI item label in the paragraph heading. Use the \nameref{label} command to cite SI items in the text.
\paragraph*{S1 Appendix.}
\label{S1_Appendix}
{\bf Cubic polynomial interaction simulation.} Consider an hypothetical simulation which simulates household size as a function of household wealth index and cubic function of the age of the household head, specified as follows:

\begin{align}\label{sim:lm_cubic}
\mathrm{hh~size}_i &= \beta_0 + \beta_{\mathrm{A_1}}\mathrm{Age}_i + \beta_{\mathrm{A_2}}\mathrm{Age}^2_i + \beta_{\mathrm{A_3}}\mathrm{Age}^3_i + \beta_{\mathrm{W}}\mathrm{Wealthindex}_i + \epsilon_i \nonumber\\
\mathrm{Age}_i &\sim \mathrm{Normal}(0, 1) \nonumber\\
\mathrm{Wealthindex}_i &\sim \mathrm{Normal}(0, 1) \nonumber\\
\epsilon_i &\sim \mathrm{Normal}(0, 10) \nonumber\\
\beta_0 &= 20 \nonumber\\
\beta_{\mathrm{A}_1} &= 0.1 \nonumber\\
\beta_{\mathrm{A}_2} &= 0.8 \nonumber\\
\beta_{\mathrm{A}_3} &= 0.3 \nonumber\\
\beta_{\mathrm{W}} &= -0.5 \nonumber\\
i &= 1,\cdots, 100
\end{align}


\paragraph*{S2 Appendix.}
\label{S2_Appendix}
{\bf Binary outcome simulation.} Consider a simple simulation for improved water quality in Nairobi slums, such that the status is $1$ for improved and $0$ for unimproved water quality. In additional to the focal predictor, age of the household head, we add wealth index. In particular:

\begin{align}\label{sim:glm_two_pred}
\mathrm{status}_i &\sim \mathrm{Bern}(\mathrm{P_i}) \nonumber\\
\mathrm{logit}(\mathrm{P_i}) &= \eta_i \nonumber\\
\mathrm{\eta}_i &= \beta_0 + \beta_{\mathrm{A}}\mathrm{Age}_i + \beta_{\mathrm{W}}\mathrm{Wealthindex}_i \nonumber\\
\mathrm{Age}_i &\sim \mathrm{Normal}(0, 1) \nonumber\\
\mathrm{Wealthindex}_i &\sim \mathrm{Normal}(0, 1) \nonumber\\
\beta_0 &= 5 \nonumber\\
\beta_{\mathrm{A}} &= 0.5 \nonumber\\
\beta_{\mathrm{W}} &= 1.5 \nonumber\\
i &= 1,\cdots, 10000
\end{align}

\paragraph*{S3 Appendix.}
\label{S3_Appendix}
{\bf Mediated effect simulation.} Next, we consider a simple indirect mediation previously described and simulate a binary outcome model such that:

\begin{align}\label{sim:simple_mediate}
z_i &\sim \mathrm{Bern}(\mathrm{P_i}) \nonumber\\
\mathrm{logit}(\mathrm{P_i}) &= \eta_i \nonumber\\
\eta_i &= \beta_0 + \beta_{xz} x_i + \beta_{yz} y_i \nonumber\\
y_i &= \rho x_i + \sqrt{1-\rho^2} y_y \nonumber\\
x_i &\sim \mathrm{Normal(0, 1)} \nonumber\\
y_y &\sim \mathrm{Normal(0, 1)} \nonumber\\
\rho &= 0.8 \nonumber\\
\beta_0 &= 5 \nonumber\\
\beta_{xz} &= 0.2 \nonumber\\
\beta_{yz} &= 1.5 \nonumber\\
i &= 1,\cdots, 10000
\end{align}


\section*{Acknowledgments}

This work was supported by a grant to Jonathan Dushoff from the Natural Sciences and Engineering Research Council of Canada (NSERC) Discovery.

\section*{Author Contributions}

\textbf{Conceptualization:} Jonathan Dushoff

\noindent\textbf{Software:} Steve Cygu, Benjamin M. Bolker

\noindent\textbf{Writing – original draft:} Steve Cygu


\nolinenumbers
