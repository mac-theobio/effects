%% Main tex

\linenumbers

% Use "Eq" instead of "Equation" for equation citations. 
%% BC: use \EREF{} for equations and \FREF{} for figures
%% JD: Why do you capitalize these? It's scary.
% Best to use a command that combines the name and the reference
\section{Introduction}

Plots of predicted values of an outcome against predictors (often called effect plots or prediction plots) are often a useful way to summarize the results of a regression model. These can be used to illustrate model uncertainty or to give a more explicit quantitative sense of how the outcome is expected to change. In generalized models with a non-linear link function, or models with a spline or polynomial response to a predictor variable, they can also aid in understanding difficult-to-interpret coefficient estimates \citep{brambor_understanding_2006, berry_improving_2012, leeper2017interpreting}. 

To make an outcome plot, we use a \emph{focal} predictor on the x-axis and central estimate (predicted values) on the y-axis. The resulting plot will depend on choices we make about other (non-focal) predictor(s). In ordinary (Gaussian) linear regression, the non-focal choices may have a simple additive effect on the central estimate. However, when the focal predictor has interactions or a non-linear link function, non-focal choices can also affect the slope of the estimate. Additional challenges arise when dealing with “mixed” models, which incorporate random effects.

As noted, the outcome plots described above are often called prediction plots or effects plots. We endeavor here to make a conceptual distinction. 
The primary distinction between the two lies in how we describe the uncertainties around the central estimate. 
If our goal is to \emph{predict} what we learn about the outcome variable by measuring the focal predictor, then we may want to capture a variety of sources of uncertainty, including that due to the intercept, focal and non-focal predictors, and random effects.
Conversely, if we wish to focus on the \emph{effect} of a focal predictor only, we might want to isolate uncertainty due to coefficients associated with that predictor.
If we follow this convention, we expect effects plots to have narrower confidence intervals (CIs) than prediction plots.

The other distinction relates not to the method of calculating CIs, but to the model chosen for the plot. 
In general, if we want to predict based on a focal parameter, we are likely to want to fit a univariate model, that only contains terms related to that predictor.
If we want to know the effects of a predictor, we may want to control for covariates with a multivariate model, in order to estimate “direct” effects, or leave covariates out, in order to estimate “total” effects (direct plus indirect), or take an intermediate strategy.
Shi et al. \citep{shi_evidence_2017} used multivariate effects plots to visualize estimated direct effects of different predictors in a paper that compared the difference in sexual risk behaviors between circumcised and uncircumcised men.

Generating quantities, i.e., central estimate together with the corresponding confidence intervals has some challenges. In particular:
\begin{enumerate}
\item choosing the \emph{reference point} for non-focal predictors in multivariate models
\item uncertainty estimation -- appropriate choice of \emph{anchor} for computing confidence intervals in effects plots
\item \jd{When is this a challenge? Doesn't it just work like magic with the lm machinery? and how to incorporate the uncertainty due to non-focal predictors} \BC{Clarify with JD. Another challenge or a continuation  of the above?} 
\item biases induced by non-linear transformations of the response variable in generalized models (especially generalized mixed models).
\item choice of representative values of the focal predictor \jd{I still don't see this as much of a challenge.} \dya{We needed to mention somewhere that we also have to choose focal values. I think \P~ below is suffecient.}
\end{enumerate}

Representative values for a focal predictor are generally chosen using quantiles, or equally spaced values, for a continuous predictor; or an exhaustive set of levels for a categorical predictor.
The central estimates are then calculated by holding the non-focal predictors at a reference point (a value chosen for a non-focal predictor) while varying the focal predictor, with the goal that the estimates represent how the model responds to the changes in the focal predictor \citep{fox2009effect, hanmer2013behind}. These values have been called: \emph{predictor effects} \citep{fox2009effect}, \emph{marginal predictions} \citep{leeper2017package} or \emph{estimated marginal means} \citep{lenth2018package} \jd{Is this also the same as least-squares means?} \BC{Yes. But was later renamed to emmeans}. In this article, we refer to these quantities as the \emph{central estimates} of the outcome. 

In models with non-focal predictors such as multivariate models, reference point can be chosen as the average of the non-focal \emph{model variables} -- we call this approach \emph{mean-based} reference point and is currently not implemented in commonly used \proglang{R} software packages. The mean of the central estimates is the prediction at the \emph{model center}. We introduce an alternative choice for the reference point below.

For linear models, the averaging is done on the linear scale, i.e., linear averaging. As a result, the \emph{bias} in model center estimates can easily be corrected using mean-based approach and the estimates are usually consistent with the observed values. However, in models with non-linear link functions, this is not always the true. In particular, when dealing with generalized models with non-linear link functions, the averaging is done on the non-linear scale, i.e., non-linear averaging, making generating correct predictions much harder. This is the bias in the expected mean prediction induced by the non-linear transformation of the response variable. One way to address this is to make predictions on the linear predictor scale and back-transform to the original scale. However, the back-transformation may either result in biased predictions or requires some approximation, for example, second-order Taylor approximation implemented in \pkg{emmeans} \citep{lenth2018package}. An alternative to the mean-based reference point is the \emph{observed-value-based} approach, discussed in detail later, which involves computing the prediction over the population of non-focal predictors and then averaging across the values of the focal predictor \citep{hanmer2013behind}. 

This article aims to discuss and implement various approaches for computing predictions and effects, together with the associated plots. We further explore and demonstrate, using simulated data, approaches for correcting bias in central estimates for generalized (mixed) models involving non-linear link functions. The proposed method and \proglang{R} software package will complement the existing ones by providing: 1) a straightforward way to generate effects, and 2) an alternative and a more robust way to correct for prediction bias in generalized (mixed) models.

\jd{We should revisit this list.}

\section{Definitions}

In order to discuss the statistical background and mathematical formulation of the proposed approaches, we need to understand and formally define a number of terms, some of which have been introduced in the previous section:

\jd{I guess this list should really be a desc, not an itemize.}\BC{Clarify}

\begin{itemize}
\item \textbf{Input variables:} Refers to the observed (or scientific) variables underlying an inference or exploration. For example, the regression models described by \EREF{simple_inter_higher_no_interaction} and \EREF{simple_inter_higher} both have $3$ input variables -- $x_1, x_2, x_3$.
\item \textbf{Focal predictors}: We call the input variable on the x-axis of an outcome plot the focal predictor.  Any other predictor variables are ``non-focal'' predictors. 

\item \textbf{Model matrix:} Refers to the design matrix whose rows include all combination of input variables. Consider an example for three hypothetical households -- the first household head is a Christian with an income of $\$ 50$, the second household head is Muslim with an income of $\$ 100$ while the third household head is a Jew with an income of $\$ 77$. Suppose we want to model the household size (\code{hhsize}) as function of these household characteristics, i.e., $$\mathrm{hhsize} = \beta_0 + \beta_1\times\mathrm{income} + \beta_{2[r]}\times\mathrm{religion} + \mathrm{error}.$$ The model matrix corresponding to this model is given by
$$\begin{bmatrix}{}
 Intercept & income & religionJew & religionMuslim \\
 1 & 50 & 0 & 0 \\
  1 & 100 & 0 & 1 \\
  1 & 77 & 1 & 0 \\
\end{bmatrix}.$$ The first column represents the constant term in our model, $\beta_0$. For continuous input variables, the representation in the model matrix is the same as the corresponding input variables (for example second column representing income). For categorical variables, however, by default, the model matrix  creates additional dummy variables using the reference cell parameterization. This means that, if an input variable has $L$ factor levels, then there will be $L-1$ dummy columns representing all but the first level created in the model matrix. In our example, the column \code{religion} is missing and instead we have \code{religionJew} and \code{religionMuslim}; the missing category \code{religionChristian} is treated as the reference category.

\item \textbf{Linear predictor variables}: Refer to the variables which are combined to make the linear predictor (corresponding to the columns in the model matrix). Each input variable may correspond to one or more model variable. Input variables with more than two categories (for instance religion in our previous example), or input variables with non-linear response functions (e.g., spline or polynomial) will correspond to more than one linear predictor variable -- we call such variables “multi-parameter variables”.

\item \textbf{Model center:} A point corresponding to a column-wise mean of the model matrix (the mean of one or more model variables). Also referred to as center point. The center point for a set of model variables corresponding to an input variable may not represent a possible value of the input variable -- the case in \FREF{justify_plots}B. In simple linear models with no interactions, the mean of the input variable can be used is a center point. If there are more than one model variables associated with the focal input variable, however, the model center does not correspond to a single value of the focal predictor, see \FREF{pred_cubic_plots}.


\item \textbf{Reference point:} The values (or sets of values) chosen for non-focal predictors, when estimating the predictions and effects. Typically the center point, but can also be chosen as a baseline value or as a mean across categories. We will also discuss using a set of quantiles or observations as a reference.

\item \textbf{Anchor:} The value chosen for the focal predictor when estimating effect-style confidence intervals. The anchor choice does not affect the central estimates, nor prediction-style. Often chosen as the center point of the linear predictor variables corresponding to the focal predictor. 

\item \textbf{Prediction-style and effect-style plots:} A prediction-style plot is about predicting observations for a given value of the focal predictor. For this, we want to use the classic curved confidence intervals. An effect-style plot attempts to visualize the effect of a focal predictor and are characterized with narrower confidence intervals. Unlike a prediction-style plot, where the confidence intervals capture the uncertainty associated all predictors in the model, the effect-style plot focuses on uncertainty associated with the focal predictor only and depend on the anchor.

\end{itemize}

\section{Statistical formulation}

\jd{This should be more general. The natural way to do the comparison is to first write out the two ways of averaging, and then point out that they're the same when $g$ is the identity. In other words, do the general derivation before making the assumption. It doesn't ever seem good to write $g$ and then \emph{define} it as the identity.}

\BC{Trying to adopt new notation style, is this better?}

To estimate the central estimate of an outcome plot on the response scale, we need a link function $g$ and appropriate values of the focal predictor $X^{f}$ and reference point for the non-focal predictors $\uset{{\bX}}$. As previously mentioned, we can either use mean-based or observed-value-based reference point. 

Using mean-based reference point, the central estimate is
%
\begin{align}\label{eq:eta_linear_mean}
\etahfi &= \bbetah \bX^{f}_c \nonumber\\
\yfi &= g^{-1}(\etahfi),
\end{align}
%
where $\bX^{f}_c = \{X^{f}, \uset{{\bX}}_c\}$ is a centered model matrix with appropriately chosen values of the focal predictor $X^{f}$ and centered non-focal linear variables $\uset{{\bX}}_c$ constructed by replacing the entries in the corresponding columns with their averages. 

On the other hand, using observed-value-based reference point, \EREF{eta_linear_mean}
becomes
%
\begin{align}\label{eq:eta_linear_sample}
\etahfj &= \bbetah \bX^{f}_j \nonumber\\
\yfi  &= \underset{j}{\textrm{mean}} ~ g^{-1} (\etahfj),
\end{align}
%
where $\bX^{f}_j = \{X^{f}_j, \uset{{\bX}}\}$ is the model matrix of the $j$th
observation and $\uset{{\bX}}$ is the entire population of the non-focal linear
predictors. Here, we generate a vector of size $J \times N$ and then average over the values of the focal predictor; $J$ and $N$ represents the number of focal values and population of non-focal predictors, respectively.

For identity link function, e.g., in a simple linear model, \EREF{eta_linear_mean} and \EREF{eta_linear_sample} are equivalent. In the subsequent sections, we will first discuss general formulation of mean-based approach and how to generate associated confidence intervals. Thereafter, we will discuss the second approach, who-sample-based, and its application to bias correction.


\subsection{Mean-based approach}

An alternative formulation of \EREF{eta_linear_mean} involves expressing the linear predictor as the sum of the focal and non-focal predictors' linear predictors. In particular, 
%
\begin{align}\label{eq:eta_mean}
\etahfi(x^f, \uset{{\bar{x}}}) &= \hat{\beta}^f x^f + \sum \uset{\hat{\beta}} \uset{{\bar{x}}} \\
\yfi  &= g^{-1} \left(\eta_i(x^f, \uset{{\bar{x}}})\right)
\end{align}
where $x^f$ and $\uset{{\bar{x}}}$ are columns of $\bX^{f}_c$ focal predictor and non-focal predictors, respectively.

In a model with a multi-parameter variable or input variables with complex interactions, construction of $\etahfi(x^f, \uset{{\bar{x}}})$ is not usually straightforward since we want $\uset{{\bar{x}}}$ to be or represent the ``true'' model center. We therefore illustrate some of these cases.

\subsubsection{Dealing with multi-parameter variables}

\jd{I feel the first s.~is perfectly clear, and I don't know why it needs any explanation at all.}
\BC{I suggest we keep the illustrations.}

Multi-parameter variables (MPVs) such as splines, polynomials, etc., can be within the focal predictor, or within non-focal predictor(s). To distinguish the two, suppose the model which describes the hypothetical simulation of household size based on a number of socio-demographic factors such as age and wealth index is
%
\begin{align}\label{eq:lm_cubic}
\mathrm{hh~size}_i &= \beta_0 + \beta_{\mathrm{A_1}}\mathrm{Age}_i + \beta_{\mathrm{A_2}}\mathrm{Age}^2_i + \beta_{\mathrm{A_3}}\mathrm{Age}^3_i\nonumber \\
&+ \beta_{\mathrm{W}}\mathrm{Wealthindex}_i + \epsilon_i.
\end{align}
%
In the first case, with \code{Age} as the focal predictor, is a cubic polynomial with three linear predictor variables ($\mathrm{Age}_i, \mathrm{Age}^2_i$ and $\mathrm{Age}^3_i$). In this case, each linear predictor variable is evaluated separately across the chosen levels of the focal predictor, $Age_i$. Specifically, the linear predictor variables are treated as additional columns of the model matrix evaluated with the same values chosen for the focal predictor, while non-focal predictors are fixed at their reference point as discussed in the previous section. The central estimates associated with \code{Age} on the linear predictor scale become
%
\begin{align}
\etahfi(\mathrm{Age}_i, \nset{{\over{\mathrm{Wealthindex}}}}) &= \betah_0 + \betah_{\mathrm{A_1}}\mathrm{Age}_i + \betah_{\mathrm{A_2}}\mathrm{Age}^2_i + \betah_{\mathrm{A_3}}\mathrm{Age}^3_i \nonumber\\
	& + \betah_{\mathrm{W}}\over{\mathrm{Wealthindex}}.
\end{align}
%
In the second case, with \code{Wealthindex} as the focal predictor, the non-focal predictor, \code{Age}, is a cubic polynomial. In this case, the non-focal linear predictor variables ($\mathrm{Age}_i, \mathrm{Age}^2_i$ and $\mathrm{Age}^3_i$) are all treated as separate non-focal linear predictor variables and an appropriate choice of reference point applies just like in the models without MPVs. For instance, in mean-based approach, we average all non-focal MPVs. Thus
%
\begin{align}\label{eq:mpv_second}
\etahfi(\mathrm{Wealthindex}_i, \nset{{\{\over{\mathrm{Age\mathop{\vphantom{^2}}}}, \over{\mathrm{Age}^2}, \over{\mathrm{Age}^2}\}}}) &= \betah_0 + \betah_{\mathrm{A_1}}\over{\mathrm{Age\mathop{\vphantom{^2}}}} + \betah_{\mathrm{A_2}}\over{\mathrm{Age}^2} + \betah_{\mathrm{A_3}}\over{\mathrm{Age}^3}\nonumber\\
	& + \betah_{\mathrm{W}}\mathrm{Wealthindex}_i.
\end{align}
%

\subsubsection{Dealing with interactions in input variables}

Interactions can be between non-focal predictor or between focal and non-focal
predictors. Handling former case is similar to that of the second case
in MPVs (\EREF{mpv_second}). In the latter case, consider model described by \EREF{simple_inter_higher}. The interaction is between the focal, $x_2$, and non-focal, $x_3$, predictors. In this case, we chose the values of the focal predictors as previously described and the reference point for the interacting non-focal predictor is predetermined or appropriately chosen set of values. In our example, suppose we pick $i$ and $j$ unique values of the focal predictor, $x_2$, and interacting non-focal predictor, $x_3$, respectively. The central estimate on linear predictor scale is given by
%
\begin{align*}
\etahfi(x_{2i}, x_{3j}, {\uset{\bar{x}}_1}) = \betah_0 + \betah_1 \uset{\bar{x}}_1 + \betah_2x_{2i} + \betah_3x_{3j} + \betah_{23}x_{2i}x_{3j}.
\end{align*}
%
The main point is that, in the case of non-interacting non-focal predictors, the reference point is a center point while in the case of interacting non-focal predictors, the choice of the reference point is not necessarily a center point but can be any appropriate value or set of values.

\subsection{Uncertainty estimation}

We describe the uncertainty around the estimates using confidence intervals (CIs). In principle, every prediction has a different CI. The conventional way to compute variances for predictions is 
%
\begin{align}\label{eq:conventional_variance}
\sigma^2_i = \mathrm{Diag}(\bXstar \boldsymbol{\Sigma} {\bXstar}^\top), 
\end{align}
%
so that the confidence intervals are $\etahfi \pm q\sigma_i$, where $\boldsymbol\Sigma$ is the variance matrix of $\bbetah$ and $q$ is an appropriate quantile of Normal or t distribution \citep{fox2009effect}. This generates conventional CIs which incorporate all the uncertainties -- including the uncertainties due to the intercept and non-focal predictor. We call this prediction-style CIs. 

\subsubsection{Effect-style CIs}

But what if we are interested in the uncertainty as a result of the focal predictor only (effect-style CIs), so that the CIs are $\etahfi \pm q\sigma^f_i$, i.e., effects? For effect-style CIs, we need an anchor and centered model matrix with all non-focal predictor variables set to zero. 

Let $\bxo$ be a centered model matrix previously defined, and let $\ba$ be an anchor matrix, with the same dimensions and entries in all non-focal predictors as $\bxo$. Let $\baf$ be the column of $\ba$ corresponding to focal predictor(s) defined in $\bxo$. Any appropriate values can be chosen for $\baf$ but for model center (center-anchored), we use $\bafc$ which is the mean of the focal predictor(s). Thus 
%
\begin{align}\label{eq:centered_variance}
\boldsymbol\sigma^2_i = \textrm{Diag}((\bxo - \bafc) \boldsymbol{\Sigma} (\bxo - \bafc)^\top).
\end{align}
%
We can see that $\forall ~\bxof=\baf$, $\bxo - \baf = \boldsymbol 0$, hence $\boldsymbol\sigma_i^2 = \boldsymbol{0}$. Similarly, for all values of $\bxof$ close to anchor point $\bafc$, the term $(\bxo - \bafc)$ and $\boldsymbol\sigma_i^2$ goes to $\boldsymbol 0$ and $\boldsymbol\sigma_i^2 = \boldsymbol 0$ if $\bxof=\bafc$. This means that $\boldsymbol\sigma_i^2$ close to the anchor point are smaller than those away from the anchor point; and results to confidence intervals which are narrower around the anchor or crosses at the anchor point for simple models. In other words, this shows the effect of changing the focal value from the anchor value. By setting $\baf = \boldsymbol 0$, we get the variances for the prediction-style CIs in \EREF{conventional_variance}.

An alternative way to compute $\boldsymbol\sigma^2_i$ in \EREF{centered_variance} is
by \emph{zeroing-out} the covariance matrix, which involves setting all the non-focal
linear predictor variables in $\Sigma$ to $0$. This procedure can be implemented 
in commonly used \proglang{R} packages for effect plots and prediction plots, but only
works when the input variables are \emph{centered} prior to model fitting, in case of
numerical variables, and more complicated when the input variables are categorical. 
The anchor approach, however, does not require the input variables to be centered
prior to model fitting since the computation of $\bxo - \bafc$ affects only the 
intercepts and non-focal predictor linear variables -- the slopes and variance
corresponding to the focal predictor linear variables are not affected. 

%% \subsection{Is center-anchored better?}
%% 
%% We want to compare the amount of uncertainty when there is/no anchor. Let $\bao = \boldsymbol{0}$ be the anchoring matrix with all entries in $0$s, and let $\bafc$ be the center-anchored matrix defined above. Then entries in $(\bxo - \bao) \geq (\bxo - \bafc)$.
%%

\section{Bias correction}

We can directly compare the outcome estimate at the model center for non-focal parameters (mean-based estimate) with the average of predictions evaluated across the population values of non-focal predictors (sample-based estimate, the colon below indicates that we are comparing two quantities):
%
\begin{align}\label{eq:compare_anchored_pop_based}
g^{-1} \left(\eta_j^\star(\bar{x}_f, \nset{\bar{x}})\right) : \frac{1}{n} \sum_{i=1}^n{ g^{-1} \left(\eta_j^\star(\bar{x}_f, \nset{x})\right)}.
\end{align}
%
In an ordinary linear model, the link function $g$ is the identity function, so the two means are the same. For non-trivial link functions, we expect them to be different in general.

From Jensen's inequality, the exponential link function, for example, is concave up; hence we expect the right-hand side of \EREF{compare_anchored_pop_based} to be greater than the left-hand side, i.e., the average of the predictions is greater than the prediction at the average of the focal and non-focal parameters. On the other hand, the logistic function is concave up and concave down at low and high probabilities, respectively. We expect a pattern similar to that of exponential function when the logistic function is concave up and the opposite when the logistic function is concave down. In other words, the mean-based approach can under-estimate the prediction in exponential and low probability logistic function and over-estimate in high probability logistic function.

When dealing with nonlinear link functions,  generated estimates may not reflect the observed response due to the bias in the expected mean induced by the nonlinear transformation of the response variable -- as illustrated by the two examples above. In such cases, bias correction is needed when back-transforming the estimates to the original scales. The common approach for bias-adjustment is second-order Taylor approximation \citep{duursma2003bias, hanmer2013behind}; already implemented in \pkg{emmeans} \citep{lenth2018package}. Here, we describe and implement a different approach -- observed-value-based approach for bias correction. Hanmer and Kalkan \citep{hanmer2013behind} discuss and implement mean- and observed-value- based approaches in binary response models only. Our formulation is more general and can easily be extended to other link functions other than logistic. 


\subsection{Observed-value-based approach for bias correction}

An alternative approach to choosing a reference point is to make predictions over all observations of the non-focal predictors (members of the population) \citep{hanmer2013behind}. The nonlinear transformation involved in these computations is always \emph{one-dimensional}; all of the multivariate computations required are at the stage of collapsing the multidimensional set of predictors for some subset of the population to a one-dimensional distribution of $\etahfi(x_f, \nset{x})$, which is a function of the chosen values of the focal predictor and the whole sample of non-focal predictors, as opposed to the definition in \EREF{eta_mean}. More specifically:
\begin{itemize}
\item compute linear predictor associated with whole sample of the non-focal predictors, $\etanfj = \sum \uset{\hat{\beta}} \uset{x}$
\item compute linear predictor associated with the chosen values focal predictor, $\etahfi = \hat{\beta}^f x^f$
\item for every value of the focal linear predictor, $\etahfi$, compute
%
\begin{align}\label{eq:pop_eta} 
\etahfj(\etahfi, \etanfj)  &= \etahfi + \etanfj \nonumber \\
&= \etahfj(x^f, \uset{x}).
\end{align}
\end{itemize}
%
HERE

Once \EREF{pop_eta} is computed, we back-transform the estimates to the original scale and average over the levels of the focal predictors, $j$:
%
\begin{align}\label{eq:pop_response} 
\yfi  &= \underset{j}{\textrm{mean}} ~ g^{-1} \left(\etahfj(x^f, \uset{x})\right).
\end{align}
%

We make similar adjustments to compute the variances of the predictions at every level of the focal predictor:
%
\begin{align}
\sigma_j^2 = \textrm{Diag}(\bX^{f}_j \boldsymbol{\Sigma} {\bX^{f}_j}^\top)
\end{align}
%
and
%
\begin{align}
\mathrm{CI}_i = \underset{j}{\textrm{mean}} ~ g^{-1} \left(\etahfj(x^f, \uset{x}) \pm q\sigma_{j}\right).
\end{align}
%

For models with random effects components, we make further adjustment to correct for bias induced by the random effects terms. In observed-value approach, we treat the random effects terms as additional non-focal predictors and simply make adjustment to \EREF{pop_eta}. In particular
%
\begin{align}\label{eq:pop_eta_re} 
\uset{\tau} &= \bZ b \nonumber \\
\etahfj(x^f, \uset{x}, \uset{\tau})  &= \etahfj(x^f, \uset{x}) + \uset{\tau}
\end{align}
where $\bZ$ and $b$ are the design matrix and a vector of random effects, respectively.

\section{Mean-based vs. observed-value-based}

In the observed-value-based approach, the ensemble of predictions and CIs are back-transformed before averaging, see \EREF{pop_response}, so we do not need to worry about the nonlinear averaging. In other words, the averaging is no longer on the link scale and is likely to be bounded by the original data scale. In simple linear models without interactions, averaging on the link scale is identical to averaging on the response, so both approaches yield similar results. However, picking a single value, e.g., the mean of the predictor, on which to draw conclusions about the effect can be problematic, unrealistic, or not contained in or representative of the population. In addition, the mean-based approach fails to use every value of non-focal predictors hence not utilizing the full potential of the information contained in the data. This may limit the inferences we can make about the entire population. In general, the mean-based approach provides the predictions of an average case, whereas the observed-value-based approach summarizes the predictions over the entire population. In some applications, the effect of an average case might not be generalizable to the entire population, especially, if the average does not represent the population. This might not be a problem in the observed-value-based approach since it focuses on specific observations -- the prediction is first obtained for each observation and then averaged across the levels of the focal predictor.

Another potential concern with the mean-based approach arises when direct naive use leads to a rare or meaningless basis for generalization. For example, if our sample has 20\% Jews, 30\% Muslims, and 50\% Christians. One approach (default in common packages) is assigning equal category weight, i.e., 1/3 Jews, 1/3 Muslims, and 1/3 Christians (the ``sum-to-zero'' approach). The second approach (our default) is setting dummy categorical variables in the model matrix to their means, which, by default, set them to their sample means or observed proportions. The first or second approach translates to prediction for a household head who is 1/3 or 50\% Christian, respectively \citep{hanmer2013behind}. The second approach seems more realistic and will converge to the population mean in many cases.

The observed-value-based approach is not entirely foolproof. For instance, similar to the mean-based approach, in the case of continuous focal predictors, choosing the representative values of the focal predictors can be very challenging, especially if the cases are not evenly distributed around the minimum and the maximum values or within some subgroups defined in the population. In addition, the observed-value-based approach can be computationally intensive for large datasets.



\section{Simulation examples}

We start by comparing our proposed approach with the existing implementations and then illustrate the construction of outcome plots and also demonstrate that the mean-based and observed-value-based approaches produce different results in models with nonlinear link functions and/or additional source(s) of potential bias. In addition, we demonstrate that observed-value-based approach can be used for bias correction.

\subsection{Comparison with other implementations}

The most commonly used \proglang{R} software packages for outcome plots (\pkg{emmeans} and \pkg{effects}), by default, use the average of input variables and ``sum-to-zero'' as the reference point approach for continuous and categorical input variables, respectively. However, there are a number of choices one can make when constructing outcome plots -- for example, in the presence of interactions, averaging the interactions (averaging the product of linear predictor variables) versus taking the product of the averages of the input variables (the default for \pkg{emmeans} and \pkg{effects}). For simple OLS models (with no interactions), the two approaches give the same estimates. However, for complex models, we demonstrate that the two approaches can produce substantially different results and show that averaging the interactions closely matches the observed values. To illustrate this, consider models~\ref{eq:simple_inter_higher_no_interaction} and \ref{eq:simple_inter_higher} below, with $x_1$ as the focal predictor:
%
\begin{align}
y &= \beta_0 + \beta_1x_1 + \beta_2x_2 + \beta_3x_3 + \epsilon \label{eq:simple_inter_higher_no_interaction}\\
y &= \beta_0 + \beta_1x_1 + \beta_2x_2 + \beta_3x_3 + \beta_{23}x_2x_3 + \epsilon \label{eq:simple_inter_higher}.
\end{align}
%
We first simulate data with the two models, such that $x_{1,2,3} \sim \mathrm{Normal}(0, 1)$, $\beta_0 = 5$, $\beta_1 = -3$, $\beta_2 = 1$, $\beta_3 = 2$, $\beta_{23} = 5$, $\epsilon \sim \mathrm{Normal}(0, \sigma^2)$ and $\sigma^2 = 1$, and then compare estimates from the \pkg{emmeans}, \pkg{effects} and our proposed alternative (\pkg{varpred}) to the ``true'' central estimates (based on the true simulation parameters) and observed average, i.e., $\bar{y}$, as shown in \FREF{justify_plots}.
%
\begin{figure}
\begin{center}
\includegraphics{justify_preds.inter.pdf}
\end{center}
\caption{{\bf A comparison of \pkg{emmeans}, \pkg{effects} and \pkg{varpred} central estimates for regression of $x_1$ on $y$ (outcome plots).} The horizontal dashed lines are the mean of the central estimates and simulated $y$, $\bar{\hat{y}}$ and $\bar{y}$, respectively. The grey points are the binned simulated $y$. The trend lines represent the corresponding $\hat{y}$ at various levels of $x_1$, while holding the other input variables at their mean and the true predictions based on the simulation parameters -- central estimate. A: In the absence of interaction, the predicted mean, $\bar{\hat{y}}$, closely matches the simulated one in all the three approaches, i.e., $\bar{y} \approx \bar{\hat{y}}$. Similarly, the central estimate based on the three approaches match the truth. B: Even with the simple interaction between non-focal predictors, we see differences between predicted mean, $\bar{\hat{y}}$ and simulated mean , $\bar{y}$. Similarly, there are differences between central estimates and the truth, in two commonly used packages (\pkg{emmeans} and \pkg{effects}), but not the proposed \pkg{varpred}.}
\label{fig:justify_plots}
\end{figure}
%
In the absence of interactions (\EREF{simple_inter_higher_no_interaction}), the three approaches produce the same estimates, which match the simulated values, \FREF{justify_plots}A. However, in the presence of interactions, even as simple as the one in \EREF{simple_inter_higher}, the estimates start to differ. In particular, \pkg{emmeans} and \pkg{effects} have similar estimates ($\bar{\hat{y}}$) but different from the \pkg{varpred}'s which, however, is very close to the simulated average ($\bar{y}$), \FREF{justify_plots}B. To generate \FREF{justify_plots}A,  \pkg{emmeans} and \pkg{effects} average $x_2$ and $x_3$, i.e., the input variables while \pkg{varpred} averages the linear predictor variables corresponding to $x_2$ and $x_3$. On other hand, to generate \FREF{justify_plots}B, the difference in the estimates lies on how each of the packages average the interaction linear predictor variable ($x_2x_3$). In particular, \pkg{emmeans} and \pkg{effects} use input variables to compute $\bar{x_2}\bar{x_3}$ while \pkg{varpred} uses linear predictor variables to compute $\over{x_2x_3}$. In the case of \FREF{justify_plots}A, averaging the input variables is equivalent to averaging the linear predictor variables.

One may be interested in the uncertainties associated with the focal predictor only, excluding other uncertainties due to other non-focal predictors -- effect plots. However, as previously mentioned, the two packages do not provide a straightforward way do achieve this. To illustrate this, we consider \EREF{simple_inter_higher_no_interaction} and use $x_2$ as the focal predictor, and generate the outcome plot shown in \FREF{justify_ci_plots}. 
%
\begin{figure}
\begin{center}
\includegraphics{justify_anchors_all.ggp.pdf}
\end{center}
\caption{{\bf Prediction and effect plots.} The description of horizontal, vertical and trend lines remain the same as above. A: The wider dashed curves corresponds to the conventional prediction curves from \pkg{emmeans} and \pkg{effects} packages, while the narrower curves crossing at the mean of the focal predictor, also referred to as the center point, represent the effect from \pkg{varpred}. For simple OLS models, the effect-styled curves cross at the center point (which is the default anchor and also referred to as center-anchored). The prediction-styled curves incorporates not only the uncertainties due to intercept term but also other non-focal predictors. On the other hand, effect-styled curves only take into account the main effect uncertainty of the focal predictor. B: center- and zero- anchored effects. The center-anchored effects (as described above) while the zero-anchored means that the anchor is at zero value of the focal predictor. The choice of the anchor do not affect the central estimates, hence they are identical in both choices of the anchor.}
\label{fig:justify_ci_plots}
\end{figure}
%
For \pkg{emmeans} and \pkg{effects}, the confidence intervals are much wider because they include uncertainties associated with the intercept and non-focal predictors, but narrower and crosses at the mean of the focal predictor in \pkg{varpred}. In other words, with \pkg{varpred}, we are able to generate effects indicating zero uncertainty at the value of the focal predictor we are more certain about, i.e., the anchor. For simple OLS models, the point where the curves cross is the model center or simply center point; it corresponds to anchor we choose, in this case, the center point (which is generally an appropriate and stable choice). 

Lastly, we compare effect plots and the marginal effects \citep{leeper2017interpreting} plots implemented in package \pkg{margins} \citep{lenth2018package}. To illustrate this, we use the simulated data described in \nameref{S1_Appendix}. The results are shown in \FREF{qoi_age_pred_plot}.
%
\begin{figure}
\centering
\includegraphics{cubic_varpred_margins_pred.ggp.pdf}
\caption{{\bf Effect and marginal effect plots.} \NEW{A:  The effect plot. B: The marginal effect (ME) at representative values of the focal predictor \code{age} together with the $95\%$ confidence intervals. For simple linear models with no interactions, the ME should be constant across all the values of the focal predictor; and it would correspond to the slope of the central estimate of central estimate. However, in this example, the focal predictor is a cubic polynomial, and so, the effect is not constant but a function of the partial derivatives of the corresponding linear predictor variables.}}
\label{fig:qoi_age_pred_plot}
\end{figure}
%


\subsection{Prediction and effect styled plots for MPVs}

To illustrate the distinction between predictions and effects in MPVs, we simulated a multivariate model described in \nameref{S1_Appendix}. We also used the same model to illustrate how predictions and effects differ if MPVs are in the focal or non-focal predictor. In particular, we generated two sets of mean-based predictions and effects: 1) one with \code{age} as the focal predictor (a cubic polynomial focal input variable); and 2) one with \code{Wealthindex} as the focal predictor (linear focal input variable). In both cases the, we used center point as the anchor for the effects, as shown in \FREF{pred_cubic_plots}.

\begin{figure}
\begin{center}
\includegraphics{cubic_predictors_preds.ggp.pdf}
\end{center}
\caption{{\bf Prediction and effect plots for cubic polynomial and simple focal predictors.} A: The focal predictor is a MPV cubic polynomial. B: The focal input variable is linear, with MPV non-focal predictor. The central estimates (dashed central curves or lines) are the same for predictions and effects, in each case (A and B). However, the effects are narrower than the predictions. The default anchor for generating effects is the center point. For linear (or simple) focal input variables, the center point is a point within the range of focal values; and therefore the effect curves intersect at that that point -- B. In the case of MPVs such as cubic polynomials, the center point is not a point but a combination of all the linear predictor variables associated with the cubic polynomial, consequently, curves will not necessarily cross at a point -- A. The horizontal black and red dashed lines are the observed and predicted average household size, i.e., $\over{hh~size}$ and $\over{\widehat{hh~size}}$, respectively.}
\label{fig:pred_cubic_plots}
\end{figure}

In the absence of, complex interactions, MPVs, or transformations on the focal input variable, in simple OLS models we would expect the observed average, $\over{hh~size}$, and the average of the predictions, $\over{\widehat{hh~size}}$, to be identical and intersect with the trend lines at the center point, for the effect plot. On the other hand, if the focal input variable is characterized by complex interactions, MPVs, or any other form of transformations, the center point is not necessarily a point in the range of focal input values. In this case, the effects will be narrower than the predictions plots but will not necessarily intersect. 


\subsection{Bias correction}

Mean-based and observed-value-based approaches can produce very different results in models with nonlinear link functions with additional sources of potential bias such as additional non-focal input variable(s), random effects or complex interactions. To demonstrate this, we considered a two predictor binary outcome simulation described in \nameref{S2_Appendix}, such that age has a very small effect size in comparison to wealth index, and compared their effects on the estimated probability of improved water quality as shown in \FREF{pred_bin_plots}. 

\begin{figure}
\begin{center}
\includegraphics{glm_two_predictor_preds.ggp.pdf}
\end{center}
\caption{{\bf Mean-based and observed-value-based central estimates.} The \emph{truth} is based on the true simulation parameters. If the focal predictor has a small effect size, mean-based and observed-value-based approaches produce different estimates -- A. In the case of strong effect size, however, the two approaches produce very close estimates -- B. In both cases, the observed-value-based estimates are closer to the truth. The difference in mean-based and observed-value-based is due to the bias induced by the non-focal predictor and the nonlinear link function in the logistic model. Mean-based approach suffers from nonlinear averaging; and if focal predictor has small effect size, the bias is even pronounced since the effect of nonlinear averaging is driven by the non-focal predictor(s) with the strong effect. However, this is not the case if the non-focal predictor(s) have small effect since the bias they induce is equally likely to be small. Since observed-value-based approach averages over the whole population of the non-focal predictor variables, it is less likely to be affected by the nonlinear averaging for the reasons already mentioned. The horizontal dashed lines correspond to the respective averages. The vertical dashed lines represent the center point, and the point at which they intersect the horizontal lines represents the expected ``perfect'' estimate at the model center. The grey points are binned observations -- observed proportions of improved water quality in each bin.} 
\label{fig:pred_bin_plots}
\end{figure}

If there was no effect of nonlinear averaging, then we would expect the average observed proportion and the average predictions to intersect at the center point as we see in \FREF{pred_cubic_plots}B. One possible reason for the variations we see in \FREF{pred_bin_plots} is the nonlinear averaging; since both observed status and predicted probabilities are averaged on the response scale as opposed to link scale. For example, if the range of values are bigger than $0.5$ (seemingly the case here), then we would expected the averages to be slightly higher than what we would expect at the center point.

In \FREF{pred_bin_prediction_effects_plots} below, we use \FREF{pred_bin_plots}A and compare the prediction and effect plots associated with the central estimates. 

\begin{figure}
\begin{center}
\includegraphics{glm_two_predictor_preds_effects.ggp.pdf}
\end{center}
\caption{{\bf Bias correction for prediction and effect plots.} In each case (A and B), the central estimates for predictions and effects are the same. These patterns are  consistent with the ones in \FREF{pred_bin_plots}A compared to the truth. Further, the predictions and effects exhibit patterns and generalize in a similar way to the ones in simple linear models.
}
\label{fig:pred_bin_prediction_effects_plots}
\end{figure}


\subsection{Mediated effect}

A \emph{mediated} effect is a situation in which only some of the input variables have a \emph{causal} impact on the outcome, even though all the variables are (somehow) associated with the outcome. For example, the age at marriage may be strongly associated with divorce rate but only married people divorce. So does marriage \emph{cause} divorce?

For simplicity, we consider an hypothetical simulation for three variables: input variables $x$ and $y$; and outcome variable $z$; such that
%
\begin{center}
\begin{tikzpicture}
    \node (1) at (0,0) {x};
    \node (2) [right = of 1] {y};
    \node (3) [below = of 2] {z};
    \path (1) edge  (2);
    \path (1) edge (2);
    \path (2) edge (3);
    \path (1) edge (3);
\end{tikzpicture}
\end{center}
%
The arrows above show the direction of influence; and the implication of $x\rightarrow y$ and $y \rightarrow z$ is that $x$ affects $z$ in two ways. First, it has (some) direct effect; and second, it can have indirect effect by influencing $y$, regulated by parameter $\rho$ as shown in \nameref{S3_Appendix}.

To make inferences about this mediated effect, we need more than one model. First, the regression of $z$ on $x$, i.e., the \emph{non-mediated} (or univariate) model which tells on the \emph{total} effect of $x$ on $z$; and second, the regression of $z$ on $x$ and $y$, i.e., the \emph{mediated} (or multivariate or full) model. We simulated the data as shown in \nameref{S3_Appendix} and fitted the two models -- non-mediated and mediated. In both cases, we compared mean-based and the observed-value-based predictions, as shown in \FREF{pred_mediated_plots}.

\begin{figure}
\begin{center}
\includegraphics{mediate_preds.ggp.pdf}
\end{center}
\caption{{\bf Mean-based and observed-value-based estimates for mediated (multivariate) and non-mediated (univariate) models.} A: In the absence of mediator variable, both mean-based and observed-value-based approaches predictions are identical since there is no any other additional (non-focal predictor) sources of bias. Consequently, in both approaches, the average estimated probability is very close to the observed proportion. B: When the mediator variable is included,  $x$ has no direct effect on $z$ and as a result the predictions do not align with the observations. However, the observed-value-based approach still closely approximates the average proportion of the simulated data. The horizontal dashed lines are the respective average estimates and observed proportions. The vertical dashed black represents the center point, and the point at which it crosses the horizontal lines represents the expected ``perfect'' estimate at the model center. The grey points are the binned observations.}
\label{fig:pred_mediated_plots}
\end{figure}

From \FREF{pred_mediated_plots}A, we see what we would expect in the absence of additional sources of bias, even though in the simulation, the effect of $x$ on $z$ is mediated through $y$. This is the total effect of $x$, which only tells us the influence of $x$ on $z$. By ignoring $y$ in the model, we are still able to capture the effect of $x$ and closely match the observed values using both approaches. However, if there were additional non-focal predictors, we would expect to see the differences similar to those in \FREF{pred_bin_plots}A. Including both $y$ and $x$ ``dilutes'' the direct effect of $x$ on $z$ and as a result, our estimates do not necessarily match the observed binned observations (see \FREF{pred_mediated_plots}B).

\section{Discussion}

Our simulations examples focused on simple linear and logistic models due their wide range of usage and application. These models also act as a starting point for building other complex models, including mixed effect models and models with categorical predictors. The logic for extending to more complex models, including other forms of nonlinear link functions is very straightforward. In fact the components needed for extension are the correct linear predictor and the inverse link function; everything else generalizes. In addition, our \proglang{R} package implementation already extends to and supports most of the nonlinear link functions and mixed model framework, including multivariate binary outcome models.

Although commonly used \proglang{R} software packages, by default, implements mean-based approach, our simulation results demonstrated that the observed-value-based approach has a potential of yielding results which are more consistent with the observed data. We would, therefore, argue that the use of mean-based approach should have some theoretical justification, especially in complex models. 

\section{Conclusion}

Generating outcome predictions or predicted probabilities from simple and generalized linear (mixed) models is not only important but also, generating quantities which are consistent with the observed values should be of interest. However, many studies still report coefficient estimates from generalized models like probit, logistic, etc., \citep{hanmer2013behind}, which are subject of less clarity and complexities in interpretation.

The argument and results we present in this paper support a greater need for a shift on focus on how to present predictions from generalized models. For example, effect plots could provide more clarity concerning the uncertainty due to the input variable of interests as opposed to the conventional way of incorporating everything. 

From our theoretical, methodological and simulation results, researchers using these kind of models should, in the absence of theoretical justification, report predictions based on observed-value-based approach or at least attempt to do a comparison of the two approaches before settling on the most appropriate in answering their research question. Moreover, we provide \proglang{R} package, \pkg{vareffects}, which implements these methods and is available on github (\href{https://github.com/mac-theobio/effects}{https://github.com/mac-theobio/effects}).


\section{Supporting information}

% Include only the SI item label in the paragraph heading. Use the \nameref{label} command to cite SI items in the text.
\paragraph*{S1 Appendix.}
\label{S1_Appendix}
{\bf Cubic polynomial interaction simulation.} Consider an hypothetical simulation which simulates household size as a function of household wealth index and cubic function of the age of the household head, specified as follows:

\begin{align}\label{sim:lm_cubic}
\mathrm{hh~size}_i &= \beta_0 + \beta_{\mathrm{A_1}}\mathrm{Age}_i + \beta_{\mathrm{A_2}}\mathrm{Age}^2_i + \beta_{\mathrm{A_3}}\mathrm{Age}^3_i + \beta_{\mathrm{W}}\mathrm{Wealthindex}_i + \epsilon_i \nonumber\\
\mathrm{Age}_i &\sim \mathrm{Normal}(0, 1) \nonumber\\
\mathrm{Wealthindex}_i &\sim \mathrm{Normal}(0, 1) \nonumber\\
\epsilon_i &\sim \mathrm{Normal}(0, 10) \nonumber\\
\beta_0 &= 20 \nonumber\\
\beta_{\mathrm{A}_1} &= 0.1 \nonumber\\
\beta_{\mathrm{A}_2} &= 0.8 \nonumber\\
\beta_{\mathrm{A}_3} &= 0.3 \nonumber\\
\beta_{\mathrm{W}} &= -0.5 \nonumber\\
i &= 1,\cdots, 100
\end{align}


\paragraph*{S2 Appendix.}
\label{S2_Appendix}
{\bf Binary outcome simulation.} Consider a simple simulation for improved water quality in Nairobi slums, such that the status is $1$ for improved and $0$ for unimproved water quality. In additional to the focal predictor, age of the household head, we add wealth index. In particular:

\begin{align}\label{sim:glm_two_pred}
\mathrm{status}_i &\sim \mathrm{Bern}(\mathrm{P_i}) \nonumber\\
\mathrm{logit}(\mathrm{P_i}) &= \eta_i \nonumber\\
\mathrm{\eta}_i &= \beta_0 + \beta_{\mathrm{A}}\mathrm{Age}_i + \beta_{\mathrm{W}}\mathrm{Wealthindex}_i \nonumber\\
\mathrm{Age}_i &\sim \mathrm{Normal}(0, 1) \nonumber\\
\mathrm{Wealthindex}_i &\sim \mathrm{Normal}(0, 1) \nonumber\\
\beta_0 &= 5 \nonumber\\
\beta_{\mathrm{A}} &= 0.5 \nonumber\\
\beta_{\mathrm{W}} &= 1.5 \nonumber\\
i &= 1,\cdots, 10000
\end{align}

\paragraph*{S3 Appendix.}
\label{S3_Appendix}
{\bf Mediated effect simulation.} Next, we consider a simple indirect mediation previously described and simulate a binary outcome model such that:

\begin{align}\label{sim:simple_mediate}
z_i &\sim \mathrm{Bern}(\mathrm{P_i}) \nonumber\\
\mathrm{logit}(\mathrm{P_i}) &= \eta_i \nonumber\\
\eta_i &= \beta_0 + \beta_{xz} x_i + \beta_{yz} y_i \nonumber\\
y_i &= \rho x_i + \sqrt{1-\rho^2} y_y \nonumber\\
x_i &\sim \mathrm{Normal(0, 1)} \nonumber\\
y_y &\sim \mathrm{Normal(0, 1)} \nonumber\\
\rho &= 0.8 \nonumber\\
\beta_0 &= 5 \nonumber\\
\beta_{xz} &= 0.2 \nonumber\\
\beta_{yz} &= 1.5 \nonumber\\
i &= 1,\cdots, 10000
\end{align}


\section*{Acknowledgments}

This work was supported by a grant to Jonathan Dushoff from the Natural Sciences and Engineering Research Council of Canada (NSERC) Discovery.

\section*{Author Contributions}

\textbf{Conceptualization:} Jonathan Dushoff

\noindent\textbf{Software:} Steve Cygu, Benjamin M. Bolker

\noindent\textbf{Writing – original draft:} Steve Cygu


\nolinenumbers
