
\section{Introduction}

Plots of predicted values of an outcome against predictors (often called effect plots or prediction plots, generalized here as “outcome plots”) are often a useful way to summarize the results of a statistical model. These can be used to illustrate the shape of model response and associated uncertainties, and may be easier to interpret than tables of coefficient estimates \citep{brambor_understanding_2006, berry_improving_2012, leeper2017interpreting}. 

\begin{gloss}
\subsection*{Glossary}
\begin{description}
\item [Input variables] Observed (scientific) variables underlying an inference or exploration. For example, the regression models described by \EREF{simple_inter_higher_no_interaction} and \EREF{simple_inter_higher} both have $3$ input variables -- $x_1, x_2, x_3$.

\item [Focal predictors] The input variable on the x-axis of an outcome plot.

\item [Linear predictor variables] The variables which are combined to make the linear predictor (corresponding to the columns in the model matrix). Each input variable corresponds to one or more linear predictor variables.

\item[Multi-parameter variables (MPVs)] Input variables which correspond to more than one linear predictor variable -- for example, variables with more than two categories (religion in our first example), or variables with spline or polynomial response. 

\item [Model center] The point corresponding to the mean of the linear predictor variables. In an ordinary linear model, the central estimate at this point will be the mean of the response variable. 

\item [Reference point] The values (or sets of values) chosen for non-focal predictors when estimating the predictions and effects. Can be the model center, chosen baseline values, or a weighted or unweighted mean across categories. We will also discuss averaging over a set of quantiles or observations as a reference point.

\item [Anchor] The values chosen for variables related the focal predictor when estimating effect-style confidence intervals. The anchor choice does not affect the central estimates, nor prediction-style confidence intervals. Often but not always based on the model center. 

\end{description}
\end{gloss}

To make an outcome plot, we use a \emph{focal} predictor on the x-axis and values of the outcome variable on the y-axis. The resulting plot will depend on choices about other (non-focal) predictors. In an \emph{ordinary} linear model, the non-focal choices may have a simple additive effect on the central estimate. However, when the focal predictor has interactions or non-linear response functions (e.g., spline or polynomial), non-focal choices can also affect the slope of the estimate. 
In a \emph{generalized} linear model, there is usually a non-linear link function, which complicates the picture of additivity.
Additional challenges arise when dealing with “mixed” models, which incorporate random effects.

We endeavor here to make a conceptual distinction between two functions of 
outcome plots: prediction and effects. 
The primary difference lies in how we describe the uncertainties around the central estimate. 
If our goal is to \emph{predict} what we learn about the outcome variable by measuring the focal predictor, then we may want to capture a variety of sources of uncertainty, including that due to the intercept, focal and non-focal predictors, and random effects.
Conversely, if we wish to focus on the \emph{effect} of a focal predictor only, we might want to isolate uncertainty due to coefficients associated with that predictor.
If we follow this convention, we expect effects plots to generally have narrower confidence intervals (CIs) than prediction plots, since less uncertainty is taken into account.

The other distinction relates not to the method of calculating CIs, but to the model chosen for the plot. 
In general, if we want to predict based on a focal parameter, we are likely to prefer a univariate model that only contains terms related to that predictor, thus addressing the question: if we know (only) the focal parameter, what can we predict about the outcome?
If we want to know the effects of a predictor, we may want to control for covariates with a multivariate model, in order to estimate “direct” effects; leave covariates out, in order to estimate “total” effects (direct plus indirect); or take an intermediate strategy.
These address different versions of the question: if we change the focal parameter (possibly allowing it also to affect other covariates), what is the expected effect on the outcome variable (see, e.g., \citep{shi_evidence_2017}).

We discuss the idea of a model “center” and show how it simplifies thinking about outcome plot choices, particularly in the case of ordinary linear models. We also discuss biases that arise from non-linear link functions in generalized linear models, and how such biases can be addressed.

%% \clearpage

\section{Ordinary linear models}

\begin{figure}
\begin{center}
\includegraphics{eco.splash.Rout.pdf}
\end{center}
\caption{Outcome plots with effect- (dashed straight lines) and prediction-style (dashed curved lines). The panel on the left anchors the effect-style intervals at the model center; the panel on the right has a specific anchor chosen for biological reasons. Anchor point does not affect prediction-style confidence intervals}
\flab{splash}
\end{figure}

\fref{splash} shows effect- and prediction-style confidence intervals for a hypothetical data set. Prediction-style confidence intervals do not depend on an anchor choice, and correspond to \CIs\ for the predicted mean value of Biomass for the given value of Nitrogen (note that these differ from the broader \emph{prediction intervals} which give \CIs\ for observations rather than the predicted means, and are not discussed further here). Effect-style confidence intervals show the range of slopes corresponding to the model's \CIs\ for the \emph{direct} effect of the focal predictor. In this simple case, effect-style CIs, unlike prediction-style CIs, have a clear visual correspondence with statistical clarity: both CI lines have the same slope exactly when the P value for the effect of the predictor is below the threshold.

\subsection{The model center}

To make an outcome plot, we vary the value of the focal predictor, but we need to choose values for other predictors. Our default is to do this using the \emph{model center}. We define the model center as the average value of all of the “linear predictor variables” which go into the model matrix. This is not, in general, the same as averaging over the “input variables” which are measured and provided as data. 

The model center does not need to correspond to a physically possible data point. For example, the mean of an interaction term across the data is generally not the same as the value of the same term evaluated when each of its components is at its mean. The predicted outcome at the model center, however, is always the same as the mean predicted outcome -- in the case of an ordinary linear model, this means that the value is also the same as the observed mean of the outcome variable.

For this reason, using the model center tends to make outcome plots match the data better than other approaches, including that of taking the mean of input variables only.

\begin{figure}
\begin{center}
\end{center}
\flab{justify_plots}
\end{figure}
%
\fref{center} shows an example, based on simulated data with an interaction between correlated variables.
In the absence of interactions (\EREF{simple_inter_higher_no_interaction}), the three approaches produce identical estimates, which match the simulated values, \FREF{justify_plots}A. However, the estimates start to differ in the presence of interactions, even as simple as the one in \EREF{simple_inter_higher}. In particular, estimates from \pkg{emmeans} and \pkg{effects} are identical but differ from \pkg{varpred}'s, which is very close to the simulated average ($\bar{y}$), \FREF{justify_plots}B.
In the simple model, \FREF{justify_plots}A, the input variables are the same as the linear predictor variables, so all the three methods produce identical results.
In the interaction model, \FREF{justify_plots}B, there is an additional linear predictor variable ($x_2x_3$). \pkg{emmeans} and \pkg{effects} first average the input variables to compute $\bar{x_2}\bar{x_3}$ while \pkg{varpred} first calculates the corresponding vector of linear predictor values and then averages.

\subsection{Multi-parameter predictors}

\subsection{Direct effects}

\begin{figure}
\begin{center}
\includegraphics{eco.mcomp.Rout.pdf}
\end{center}
\caption{Outcome plots with effect- (dashed straight lines) and prediction-style (dashed curved lines). The panel on the left shows the results of a univariate model fit; the panel on the right shows a multivariate fit (and effect-style lines only, see text.}
\flab{mcomp}
\end{figure}
%%
\jd{Still working on this. One panel or two?}
\fref{mcomp} compares direct and indirect effects using univariate vs.~multivariate models

\section{Generalized linear models}

\section{Discussion}

Generalized linear (mixed) models are widely used in various fields, including public health. In a model involving difficult-to-interpret coefficient estimates, an outcome plot can aid in understanding and summarizing the results. In particular, a prediction plot would be appropriate if the goal is to capture every uncertainty in the model for a particular focal predictor or if we are interested in total effect. Conversely, an effect plot is preferable if we want to focus on the uncertainty associated with a focal predictor only or if we are interested in the direct effect.

The mean-based approach is widely used to create outcome plots. However, in a model with complex interaction, MPVs or categorical variables, it is sensitive to the choice of the reference point. We have demonstrated that a model-center-based reference point is generally a stable choice and provides estimates more consistent with the observed quantities as compared to common input-variable mean-based approach.

In a model with a non-linear link function such as a logistic or exponential function, the generated central estimate curve may not match well with the observed data, i.e., our description for bias. In such a model, the observed-value-based approach provides a way to generate more consistent estimates and is preferable to the widely used mean-based approach.

The argument and results we present in this paper support a greater need for a shift in focus on how to summarize these kinds of models. From our theoretical, methodological and simulation results, researchers using these models should, in the absence of theoretical justification, report predictions based on the observed-value approach or at least attempt to compare the two approaches before settling on the most appropriate in answering their research question. Moreover, we provide \proglang{R} package, \pkg{vareffects}, which implements these methods and is available on GitHub (\href{https://github.com/mac-theobio/effects}{https://github.com/mac-theobio/effects}).

Our simulation examples focused on simple linear and logistic models due to their wide range of usage and application. These models also act as a starting point for building other complex models, including mixed effect models and models with categorical predictors. The logic for extending to more complex models, including other forms of non-linear link functions, is straightforward. The components needed for extension are the correct linear predictor and the inverse link function; everything else generalizes. In addition, our \proglang{R} package implementation already extends to and supports most of the non-linear link functions and mixed model framework, including multivariate binary outcome models.

\section{Supporting information}

% Include only the SI item label in the paragraph heading. Use the \nameref{label} command to cite SI items in the text.
\paragraph*{S1 Appendix.}
\label{S1_Appendix}
{\bf Cubic polynomial interaction simulation.} Consider a hypothetical simulation which simulates household size as a function of household wealth index and cubic function of the age of the household head, specified as follows:
%
\begin{align}\label{sim:lm_cubic}
\mathrm{hh~size}_i &= \beta_0 + \beta_{\mathrm{A_1}}\mathrm{Age}_i + \beta_{\mathrm{A_2}}\mathrm{Age}^2_i + \beta_{\mathrm{A_3}}\mathrm{Age}^3_i + \beta_{\mathrm{W}}\mathrm{Wealthindex}_i + \epsilon_i \nonumber\\
\mathrm{Age}_i &\sim \mathrm{Normal}(0, 1) \nonumber\\
\mathrm{Wealthindex}_i &\sim \mathrm{Normal}(0, 1) \nonumber\\
\epsilon_i &\sim \mathrm{Normal}(0, 10) \nonumber\\
\beta_0 &= 20 \nonumber\\
\beta_{\mathrm{A}_1} &= 0.1 \nonumber\\
\beta_{\mathrm{A}_2} &= 0.8 \nonumber\\
\beta_{\mathrm{A}_3} &= 0.3 \nonumber\\
\beta_{\mathrm{W}} &= -0.5 \nonumber\\
i &= 1,\cdots, 100
\end{align}


\paragraph*{S2 Appendix.}
\label{S2_Appendix}
{\bf Binary outcome simulation.} Consider a simple simulation for improved water quality in Nairobi slums, such that the status is $1$ for improved and $0$ for unimproved water quality. In addition to the focal predictor, age of the household head, we add wealth index. In particular:
%
\begin{align}\label{sim:glm_two_pred}
\mathrm{status}_i &\sim \mathrm{Bern}(\mathrm{P_i}) \nonumber\\
\mathrm{logit}(\mathrm{P_i}) &= \eta_i \nonumber\\
\mathrm{\eta}_i &= \beta_0 + \beta_{\mathrm{A}}\mathrm{Age}_i + \beta_{\mathrm{W}}\mathrm{Wealthindex}_i \nonumber\\
\mathrm{Age}_i &\sim \mathrm{Normal}(0, 1) \nonumber\\
\mathrm{Wealthindex}_i &\sim \mathrm{Normal}(0, 1) \nonumber\\
\beta_0 &= 5 \nonumber\\
\beta_{\mathrm{A}} &= 0.5 \nonumber\\
\beta_{\mathrm{W}} &= 1.5 \nonumber\\
i &= 1,\cdots, 10000
\end{align}

\paragraph*{S3 Appendix.}
\label{S3_Appendix}
{\bf Mediated effect simulation.} Next, we consider a simple indirect mediation previously described and simulate a binary outcome model such that:

\begin{align}\label{sim:simple_mediate}
%% z_i &\sim \mathrm{Bern}(\mathrm{P_i}) \nonumber\\
%% \mathrm{logit}(\mathrm{P_i}) &= \eta_i \nonumber\\
z_i &= \beta_0 + \beta_{xz} x_i + \beta_{yz} y_i \nonumber\\
y_i &= \rho x_i + \sqrt{1-\rho^2} y_y \nonumber\\
x_i &\sim \mathrm{Normal(0, 1)} \nonumber\\
y_y &\sim \mathrm{Normal(0, 1)} \nonumber\\
\rho &= 0.8 \nonumber\\
\beta_0 &= 5 \nonumber\\
\beta_{xz} &= 0.2 \nonumber\\
\beta_{yz} &= 1.5 \nonumber\\
i &= 1,\cdots, 10000
\end{align}


\section*{Acknowledgments}

This work was supported by a grant to Jonathan Dushoff from the Natural Sciences and Engineering Research Council of Canada (NSERC) Discovery.

\section*{Author Contributions}

\textbf{Conceptualization:} Jonathan Dushoff, Steve Cygu

\noindent\textbf{Software:} Steve Cygu, Benjamin M. Bolker

\noindent\textbf{Writing – original draft:} Steve Cygu

\nolinenumbers

